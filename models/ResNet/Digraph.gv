digraph {
	graph [size="622.8,622.8"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1953000314480 [label="
 (1, 4)" fillcolor=darkolivegreen1]
	1953173239792 -> 1952874307776 [dir=none]
	1952874307776 [label="mat1
 (1, 2048)" fillcolor=orange]
	1953173239792 -> 1953172334736 [dir=none]
	1953172334736 [label="mat2
 (2048, 4)" fillcolor=orange]
	1953173239792 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :      (1, 2048)
mat1_sym_strides:      (2048, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (2048, 4)
mat2_sym_strides:      (1, 2048)"]
	1953173238352 -> 1953173239792
	1953000570800 [label="fc.bias
 (4)" fillcolor=lightblue]
	1953000570800 -> 1953173238352
	1953173238352 [label=AccumulateGrad]
	1953173239168 -> 1953173239792
	1953173239168 [label="ReshapeAliasBackward0
-------------------------------
self_sym_sizes: (1, 2048, 1, 1)"]
	1953173239120 -> 1953173239168
	1953173239120 -> 1952874309296 [dir=none]
	1952874309296 [label="self
 (1, 2048, 11, 11)" fillcolor=orange]
	1953173239120 [label="MeanBackward1
----------------------------------------
dim           : (4294967295, 4294967294)
keepdim       :                     True
self          :           [saved tensor]
self_sym_sizes:        (1, 2048, 11, 11)"]
	1953173237680 -> 1953173239120
	1953173237680 -> 1953172335456 [dir=none]
	1953172335456 [label="result
 (1, 2048, 11, 11)" fillcolor=orange]
	1953173237680 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173237872 -> 1953173237680
	1953173237872 [label="AddBackward0
------------
alpha: 1"]
	1953173237056 -> 1953173237872
	1953173237056 -> 1952874310176 [dir=none]
	1952874310176 [label="input
 (1, 2048, 11, 11)" fillcolor=orange]
	1953173237056 -> 1953172334976 [dir=none]
	1953172334976 [label="result1
 (2048)" fillcolor=orange]
	1953173237056 -> 1953172335056 [dir=none]
	1953172335056 [label="result2
 (2048)" fillcolor=orange]
	1953173237056 -> 1953172334576 [dir=none]
	1953172334576 [label="result3
 (0)" fillcolor=orange]
	1953173237056 -> 1953000566480 [dir=none]
	1953000566480 [label="running_mean
 (2048)" fillcolor=orange]
	1953173237056 -> 1953000568720 [dir=none]
	1953000568720 [label="running_var
 (2048)" fillcolor=orange]
	1953173237056 -> 1953000568080 [dir=none]
	1953000568080 [label="weight
 (2048)" fillcolor=orange]
	1953173237056 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173237296 -> 1953173237056
	1953173237296 -> 1952874310096 [dir=none]
	1952874310096 [label="input
 (1, 512, 11, 11)" fillcolor=orange]
	1953173237296 -> 1953000568400 [dir=none]
	1953000568400 [label="weight
 (2048, 512, 1, 1)" fillcolor=orange]
	1953173237296 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173236672 -> 1953173237296
	1953173236672 -> 1953172334896 [dir=none]
	1953172334896 [label="result
 (1, 512, 11, 11)" fillcolor=orange]
	1953173236672 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173236000 -> 1953173236672
	1953173236000 -> 1952874308976 [dir=none]
	1952874308976 [label="input
 (1, 512, 11, 11)" fillcolor=orange]
	1953173236000 -> 1953172335776 [dir=none]
	1953172335776 [label="result1
 (512)" fillcolor=orange]
	1953173236000 -> 1953172335216 [dir=none]
	1953172335216 [label="result2
 (512)" fillcolor=orange]
	1953173236000 -> 1953172335376 [dir=none]
	1953172335376 [label="result3
 (0)" fillcolor=orange]
	1953173236000 -> 1953000499984 [dir=none]
	1953000499984 [label="running_mean
 (512)" fillcolor=orange]
	1953173236000 -> 1953000562320 [dir=none]
	1953000562320 [label="running_var
 (512)" fillcolor=orange]
	1953173236000 -> 1953000565840 [dir=none]
	1953000565840 [label="weight
 (512)" fillcolor=orange]
	1953173236000 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173235184 -> 1953173236000
	1953173235184 -> 1952874308736 [dir=none]
	1952874308736 [label="input
 (1, 512, 11, 11)" fillcolor=orange]
	1953173235184 -> 1953000566800 [dir=none]
	1953000566800 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	1953173235184 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173234560 -> 1953173235184
	1953173234560 -> 1953172335136 [dir=none]
	1953172335136 [label="result
 (1, 512, 11, 11)" fillcolor=orange]
	1953173234560 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173234800 -> 1953173234560
	1953173234800 -> 1952874309456 [dir=none]
	1952874309456 [label="input
 (1, 512, 11, 11)" fillcolor=orange]
	1953173234800 -> 1953172335536 [dir=none]
	1953172335536 [label="result1
 (512)" fillcolor=orange]
	1953173234800 -> 1953172337056 [dir=none]
	1953172337056 [label="result2
 (512)" fillcolor=orange]
	1953173234800 -> 1953172335856 [dir=none]
	1953172335856 [label="result3
 (0)" fillcolor=orange]
	1953173234800 -> 1953000555440 [dir=none]
	1953000555440 [label="running_mean
 (512)" fillcolor=orange]
	1953173234800 -> 1953000558080 [dir=none]
	1953000558080 [label="running_var
 (512)" fillcolor=orange]
	1953173234800 -> 1953000562960 [dir=none]
	1953000562960 [label="weight
 (512)" fillcolor=orange]
	1953173234800 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173233984 -> 1953173234800
	1953173233984 -> 1952874308336 [dir=none]
	1952874308336 [label="input
 (1, 2048, 11, 11)" fillcolor=orange]
	1953173233984 -> 1953000563760 [dir=none]
	1953000563760 [label="weight
 (512, 2048, 1, 1)" fillcolor=orange]
	1953173233984 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173237920 -> 1953173233984
	1953173237920 -> 1953172335616 [dir=none]
	1953172335616 [label="result
 (1, 2048, 11, 11)" fillcolor=orange]
	1953173237920 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173233552 -> 1953173237920
	1953173233552 [label="AddBackward0
------------
alpha: 1"]
	1953173232736 -> 1953173233552
	1953173232736 -> 1952874310976 [dir=none]
	1952874310976 [label="input
 (1, 2048, 11, 11)" fillcolor=orange]
	1953173232736 -> 1953172335696 [dir=none]
	1953172335696 [label="result1
 (2048)" fillcolor=orange]
	1953173232736 -> 1953172336096 [dir=none]
	1953172336096 [label="result2
 (2048)" fillcolor=orange]
	1953173232736 -> 1953172337376 [dir=none]
	1953172337376 [label="result3
 (0)" fillcolor=orange]
	1953173232736 -> 1953000426048 [dir=none]
	1953000426048 [label="running_mean
 (2048)" fillcolor=orange]
	1953173232736 -> 1953000554960 [dir=none]
	1953000554960 [label="running_var
 (2048)" fillcolor=orange]
	1953173232736 -> 1953000560960 [dir=none]
	1953000560960 [label="weight
 (2048)" fillcolor=orange]
	1953173232736 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173232064 -> 1953173232736
	1953173232064 -> 1952874307936 [dir=none]
	1952874307936 [label="input
 (1, 512, 11, 11)" fillcolor=orange]
	1953173232064 -> 1953000559360 [dir=none]
	1953000559360 [label="weight
 (2048, 512, 1, 1)" fillcolor=orange]
	1953173232064 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173231440 -> 1953173232064
	1953173231440 -> 1953172337216 [dir=none]
	1953172337216 [label="result
 (1, 512, 11, 11)" fillcolor=orange]
	1953173231440 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173231680 -> 1953173231440
	1953173231680 -> 1952874307216 [dir=none]
	1952874307216 [label="input
 (1, 512, 11, 11)" fillcolor=orange]
	1953173231680 -> 1953172336976 [dir=none]
	1953172336976 [label="result1
 (512)" fillcolor=orange]
	1953173231680 -> 1953172337936 [dir=none]
	1953172337936 [label="result2
 (512)" fillcolor=orange]
	1953173231680 -> 1953172338336 [dir=none]
	1953172338336 [label="result3
 (0)" fillcolor=orange]
	1953173231680 -> 1953000562480 [dir=none]
	1953000562480 [label="running_mean
 (512)" fillcolor=orange]
	1953173231680 -> 1953000562800 [dir=none]
	1953000562800 [label="running_var
 (512)" fillcolor=orange]
	1953173231680 -> 1953000562160 [dir=none]
	1953000562160 [label="weight
 (512)" fillcolor=orange]
	1953173231680 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173230864 -> 1953173231680
	1953173230864 -> 1952874310736 [dir=none]
	1952874310736 [label="input
 (1, 512, 11, 11)" fillcolor=orange]
	1953173230864 -> 1953000556480 [dir=none]
	1953000556480 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	1953173230864 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173230240 -> 1953173230864
	1953173230240 -> 1953172337616 [dir=none]
	1953172337616 [label="result
 (1, 512, 11, 11)" fillcolor=orange]
	1953173230240 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173229568 -> 1953173230240
	1953173229568 -> 1952874311056 [dir=none]
	1952874311056 [label="input
 (1, 512, 11, 11)" fillcolor=orange]
	1953173229568 -> 1953172338176 [dir=none]
	1953172338176 [label="result1
 (512)" fillcolor=orange]
	1953173229568 -> 1953172338096 [dir=none]
	1953172338096 [label="result2
 (512)" fillcolor=orange]
	1953173229568 -> 1953172338256 [dir=none]
	1953172338256 [label="result3
 (0)" fillcolor=orange]
	1953173229568 -> 1953000570720 [dir=none]
	1953000570720 [label="running_mean
 (512)" fillcolor=orange]
	1953173229568 -> 1953000569840 [dir=none]
	1953000569840 [label="running_var
 (512)" fillcolor=orange]
	1953173229568 -> 1953000559040 [dir=none]
	1953000559040 [label="weight
 (512)" fillcolor=orange]
	1953173229568 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173229760 -> 1953173229568
	1953173229760 -> 1952874311216 [dir=none]
	1952874311216 [label="input
 (1, 2048, 11, 11)" fillcolor=orange]
	1953173229760 -> 1953000569200 [dir=none]
	1953000569200 [label="weight
 (512, 2048, 1, 1)" fillcolor=orange]
	1953173229760 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173232688 -> 1953173229760
	1953173232688 -> 1953172337776 [dir=none]
	1953172337776 [label="result
 (1, 2048, 11, 11)" fillcolor=orange]
	1953173232688 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173228320 -> 1953173232688
	1953173228320 [label="AddBackward0
------------
alpha: 1"]
	1953173228512 -> 1953173228320
	1953173228512 -> 1952874305856 [dir=none]
	1952874305856 [label="input
 (1, 2048, 11, 11)" fillcolor=orange]
	1953173228512 -> 1953172338496 [dir=none]
	1953172338496 [label="result1
 (2048)" fillcolor=orange]
	1953173228512 -> 1953172338576 [dir=none]
	1953172338576 [label="result2
 (2048)" fillcolor=orange]
	1953173228512 -> 1952874306336 [dir=none]
	1952874306336 [label="result3
 (0)" fillcolor=orange]
	1953173228512 -> 1953000566560 [dir=none]
	1953000566560 [label="running_mean
 (2048)" fillcolor=orange]
	1953173228512 -> 1953000559120 [dir=none]
	1953000559120 [label="running_var
 (2048)" fillcolor=orange]
	1953173228512 -> 1953000567600 [dir=none]
	1953000567600 [label="weight
 (2048)" fillcolor=orange]
	1953173228512 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173227744 -> 1953173228512
	1953173227744 -> 1953172305168 [dir=none]
	1953172305168 [label="input
 (1, 512, 11, 11)" fillcolor=orange]
	1953173227744 -> 1953000558640 [dir=none]
	1953000558640 [label="weight
 (2048, 512, 1, 1)" fillcolor=orange]
	1953173227744 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173227120 -> 1953173227744
	1953173227120 -> 1953172338816 [dir=none]
	1953172338816 [label="result
 (1, 512, 11, 11)" fillcolor=orange]
	1953173227120 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173226448 -> 1953173227120
	1953173226448 -> 1953172300128 [dir=none]
	1953172300128 [label="input
 (1, 512, 11, 11)" fillcolor=orange]
	1953173226448 -> 1953172335296 [dir=none]
	1953172335296 [label="result1
 (512)" fillcolor=orange]
	1953173226448 -> 1953172339136 [dir=none]
	1953172339136 [label="result2
 (512)" fillcolor=orange]
	1953173226448 -> 1953172338896 [dir=none]
	1953172338896 [label="result3
 (0)" fillcolor=orange]
	1953173226448 -> 1953000569520 [dir=none]
	1953000569520 [label="running_mean
 (512)" fillcolor=orange]
	1953173226448 -> 1953000556720 [dir=none]
	1953000556720 [label="running_var
 (512)" fillcolor=orange]
	1953173226448 -> 1953000567680 [dir=none]
	1953000567680 [label="weight
 (512)" fillcolor=orange]
	1953173226448 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173226640 -> 1953173226448
	1953173226640 -> 1953172296048 [dir=none]
	1953172296048 [label="input
 (1, 512, 21, 21)" fillcolor=orange]
	1953173226640 -> 1953000557440 [dir=none]
	1953000557440 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	1953173226640 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	1953173226016 -> 1953173226640
	1953173226016 -> 1953172338656 [dir=none]
	1953172338656 [label="result
 (1, 512, 21, 21)" fillcolor=orange]
	1953173226016 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173241808 -> 1953173226016
	1953173241808 -> 1953172300368 [dir=none]
	1953172300368 [label="input
 (1, 512, 21, 21)" fillcolor=orange]
	1953173241808 -> 1953172335936 [dir=none]
	1953172335936 [label="result1
 (512)" fillcolor=orange]
	1953173241808 -> 1953172339456 [dir=none]
	1953172339456 [label="result2
 (512)" fillcolor=orange]
	1953173241808 -> 1953172339216 [dir=none]
	1953172339216 [label="result3
 (0)" fillcolor=orange]
	1953173241808 -> 1953000437728 [dir=none]
	1953000437728 [label="running_mean
 (512)" fillcolor=orange]
	1953173241808 -> 1953000312400 [dir=none]
	1953000312400 [label="running_var
 (512)" fillcolor=orange]
	1953173241808 -> 1953000565200 [dir=none]
	1953000565200 [label="weight
 (512)" fillcolor=orange]
	1953173241808 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173241568 -> 1953173241808
	1953173241568 -> 1953172304928 [dir=none]
	1953172304928 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173241568 -> 1953000311440 [dir=none]
	1953000311440 [label="weight
 (512, 1024, 1, 1)" fillcolor=orange]
	1953173241568 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173241280 -> 1953173241568
	1953173241280 -> 1953172338976 [dir=none]
	1953172338976 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173241280 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173240896 -> 1953173241280
	1953173240896 [label="AddBackward0
------------
alpha: 1"]
	1953173240512 -> 1953173240896
	1953173240512 -> 1953172299888 [dir=none]
	1953172299888 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173240512 -> 1953172339296 [dir=none]
	1953172339296 [label="result1
 (1024)" fillcolor=orange]
	1953173240512 -> 1953172339056 [dir=none]
	1953172339056 [label="result2
 (1024)" fillcolor=orange]
	1953173240512 -> 1953172339536 [dir=none]
	1953172339536 [label="result3
 (0)" fillcolor=orange]
	1953173240512 -> 1953000318960 [dir=none]
	1953000318960 [label="running_mean
 (1024)" fillcolor=orange]
	1953173240512 -> 1953000316400 [dir=none]
	1953000316400 [label="running_var
 (1024)" fillcolor=orange]
	1953173240512 -> 1953000314000 [dir=none]
	1953000314000 [label="weight
 (1024)" fillcolor=orange]
	1953173240512 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173240656 -> 1953173240512
	1953173240656 -> 1953172295808 [dir=none]
	1953172295808 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173240656 -> 1953000317680 [dir=none]
	1953000317680 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173240656 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173240320 -> 1953173240656
	1953173240320 -> 1953172339616 [dir=none]
	1953172339616 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173240320 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173239984 -> 1953173240320
	1953173239984 -> 1953172305648 [dir=none]
	1953172305648 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173239984 -> 1953172339376 [dir=none]
	1953172339376 [label="result1
 (256)" fillcolor=orange]
	1953173239984 -> 1953172340096 [dir=none]
	1953172340096 [label="result2
 (256)" fillcolor=orange]
	1953173239984 -> 1953172339856 [dir=none]
	1953172339856 [label="result3
 (0)" fillcolor=orange]
	1953173239984 -> 1953000320560 [dir=none]
	1953000320560 [label="running_mean
 (256)" fillcolor=orange]
	1953173239984 -> 1953000319920 [dir=none]
	1953000319920 [label="running_var
 (256)" fillcolor=orange]
	1953173239984 -> 1953000321440 [dir=none]
	1953000321440 [label="weight
 (256)" fillcolor=orange]
	1953173239984 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173240128 -> 1953173239984
	1953173240128 -> 1953172301808 [dir=none]
	1953172301808 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173240128 -> 1953000324480 [dir=none]
	1953000324480 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173240128 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173239312 -> 1953173240128
	1953173239312 -> 1953172339776 [dir=none]
	1953172339776 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173239312 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173239456 -> 1953173239312
	1953173239456 -> 1953172297728 [dir=none]
	1953172297728 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173239456 -> 1953172339696 [dir=none]
	1953172339696 [label="result1
 (256)" fillcolor=orange]
	1953173239456 -> 1953172340416 [dir=none]
	1953172340416 [label="result2
 (256)" fillcolor=orange]
	1953173239456 -> 1953172340176 [dir=none]
	1953172340176 [label="result3
 (0)" fillcolor=orange]
	1953173239456 -> 1953000315360 [dir=none]
	1953000315360 [label="running_mean
 (256)" fillcolor=orange]
	1953173239456 -> 1953000316720 [dir=none]
	1953000316720 [label="running_var
 (256)" fillcolor=orange]
	1953173239456 -> 1953000318000 [dir=none]
	1953000318000 [label="weight
 (256)" fillcolor=orange]
	1953173239456 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173239024 -> 1953173239456
	1953173239024 -> 1953172297488 [dir=none]
	1953172297488 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173239024 -> 1953000314960 [dir=none]
	1953000314960 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173239024 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173240944 -> 1953173239024
	1953173240944 -> 1953000565520 [dir=none]
	1953000565520 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173240944 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173238832 -> 1953173240944
	1953173238832 [label="AddBackward0
------------
alpha: 1"]
	1953173238400 -> 1953173238832
	1953173238400 -> 1953172304688 [dir=none]
	1953172304688 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173238400 -> 1953000556800 [dir=none]
	1953000556800 [label="result1
 (1024)" fillcolor=orange]
	1953173238400 -> 1953000557120 [dir=none]
	1953000557120 [label="result2
 (1024)" fillcolor=orange]
	1953173238400 -> 1953000564560 [dir=none]
	1953000564560 [label="result3
 (0)" fillcolor=orange]
	1953173238400 -> 1953000313200 [dir=none]
	1953000313200 [label="running_mean
 (1024)" fillcolor=orange]
	1953173238400 -> 1953000313840 [dir=none]
	1953000313840 [label="running_var
 (1024)" fillcolor=orange]
	1953173238400 -> 1953000313040 [dir=none]
	1953000313040 [label="weight
 (1024)" fillcolor=orange]
	1953173238400 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173238112 -> 1953173238400
	1953173238112 -> 1953172301568 [dir=none]
	1953172301568 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173238112 -> 1953000310480 [dir=none]
	1953000310480 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173238112 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173237776 -> 1953173238112
	1953173237776 -> 1953368846272 [dir=none]
	1953368846272 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173237776 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173237440 -> 1953173237776
	1953173237440 -> 1953172301328 [dir=none]
	1953172301328 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173237440 -> 1953172340256 [dir=none]
	1953172340256 [label="result1
 (256)" fillcolor=orange]
	1953173237440 -> 1953172340576 [dir=none]
	1953172340576 [label="result2
 (256)" fillcolor=orange]
	1953173237440 -> 1953172340496 [dir=none]
	1953172340496 [label="result3
 (0)" fillcolor=orange]
	1953173237440 -> 1953000315440 [dir=none]
	1953000315440 [label="running_mean
 (256)" fillcolor=orange]
	1953173237440 -> 1953000316240 [dir=none]
	1953000316240 [label="running_var
 (256)" fillcolor=orange]
	1953173237440 -> 1953000315040 [dir=none]
	1953000315040 [label="weight
 (256)" fillcolor=orange]
	1953173237440 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173237584 -> 1953173237440
	1953173237584 -> 1953172297248 [dir=none]
	1953172297248 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173237584 -> 1953000314880 [dir=none]
	1953000314880 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173237584 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173236768 -> 1953173237584
	1953173236768 -> 1953172339936 [dir=none]
	1953172339936 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173236768 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173236912 -> 1953173236768
	1953173236912 -> 1953172304448 [dir=none]
	1953172304448 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173236912 -> 1953172338736 [dir=none]
	1953172338736 [label="result1
 (256)" fillcolor=orange]
	1953173236912 -> 1953172338416 [dir=none]
	1953172338416 [label="result2
 (256)" fillcolor=orange]
	1953173236912 -> 1953172340016 [dir=none]
	1953172340016 [label="result3
 (0)" fillcolor=orange]
	1953173236912 -> 1953000319120 [dir=none]
	1953000319120 [label="running_mean
 (256)" fillcolor=orange]
	1953173236912 -> 1953000318480 [dir=none]
	1953000318480 [label="running_var
 (256)" fillcolor=orange]
	1953173236912 -> 1953000317840 [dir=none]
	1953000317840 [label="weight
 (256)" fillcolor=orange]
	1953173236912 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173236528 -> 1953173236912
	1953173236528 -> 1953172303968 [dir=none]
	1953172303968 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173236528 -> 1953000317520 [dir=none]
	1953000317520 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173236528 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173238880 -> 1953173236528
	1953173238880 -> 1953172340336 [dir=none]
	1953172340336 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173238880 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173236336 -> 1953173238880
	1953173236336 [label="AddBackward0
------------
alpha: 1"]
	1953173235904 -> 1953173236336
	1953173235904 -> 1953172296768 [dir=none]
	1953172296768 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173235904 -> 1953172389728 [dir=none]
	1953172389728 [label="result1
 (1024)" fillcolor=orange]
	1953173235904 -> 1953172373648 [dir=none]
	1953172373648 [label="result2
 (1024)" fillcolor=orange]
	1953173235904 -> 1953172373728 [dir=none]
	1953172373728 [label="result3
 (0)" fillcolor=orange]
	1953173235904 -> 1953000322080 [dir=none]
	1953000322080 [label="running_mean
 (1024)" fillcolor=orange]
	1953173235904 -> 1953000321280 [dir=none]
	1953000321280 [label="running_var
 (1024)" fillcolor=orange]
	1953173235904 -> 1953000320400 [dir=none]
	1953000320400 [label="weight
 (1024)" fillcolor=orange]
	1953173235904 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173235616 -> 1953173235904
	1953173235616 -> 1953172301088 [dir=none]
	1953172301088 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173235616 -> 1953000320080 [dir=none]
	1953000320080 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173235616 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173235280 -> 1953173235616
	1953173235280 -> 1953172373968 [dir=none]
	1953172373968 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173235280 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173234944 -> 1953173235280
	1953173234944 -> 1953172297008 [dir=none]
	1953172297008 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173234944 -> 1953172373888 [dir=none]
	1953172373888 [label="result1
 (256)" fillcolor=orange]
	1953173234944 -> 1953172374288 [dir=none]
	1953172374288 [label="result2
 (256)" fillcolor=orange]
	1953173234944 -> 1953172373808 [dir=none]
	1953172373808 [label="result3
 (0)" fillcolor=orange]
	1953173234944 -> 1953000325040 [dir=none]
	1953000325040 [label="running_mean
 (256)" fillcolor=orange]
	1953173234944 -> 1953000324160 [dir=none]
	1953000324160 [label="running_var
 (256)" fillcolor=orange]
	1953173234944 -> 1953000323440 [dir=none]
	1953000323440 [label="weight
 (256)" fillcolor=orange]
	1953173234944 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173235088 -> 1953173234944
	1953173235088 -> 1953172306128 [dir=none]
	1953172306128 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173235088 -> 1953000323840 [dir=none]
	1953000323840 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173235088 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173234272 -> 1953173235088
	1953173234272 -> 1953172373568 [dir=none]
	1953172373568 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173234272 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173234416 -> 1953173234272
	1953173234416 -> 1953172295168 [dir=none]
	1953172295168 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173234416 -> 1953172374208 [dir=none]
	1953172374208 [label="result1
 (256)" fillcolor=orange]
	1953173234416 -> 1953172374608 [dir=none]
	1953172374608 [label="result2
 (256)" fillcolor=orange]
	1953173234416 -> 1953172374128 [dir=none]
	1953172374128 [label="result3
 (0)" fillcolor=orange]
	1953173234416 -> 1953000323760 [dir=none]
	1953000323760 [label="running_mean
 (256)" fillcolor=orange]
	1953173234416 -> 1953000324080 [dir=none]
	1953000324080 [label="running_var
 (256)" fillcolor=orange]
	1953173234416 -> 1953000324880 [dir=none]
	1953000324880 [label="weight
 (256)" fillcolor=orange]
	1953173234416 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173234032 -> 1953173234416
	1953173234032 -> 1953172304208 [dir=none]
	1953172304208 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173234032 -> 1953000324240 [dir=none]
	1953000324240 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173234032 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173236384 -> 1953173234032
	1953173236384 -> 1953172374368 [dir=none]
	1953172374368 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173236384 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173233840 -> 1953173236384
	1953173233840 [label="AddBackward0
------------
alpha: 1"]
	1953173233408 -> 1953173233840
	1953173233408 -> 1953172300848 [dir=none]
	1953172300848 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173233408 -> 1953172374688 [dir=none]
	1953172374688 [label="result1
 (1024)" fillcolor=orange]
	1953173233408 -> 1953172374528 [dir=none]
	1953172374528 [label="result2
 (1024)" fillcolor=orange]
	1953173233408 -> 1953172374448 [dir=none]
	1953172374448 [label="result3
 (0)" fillcolor=orange]
	1953173233408 -> 1953000322000 [dir=none]
	1953000322000 [label="running_mean
 (1024)" fillcolor=orange]
	1953173233408 -> 1953000322400 [dir=none]
	1953000322400 [label="running_var
 (1024)" fillcolor=orange]
	1953173233408 -> 1953000323520 [dir=none]
	1953000323520 [label="weight
 (1024)" fillcolor=orange]
	1953173233408 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173233120 -> 1953173233408
	1953173233120 -> 1953172295008 [dir=none]
	1953172295008 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173233120 -> 1953000322640 [dir=none]
	1953000322640 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173233120 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173232784 -> 1953173233120
	1953173232784 -> 1953172375008 [dir=none]
	1953172375008 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173232784 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173232448 -> 1953173232784
	1953173232448 -> 1953172294928 [dir=none]
	1953172294928 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173232448 -> 1953172374848 [dir=none]
	1953172374848 [label="result1
 (256)" fillcolor=orange]
	1953173232448 -> 1953172375248 [dir=none]
	1953172375248 [label="result2
 (256)" fillcolor=orange]
	1953173232448 -> 1953172374768 [dir=none]
	1953172374768 [label="result3
 (0)" fillcolor=orange]
	1953173232448 -> 1953000320720 [dir=none]
	1953000320720 [label="running_mean
 (256)" fillcolor=orange]
	1953173232448 -> 1953000320480 [dir=none]
	1953000320480 [label="running_var
 (256)" fillcolor=orange]
	1953173232448 -> 1953000320960 [dir=none]
	1953000320960 [label="weight
 (256)" fillcolor=orange]
	1953173232448 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173232592 -> 1953173232448
	1953173232592 -> 1953172305408 [dir=none]
	1953172305408 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173232592 -> 1953000321520 [dir=none]
	1953000321520 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173232592 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173231776 -> 1953173232592
	1953173231776 -> 1953172374928 [dir=none]
	1953172374928 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173231776 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173231920 -> 1953173231776
	1953173231920 -> 1953172296288 [dir=none]
	1953172296288 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173231920 -> 1953172375168 [dir=none]
	1953172375168 [label="result1
 (256)" fillcolor=orange]
	1953173231920 -> 1953172375568 [dir=none]
	1953172375568 [label="result2
 (256)" fillcolor=orange]
	1953173231920 -> 1953172375088 [dir=none]
	1953172375088 [label="result3
 (0)" fillcolor=orange]
	1953173231920 -> 1953000319360 [dir=none]
	1953000319360 [label="running_mean
 (256)" fillcolor=orange]
	1953173231920 -> 1953000319680 [dir=none]
	1953000319680 [label="running_var
 (256)" fillcolor=orange]
	1953173231920 -> 1953000320000 [dir=none]
	1953000320000 [label="weight
 (256)" fillcolor=orange]
	1953173231920 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173231536 -> 1953173231920
	1953173231536 -> 1953172294848 [dir=none]
	1953172294848 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173231536 -> 1953000319520 [dir=none]
	1953000319520 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173231536 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173233888 -> 1953173231536
	1953173233888 -> 1953172375328 [dir=none]
	1953172375328 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173233888 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173231344 -> 1953173233888
	1953173231344 [label="AddBackward0
------------
alpha: 1"]
	1953173230912 -> 1953173231344
	1953173230912 -> 1953172294688 [dir=none]
	1953172294688 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173230912 -> 1953172375648 [dir=none]
	1953172375648 [label="result1
 (1024)" fillcolor=orange]
	1953173230912 -> 1953172375488 [dir=none]
	1953172375488 [label="result2
 (1024)" fillcolor=orange]
	1953173230912 -> 1953172375408 [dir=none]
	1953172375408 [label="result3
 (0)" fillcolor=orange]
	1953173230912 -> 1953000318080 [dir=none]
	1953000318080 [label="running_mean
 (1024)" fillcolor=orange]
	1953173230912 -> 1953000318400 [dir=none]
	1953000318400 [label="running_var
 (1024)" fillcolor=orange]
	1953173230912 -> 1953000318720 [dir=none]
	1953000318720 [label="weight
 (1024)" fillcolor=orange]
	1953173230912 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173230624 -> 1953173230912
	1953173230624 -> 1953172294768 [dir=none]
	1953172294768 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173230624 -> 1953000318240 [dir=none]
	1953000318240 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173230624 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173230288 -> 1953173230624
	1953173230288 -> 1953172375968 [dir=none]
	1953172375968 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173230288 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173229952 -> 1953173230288
	1953173229952 -> 1953172294448 [dir=none]
	1953172294448 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173229952 -> 1953172375808 [dir=none]
	1953172375808 [label="result1
 (256)" fillcolor=orange]
	1953173229952 -> 1953172376208 [dir=none]
	1953172376208 [label="result2
 (256)" fillcolor=orange]
	1953173229952 -> 1953172375728 [dir=none]
	1953172375728 [label="result3
 (0)" fillcolor=orange]
	1953173229952 -> 1953000316800 [dir=none]
	1953000316800 [label="running_mean
 (256)" fillcolor=orange]
	1953173229952 -> 1953000316640 [dir=none]
	1953000316640 [label="running_var
 (256)" fillcolor=orange]
	1953173229952 -> 1953000316960 [dir=none]
	1953000316960 [label="weight
 (256)" fillcolor=orange]
	1953173229952 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173230096 -> 1953173229952
	1953173230096 -> 1953172294528 [dir=none]
	1953172294528 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173230096 -> 1953000317440 [dir=none]
	1953000317440 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173230096 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173229280 -> 1953173230096
	1953173229280 -> 1953172375888 [dir=none]
	1953172375888 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173229280 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173229424 -> 1953173229280
	1953173229424 -> 1953172294608 [dir=none]
	1953172294608 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173229424 -> 1953172376128 [dir=none]
	1953172376128 [label="result1
 (256)" fillcolor=orange]
	1953173229424 -> 1953172376528 [dir=none]
	1953172376528 [label="result2
 (256)" fillcolor=orange]
	1953173229424 -> 1953172376048 [dir=none]
	1953172376048 [label="result3
 (0)" fillcolor=orange]
	1953173229424 -> 1953000314080 [dir=none]
	1953000314080 [label="running_mean
 (256)" fillcolor=orange]
	1953173229424 -> 1953000314240 [dir=none]
	1953000314240 [label="running_var
 (256)" fillcolor=orange]
	1953173229424 -> 1953000314400 [dir=none]
	1953000314400 [label="weight
 (256)" fillcolor=orange]
	1953173229424 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173229040 -> 1953173229424
	1953173229040 -> 1953172294208 [dir=none]
	1953172294208 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173229040 -> 1953000316160 [dir=none]
	1953000316160 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173229040 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173231392 -> 1953173229040
	1953173231392 -> 1953172376288 [dir=none]
	1953172376288 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173231392 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173228848 -> 1953173231392
	1953173228848 [label="AddBackward0
------------
alpha: 1"]
	1953173228416 -> 1953173228848
	1953173228416 -> 1953172294128 [dir=none]
	1953172294128 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173228416 -> 1953172376608 [dir=none]
	1953172376608 [label="result1
 (1024)" fillcolor=orange]
	1953173228416 -> 1953172376448 [dir=none]
	1953172376448 [label="result2
 (1024)" fillcolor=orange]
	1953173228416 -> 1953172376368 [dir=none]
	1953172376368 [label="result3
 (0)" fillcolor=orange]
	1953173228416 -> 1953000313120 [dir=none]
	1953000313120 [label="running_mean
 (1024)" fillcolor=orange]
	1953173228416 -> 1953000313440 [dir=none]
	1953000313440 [label="running_var
 (1024)" fillcolor=orange]
	1953173228416 -> 1953000313600 [dir=none]
	1953000313600 [label="weight
 (1024)" fillcolor=orange]
	1953173228416 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173228128 -> 1953173228416
	1953173228128 -> 1953172294288 [dir=none]
	1953172294288 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173228128 -> 1953000313280 [dir=none]
	1953000313280 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173228128 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173227792 -> 1953173228128
	1953173227792 -> 1953172376928 [dir=none]
	1953172376928 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173227792 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173227456 -> 1953173227792
	1953173227456 -> 1953172294368 [dir=none]
	1953172294368 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173227456 -> 1953172376768 [dir=none]
	1953172376768 [label="result1
 (256)" fillcolor=orange]
	1953173227456 -> 1953172377168 [dir=none]
	1953172377168 [label="result2
 (256)" fillcolor=orange]
	1953173227456 -> 1953172376688 [dir=none]
	1953172376688 [label="result3
 (0)" fillcolor=orange]
	1953173227456 -> 1953000316080 [dir=none]
	1953000316080 [label="running_mean
 (256)" fillcolor=orange]
	1953173227456 -> 1953000315680 [dir=none]
	1953000315680 [label="running_var
 (256)" fillcolor=orange]
	1953173227456 -> 1953000315600 [dir=none]
	1953000315600 [label="weight
 (256)" fillcolor=orange]
	1953173227456 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173227600 -> 1953173227456
	1953173227600 -> 1953172293888 [dir=none]
	1953172293888 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173227600 -> 1953000310640 [dir=none]
	1953000310640 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173227600 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173226784 -> 1953173227600
	1953173226784 -> 1953172376848 [dir=none]
	1953172376848 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173226784 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173226928 -> 1953173226784
	1953173226928 -> 1953172293808 [dir=none]
	1953172293808 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173226928 -> 1953172377088 [dir=none]
	1953172377088 [label="result1
 (256)" fillcolor=orange]
	1953173226928 -> 1953172377488 [dir=none]
	1953172377488 [label="result2
 (256)" fillcolor=orange]
	1953173226928 -> 1953172377008 [dir=none]
	1953172377008 [label="result3
 (0)" fillcolor=orange]
	1953173226928 -> 1953000311760 [dir=none]
	1953000311760 [label="running_mean
 (256)" fillcolor=orange]
	1953173226928 -> 1953000311920 [dir=none]
	1953000311920 [label="running_var
 (256)" fillcolor=orange]
	1953173226928 -> 1953000315840 [dir=none]
	1953000315840 [label="weight
 (256)" fillcolor=orange]
	1953173226928 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173226544 -> 1953173226928
	1953173226544 -> 1953172293968 [dir=none]
	1953172293968 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173226544 -> 1953000312240 [dir=none]
	1953000312240 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173226544 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173228896 -> 1953173226544
	1953173228896 -> 1953172377248 [dir=none]
	1953172377248 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173228896 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173226352 -> 1953173228896
	1953173226352 [label="AddBackward0
------------
alpha: 1"]
	1953173225920 -> 1953173226352
	1953173225920 -> 1953172294048 [dir=none]
	1953172294048 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173225920 -> 1953172377568 [dir=none]
	1953172377568 [label="result1
 (1024)" fillcolor=orange]
	1953173225920 -> 1953172377408 [dir=none]
	1953172377408 [label="result2
 (1024)" fillcolor=orange]
	1953173225920 -> 1953172377328 [dir=none]
	1953172377328 [label="result3
 (0)" fillcolor=orange]
	1953173225920 -> 1953000311680 [dir=none]
	1953000311680 [label="running_mean
 (1024)" fillcolor=orange]
	1953173225920 -> 1953000312640 [dir=none]
	1953000312640 [label="running_var
 (1024)" fillcolor=orange]
	1953173225920 -> 1953000319600 [dir=none]
	1953000319600 [label="weight
 (1024)" fillcolor=orange]
	1953173225920 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173225632 -> 1953173225920
	1953173225632 -> 1953172293568 [dir=none]
	1953172293568 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173225632 -> 1953000312880 [dir=none]
	1953000312880 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173225632 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173225776 -> 1953173225632
	1953173225776 -> 1953172377888 [dir=none]
	1953172377888 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173225776 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173176224 -> 1953173225776
	1953173176224 -> 1953172293488 [dir=none]
	1953172293488 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173176224 -> 1953172377728 [dir=none]
	1953172377728 [label="result1
 (256)" fillcolor=orange]
	1953173176224 -> 1953172378128 [dir=none]
	1953172378128 [label="result2
 (256)" fillcolor=orange]
	1953173176224 -> 1953172377648 [dir=none]
	1953172377648 [label="result3
 (0)" fillcolor=orange]
	1953173176224 -> 1953000490944 [dir=none]
	1953000490944 [label="running_mean
 (256)" fillcolor=orange]
	1953173176224 -> 1953000310960 [dir=none]
	1953000310960 [label="running_var
 (256)" fillcolor=orange]
	1953173176224 -> 1953000312160 [dir=none]
	1953000312160 [label="weight
 (256)" fillcolor=orange]
	1953173176224 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173175552 -> 1953173176224
	1953173175552 -> 1953172293648 [dir=none]
	1953172293648 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173175552 -> 1953000312480 [dir=none]
	1953000312480 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173175552 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173174928 -> 1953173175552
	1953173174928 -> 1953172377808 [dir=none]
	1953172377808 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173174928 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173174160 -> 1953173174928
	1953173174160 -> 1953172293728 [dir=none]
	1953172293728 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173174160 -> 1953172378048 [dir=none]
	1953172378048 [label="result1
 (256)" fillcolor=orange]
	1953173174160 -> 1953172378448 [dir=none]
	1953172378448 [label="result2
 (256)" fillcolor=orange]
	1953173174160 -> 1953172377968 [dir=none]
	1953172377968 [label="result3
 (0)" fillcolor=orange]
	1953173174160 -> 1953000503024 [dir=none]
	1953000503024 [label="running_mean
 (256)" fillcolor=orange]
	1953173174160 -> 1953000493104 [dir=none]
	1953000493104 [label="running_var
 (256)" fillcolor=orange]
	1953173174160 -> 1953000492464 [dir=none]
	1953000492464 [label="weight
 (256)" fillcolor=orange]
	1953173174160 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173173488 -> 1953173174160
	1953173173488 -> 1953172293408 [dir=none]
	1953172293408 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173173488 -> 1953000493424 [dir=none]
	1953000493424 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173173488 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173226400 -> 1953173173488
	1953173226400 -> 1953172378208 [dir=none]
	1953172378208 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173226400 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173173056 -> 1953173226400
	1953173173056 [label="AddBackward0
------------
alpha: 1"]
	1953173172240 -> 1953173173056
	1953173172240 -> 1953172293248 [dir=none]
	1953172293248 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173172240 -> 1953172378528 [dir=none]
	1953172378528 [label="result1
 (1024)" fillcolor=orange]
	1953173172240 -> 1953172378368 [dir=none]
	1953172378368 [label="result2
 (1024)" fillcolor=orange]
	1953173172240 -> 1953172378288 [dir=none]
	1953172378288 [label="result3
 (0)" fillcolor=orange]
	1953173172240 -> 1953000494704 [dir=none]
	1953000494704 [label="running_mean
 (1024)" fillcolor=orange]
	1953173172240 -> 1953000495024 [dir=none]
	1953000495024 [label="running_var
 (1024)" fillcolor=orange]
	1953173172240 -> 1953000501024 [dir=none]
	1953000501024 [label="weight
 (1024)" fillcolor=orange]
	1953173172240 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173171616 -> 1953173172240
	1953173171616 -> 1953172293328 [dir=none]
	1953172293328 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173171616 -> 1953000495984 [dir=none]
	1953000495984 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173171616 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173170992 -> 1953173171616
	1953173170992 -> 1953172378848 [dir=none]
	1953172378848 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173170992 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173171232 -> 1953173170992
	1953173171232 -> 1953172300608 [dir=none]
	1953172300608 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173171232 -> 1953172378688 [dir=none]
	1953172378688 [label="result1
 (256)" fillcolor=orange]
	1953173171232 -> 1953172379088 [dir=none]
	1953172379088 [label="result2
 (256)" fillcolor=orange]
	1953173171232 -> 1953172378608 [dir=none]
	1953172378608 [label="result3
 (0)" fillcolor=orange]
	1953173171232 -> 1953000496304 [dir=none]
	1953000496304 [label="running_mean
 (256)" fillcolor=orange]
	1953173171232 -> 1953000496624 [dir=none]
	1953000496624 [label="running_var
 (256)" fillcolor=orange]
	1953173171232 -> 1953000498784 [dir=none]
	1953000498784 [label="weight
 (256)" fillcolor=orange]
	1953173171232 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173170560 -> 1953173171232
	1953173170560 -> 1953172293008 [dir=none]
	1953172293008 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173170560 -> 1953000498464 [dir=none]
	1953000498464 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173170560 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173169936 -> 1953173170560
	1953173169936 -> 1953172378768 [dir=none]
	1953172378768 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173169936 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173169168 -> 1953173169936
	1953173169168 -> 1953172293088 [dir=none]
	1953172293088 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173169168 -> 1953172379008 [dir=none]
	1953172379008 [label="result1
 (256)" fillcolor=orange]
	1953173169168 -> 1953172379408 [dir=none]
	1953172379408 [label="result2
 (256)" fillcolor=orange]
	1953173169168 -> 1953172378928 [dir=none]
	1953172378928 [label="result3
 (0)" fillcolor=orange]
	1953173169168 -> 1953000499424 [dir=none]
	1953000499424 [label="running_mean
 (256)" fillcolor=orange]
	1953173169168 -> 1953000498144 [dir=none]
	1953000498144 [label="running_var
 (256)" fillcolor=orange]
	1953173169168 -> 1953000500384 [dir=none]
	1953000500384 [label="weight
 (256)" fillcolor=orange]
	1953173169168 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173168496 -> 1953173169168
	1953173168496 -> 1953172293168 [dir=none]
	1953172293168 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173168496 -> 1953000500704 [dir=none]
	1953000500704 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173168496 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173173104 -> 1953173168496
	1953173173104 -> 1953172379168 [dir=none]
	1953172379168 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173173104 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173168064 -> 1953173173104
	1953173168064 [label="AddBackward0
------------
alpha: 1"]
	1953173167248 -> 1953173168064
	1953173167248 -> 1953172292848 [dir=none]
	1953172292848 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173167248 -> 1953172379488 [dir=none]
	1953172379488 [label="result1
 (1024)" fillcolor=orange]
	1953173167248 -> 1953172379328 [dir=none]
	1953172379328 [label="result2
 (1024)" fillcolor=orange]
	1953173167248 -> 1953172379248 [dir=none]
	1953172379248 [label="result3
 (0)" fillcolor=orange]
	1953173167248 -> 1953000503344 [dir=none]
	1953000503344 [label="running_mean
 (1024)" fillcolor=orange]
	1953173167248 -> 1953000504944 [dir=none]
	1953000504944 [label="running_var
 (1024)" fillcolor=orange]
	1953173167248 -> 1953000505184 [dir=none]
	1953000505184 [label="weight
 (1024)" fillcolor=orange]
	1953173167248 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173166624 -> 1953173167248
	1953173166624 -> 1953172292768 [dir=none]
	1953172292768 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173166624 -> 1953000504624 [dir=none]
	1953000504624 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173166624 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173166000 -> 1953173166624
	1953173166000 -> 1953172379808 [dir=none]
	1953172379808 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173166000 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173166240 -> 1953173166000
	1953173166240 -> 1953172292928 [dir=none]
	1953172292928 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173166240 -> 1953172379648 [dir=none]
	1953172379648 [label="result1
 (256)" fillcolor=orange]
	1953173166240 -> 1953172380048 [dir=none]
	1953172380048 [label="result2
 (256)" fillcolor=orange]
	1953173166240 -> 1953172379568 [dir=none]
	1953172379568 [label="result3
 (0)" fillcolor=orange]
	1953173166240 -> 1953000504704 [dir=none]
	1953000504704 [label="running_mean
 (256)" fillcolor=orange]
	1953173166240 -> 1953000505024 [dir=none]
	1953000505024 [label="running_var
 (256)" fillcolor=orange]
	1953173166240 -> 1953000504384 [dir=none]
	1953000504384 [label="weight
 (256)" fillcolor=orange]
	1953173166240 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173165568 -> 1953173166240
	1953173165568 -> 1953172305888 [dir=none]
	1953172305888 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173165568 -> 1953000505264 [dir=none]
	1953000505264 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173165568 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173164944 -> 1953173165568
	1953173164944 -> 1953172379728 [dir=none]
	1953172379728 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173164944 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173164176 -> 1953173164944
	1953173164176 -> 1953172292528 [dir=none]
	1953172292528 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173164176 -> 1953172379968 [dir=none]
	1953172379968 [label="result1
 (256)" fillcolor=orange]
	1953173164176 -> 1953172380368 [dir=none]
	1953172380368 [label="result2
 (256)" fillcolor=orange]
	1953173164176 -> 1953172379888 [dir=none]
	1953172379888 [label="result3
 (0)" fillcolor=orange]
	1953173164176 -> 1953000496144 [dir=none]
	1953000496144 [label="running_mean
 (256)" fillcolor=orange]
	1953173164176 -> 1953000503584 [dir=none]
	1953000503584 [label="running_var
 (256)" fillcolor=orange]
	1953173164176 -> 1953000503904 [dir=none]
	1953000503904 [label="weight
 (256)" fillcolor=orange]
	1953173164176 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173163504 -> 1953173164176
	1953173163504 -> 1953172292448 [dir=none]
	1953172292448 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173163504 -> 1953000504064 [dir=none]
	1953000504064 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173163504 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173168112 -> 1953173163504
	1953173168112 -> 1953172380128 [dir=none]
	1953172380128 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173168112 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173163072 -> 1953173168112
	1953173163072 [label="AddBackward0
------------
alpha: 1"]
	1953173162256 -> 1953173163072
	1953173162256 -> 1953172292608 [dir=none]
	1953172292608 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173162256 -> 1953172380448 [dir=none]
	1953172380448 [label="result1
 (1024)" fillcolor=orange]
	1953173162256 -> 1953172380288 [dir=none]
	1953172380288 [label="result2
 (1024)" fillcolor=orange]
	1953173162256 -> 1953172380208 [dir=none]
	1953172380208 [label="result3
 (0)" fillcolor=orange]
	1953173162256 -> 1953000502464 [dir=none]
	1953000502464 [label="running_mean
 (1024)" fillcolor=orange]
	1953173162256 -> 1953000502144 [dir=none]
	1953000502144 [label="running_var
 (1024)" fillcolor=orange]
	1953173162256 -> 1953000498864 [dir=none]
	1953000498864 [label="weight
 (1024)" fillcolor=orange]
	1953173162256 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173161632 -> 1953173162256
	1953173161632 -> 1953172292688 [dir=none]
	1953172292688 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173161632 -> 1953000499184 [dir=none]
	1953000499184 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173161632 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173161008 -> 1953173161632
	1953173161008 -> 1953172380768 [dir=none]
	1953172380768 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173161008 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173161248 -> 1953173161008
	1953173161248 -> 1953172292208 [dir=none]
	1953172292208 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173161248 -> 1953172380608 [dir=none]
	1953172380608 [label="result1
 (256)" fillcolor=orange]
	1953173161248 -> 1953172381008 [dir=none]
	1953172381008 [label="result2
 (256)" fillcolor=orange]
	1953173161248 -> 1953172380528 [dir=none]
	1953172380528 [label="result3
 (0)" fillcolor=orange]
	1953173161248 -> 1953000501584 [dir=none]
	1953000501584 [label="running_mean
 (256)" fillcolor=orange]
	1953173161248 -> 1953000501264 [dir=none]
	1953000501264 [label="running_var
 (256)" fillcolor=orange]
	1953173161248 -> 1953000501104 [dir=none]
	1953000501104 [label="weight
 (256)" fillcolor=orange]
	1953173161248 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173160576 -> 1953173161248
	1953173160576 -> 1953172292288 [dir=none]
	1953172292288 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173160576 -> 1953000501744 [dir=none]
	1953000501744 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173160576 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173175696 -> 1953173160576
	1953173175696 -> 1953172380688 [dir=none]
	1953172380688 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173175696 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173175840 -> 1953173175696
	1953173175840 -> 1953172292368 [dir=none]
	1953172292368 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173175840 -> 1953172380928 [dir=none]
	1953172380928 [label="result1
 (256)" fillcolor=orange]
	1953173175840 -> 1953172381328 [dir=none]
	1953172381328 [label="result2
 (256)" fillcolor=orange]
	1953173175840 -> 1953172380848 [dir=none]
	1953172380848 [label="result3
 (0)" fillcolor=orange]
	1953173175840 -> 1953000500304 [dir=none]
	1953000500304 [label="running_mean
 (256)" fillcolor=orange]
	1953173175840 -> 1953000500464 [dir=none]
	1953000500464 [label="running_var
 (256)" fillcolor=orange]
	1953173175840 -> 1953000499824 [dir=none]
	1953000499824 [label="weight
 (256)" fillcolor=orange]
	1953173175840 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173175456 -> 1953173175840
	1953173175456 -> 1953172292128 [dir=none]
	1953172292128 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173175456 -> 1953000499664 [dir=none]
	1953000499664 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173175456 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173163120 -> 1953173175456
	1953173163120 -> 1953172381088 [dir=none]
	1953172381088 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173163120 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173175264 -> 1953173163120
	1953173175264 [label="AddBackward0
------------
alpha: 1"]
	1953173174832 -> 1953173175264
	1953173174832 -> 1953172291968 [dir=none]
	1953172291968 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173174832 -> 1953172381408 [dir=none]
	1953172381408 [label="result1
 (1024)" fillcolor=orange]
	1953173174832 -> 1953172381248 [dir=none]
	1953172381248 [label="result2
 (1024)" fillcolor=orange]
	1953173174832 -> 1953172381168 [dir=none]
	1953172381168 [label="result3
 (0)" fillcolor=orange]
	1953173174832 -> 1954164382976 [dir=none]
	1954164382976 [label="running_mean
 (1024)" fillcolor=orange]
	1953173174832 -> 1953000498384 [dir=none]
	1953000498384 [label="running_var
 (1024)" fillcolor=orange]
	1953173174832 -> 1953000498704 [dir=none]
	1953000498704 [label="weight
 (1024)" fillcolor=orange]
	1953173174832 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173174544 -> 1953173174832
	1953173174544 -> 1953172292048 [dir=none]
	1953172292048 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173174544 -> 1953000498064 [dir=none]
	1953000498064 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173174544 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173174208 -> 1953173174544
	1953173174208 -> 1953172381728 [dir=none]
	1953172381728 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173174208 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173173872 -> 1953173174208
	1953173173872 -> 1953172291728 [dir=none]
	1953172291728 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173173872 -> 1953172381568 [dir=none]
	1953172381568 [label="result1
 (256)" fillcolor=orange]
	1953173173872 -> 1953172381968 [dir=none]
	1953172381968 [label="result2
 (256)" fillcolor=orange]
	1953173173872 -> 1953172381488 [dir=none]
	1953172381488 [label="result3
 (0)" fillcolor=orange]
	1953173173872 -> 1953000498224 [dir=none]
	1953000498224 [label="running_mean
 (256)" fillcolor=orange]
	1953173173872 -> 1953000497744 [dir=none]
	1953000497744 [label="running_var
 (256)" fillcolor=orange]
	1953173173872 -> 1953000497424 [dir=none]
	1953000497424 [label="weight
 (256)" fillcolor=orange]
	1953173173872 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173174016 -> 1953173173872
	1953173174016 -> 1953172291648 [dir=none]
	1953172291648 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173174016 -> 1953000497264 [dir=none]
	1953000497264 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173174016 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173173200 -> 1953173174016
	1953173173200 -> 1953172381648 [dir=none]
	1953172381648 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173173200 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173173344 -> 1953173173200
	1953173173344 -> 1953172291808 [dir=none]
	1953172291808 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173173344 -> 1953172381888 [dir=none]
	1953172381888 [label="result1
 (256)" fillcolor=orange]
	1953173173344 -> 1953172382288 [dir=none]
	1953172382288 [label="result2
 (256)" fillcolor=orange]
	1953173173344 -> 1953172381808 [dir=none]
	1953172381808 [label="result3
 (0)" fillcolor=orange]
	1953173173344 -> 1953000496064 [dir=none]
	1953000496064 [label="running_mean
 (256)" fillcolor=orange]
	1953173173344 -> 1953000496544 [dir=none]
	1953000496544 [label="running_var
 (256)" fillcolor=orange]
	1953173173344 -> 1953000495904 [dir=none]
	1953000495904 [label="weight
 (256)" fillcolor=orange]
	1953173173344 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173172960 -> 1953173173344
	1953173172960 -> 1953172291888 [dir=none]
	1953172291888 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173172960 -> 1953000495744 [dir=none]
	1953000495744 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173172960 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173175312 -> 1953173172960
	1953173175312 -> 1953172382048 [dir=none]
	1953172382048 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173175312 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173172768 -> 1953173175312
	1953173172768 [label="AddBackward0
------------
alpha: 1"]
	1953173172336 -> 1953173172768
	1953173172336 -> 1953172307648 [dir=none]
	1953172307648 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173172336 -> 1953172382368 [dir=none]
	1953172382368 [label="result1
 (1024)" fillcolor=orange]
	1953173172336 -> 1953172382208 [dir=none]
	1953172382208 [label="result2
 (1024)" fillcolor=orange]
	1953173172336 -> 1953172382128 [dir=none]
	1953172382128 [label="result3
 (0)" fillcolor=orange]
	1953173172336 -> 1953000494784 [dir=none]
	1953000494784 [label="running_mean
 (1024)" fillcolor=orange]
	1953173172336 -> 1953000495104 [dir=none]
	1953000495104 [label="running_var
 (1024)" fillcolor=orange]
	1953173172336 -> 1953000494464 [dir=none]
	1953000494464 [label="weight
 (1024)" fillcolor=orange]
	1953173172336 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173172048 -> 1953173172336
	1953173172048 -> 1953172307488 [dir=none]
	1953172307488 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173172048 -> 1953000494944 [dir=none]
	1953000494944 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173172048 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173171712 -> 1953173172048
	1953173171712 -> 1953172382688 [dir=none]
	1953172382688 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173171712 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173171376 -> 1953173171712
	1953173171376 -> 1953172307728 [dir=none]
	1953172307728 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173171376 -> 1953172382528 [dir=none]
	1953172382528 [label="result1
 (256)" fillcolor=orange]
	1953173171376 -> 1953172382928 [dir=none]
	1953172382928 [label="result2
 (256)" fillcolor=orange]
	1953173171376 -> 1953172382448 [dir=none]
	1953172382448 [label="result3
 (0)" fillcolor=orange]
	1953173171376 -> 1953000493184 [dir=none]
	1953000493184 [label="running_mean
 (256)" fillcolor=orange]
	1953173171376 -> 1953000492864 [dir=none]
	1953000492864 [label="running_var
 (256)" fillcolor=orange]
	1953173171376 -> 1953000494304 [dir=none]
	1953000494304 [label="weight
 (256)" fillcolor=orange]
	1953173171376 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173171520 -> 1953173171376
	1953173171520 -> 1953172307888 [dir=none]
	1953172307888 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173171520 -> 1953000493824 [dir=none]
	1953000493824 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173171520 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173170704 -> 1953173171520
	1953173170704 -> 1953172382608 [dir=none]
	1953172382608 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173170704 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173170848 -> 1953173170704
	1953173170848 -> 1953172307248 [dir=none]
	1953172307248 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173170848 -> 1953172382848 [dir=none]
	1953172382848 [label="result1
 (256)" fillcolor=orange]
	1953173170848 -> 1953172383248 [dir=none]
	1953172383248 [label="result2
 (256)" fillcolor=orange]
	1953173170848 -> 1953172382768 [dir=none]
	1953172382768 [label="result3
 (0)" fillcolor=orange]
	1953173170848 -> 1953000491664 [dir=none]
	1953000491664 [label="running_mean
 (256)" fillcolor=orange]
	1953173170848 -> 1953000491504 [dir=none]
	1953000491504 [label="running_var
 (256)" fillcolor=orange]
	1953173170848 -> 1953000491024 [dir=none]
	1953000491024 [label="weight
 (256)" fillcolor=orange]
	1953173170848 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173170464 -> 1953173170848
	1953173170464 -> 1953172307408 [dir=none]
	1953172307408 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173170464 -> 1953000491184 [dir=none]
	1953000491184 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173170464 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173172816 -> 1953173170464
	1953173172816 -> 1953172383008 [dir=none]
	1953172383008 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173172816 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173170272 -> 1953173172816
	1953173170272 [label="AddBackward0
------------
alpha: 1"]
	1953173169840 -> 1953173170272
	1953173169840 -> 1953172306928 [dir=none]
	1953172306928 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173169840 -> 1953172383328 [dir=none]
	1953172383328 [label="result1
 (1024)" fillcolor=orange]
	1953173169840 -> 1953172383168 [dir=none]
	1953172383168 [label="result2
 (1024)" fillcolor=orange]
	1953173169840 -> 1953172383088 [dir=none]
	1953172383088 [label="result3
 (0)" fillcolor=orange]
	1953173169840 -> 1953000490384 [dir=none]
	1953000490384 [label="running_mean
 (1024)" fillcolor=orange]
	1953173169840 -> 1953000490224 [dir=none]
	1953000490224 [label="running_var
 (1024)" fillcolor=orange]
	1953173169840 -> 1953000492224 [dir=none]
	1953000492224 [label="weight
 (1024)" fillcolor=orange]
	1953173169840 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173169552 -> 1953173169840
	1953173169552 -> 1953172306768 [dir=none]
	1953172306768 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173169552 -> 1953000491344 [dir=none]
	1953000491344 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173169552 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173169216 -> 1953173169552
	1953173169216 -> 1953172383648 [dir=none]
	1953172383648 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173169216 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173168880 -> 1953173169216
	1953173168880 -> 1953172307008 [dir=none]
	1953172307008 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173168880 -> 1953172383488 [dir=none]
	1953172383488 [label="result1
 (256)" fillcolor=orange]
	1953173168880 -> 1953172383968 [dir=none]
	1953172383968 [label="result2
 (256)" fillcolor=orange]
	1953173168880 -> 1953172383408 [dir=none]
	1953172383408 [label="result3
 (0)" fillcolor=orange]
	1953173168880 -> 1953000489584 [dir=none]
	1953000489584 [label="running_mean
 (256)" fillcolor=orange]
	1953173168880 -> 1953000489904 [dir=none]
	1953000489904 [label="running_var
 (256)" fillcolor=orange]
	1953173168880 -> 1953000489424 [dir=none]
	1953000489424 [label="weight
 (256)" fillcolor=orange]
	1953173168880 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173169024 -> 1953173168880
	1953173169024 -> 1953172307168 [dir=none]
	1953172307168 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173169024 -> 1953000489104 [dir=none]
	1953000489104 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173169024 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173168208 -> 1953173169024
	1953173168208 -> 1953172383568 [dir=none]
	1953172383568 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173168208 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173168352 -> 1953173168208
	1953173168352 -> 1953172306448 [dir=none]
	1953172306448 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173168352 -> 1953172383808 [dir=none]
	1953172383808 [label="result1
 (256)" fillcolor=orange]
	1953173168352 -> 1953172384608 [dir=none]
	1953172384608 [label="result2
 (256)" fillcolor=orange]
	1953173168352 -> 1953172383728 [dir=none]
	1953172383728 [label="result3
 (0)" fillcolor=orange]
	1953173168352 -> 1953000489664 [dir=none]
	1953000489664 [label="running_mean
 (256)" fillcolor=orange]
	1953173168352 -> 1953000497824 [dir=none]
	1953000497824 [label="running_var
 (256)" fillcolor=orange]
	1953173168352 -> 1953000489264 [dir=none]
	1953000489264 [label="weight
 (256)" fillcolor=orange]
	1953173168352 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173167968 -> 1953173168352
	1953173167968 -> 1953172306288 [dir=none]
	1953172306288 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173167968 -> 1953000504784 [dir=none]
	1953000504784 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173167968 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173170320 -> 1953173167968
	1953173170320 -> 1953172384048 [dir=none]
	1953172384048 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173170320 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173167776 -> 1953173170320
	1953173167776 [label="AddBackward0
------------
alpha: 1"]
	1953173167344 -> 1953173167776
	1953173167344 -> 1953172306528 [dir=none]
	1953172306528 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173167344 -> 1953172384368 [dir=none]
	1953172384368 [label="result1
 (1024)" fillcolor=orange]
	1953173167344 -> 1953172384208 [dir=none]
	1953172384208 [label="result2
 (1024)" fillcolor=orange]
	1953173167344 -> 1953172384448 [dir=none]
	1953172384448 [label="result3
 (0)" fillcolor=orange]
	1953173167344 -> 1953000431488 [dir=none]
	1953000431488 [label="running_mean
 (1024)" fillcolor=orange]
	1953173167344 -> 1953000431168 [dir=none]
	1953000431168 [label="running_var
 (1024)" fillcolor=orange]
	1953173167344 -> 1953000429568 [dir=none]
	1953000429568 [label="weight
 (1024)" fillcolor=orange]
	1953173167344 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173167056 -> 1953173167344
	1953173167056 -> 1953172306688 [dir=none]
	1953172306688 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173167056 -> 1953000430528 [dir=none]
	1953000430528 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173167056 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173166720 -> 1953173167056
	1953173166720 -> 1953172384688 [dir=none]
	1953172384688 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173166720 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173166384 -> 1953173166720
	1953173166384 -> 1953172306048 [dir=none]
	1953172306048 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173166384 -> 1953172384528 [dir=none]
	1953172384528 [label="result1
 (256)" fillcolor=orange]
	1953173166384 -> 1953172385248 [dir=none]
	1953172385248 [label="result2
 (256)" fillcolor=orange]
	1953173166384 -> 1953172384768 [dir=none]
	1953172384768 [label="result3
 (0)" fillcolor=orange]
	1953173166384 -> 1953000426368 [dir=none]
	1953000426368 [label="running_mean
 (256)" fillcolor=orange]
	1953173166384 -> 1953000431008 [dir=none]
	1953000431008 [label="running_var
 (256)" fillcolor=orange]
	1953173166384 -> 1953000434768 [dir=none]
	1953000434768 [label="weight
 (256)" fillcolor=orange]
	1953173166384 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173166528 -> 1953173166384
	1953173166528 -> 1953172305968 [dir=none]
	1953172305968 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173166528 -> 1953000431648 [dir=none]
	1953000431648 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173166528 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173165712 -> 1953173166528
	1953173165712 -> 1953172384928 [dir=none]
	1953172384928 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173165712 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173165856 -> 1953173165712
	1953173165856 -> 1953172306208 [dir=none]
	1953172306208 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173165856 -> 1953172384848 [dir=none]
	1953172384848 [label="result1
 (256)" fillcolor=orange]
	1953173165856 -> 1953172385568 [dir=none]
	1953172385568 [label="result2
 (256)" fillcolor=orange]
	1953173165856 -> 1953172385088 [dir=none]
	1953172385088 [label="result3
 (0)" fillcolor=orange]
	1953173165856 -> 1953000430048 [dir=none]
	1953000430048 [label="running_mean
 (256)" fillcolor=orange]
	1953173165856 -> 1953000429728 [dir=none]
	1953000429728 [label="running_var
 (256)" fillcolor=orange]
	1953173165856 -> 1953000435408 [dir=none]
	1953000435408 [label="weight
 (256)" fillcolor=orange]
	1953173165856 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173165472 -> 1953173165856
	1953173165472 -> 1953172296528 [dir=none]
	1953172296528 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173165472 -> 1953000432448 [dir=none]
	1953000432448 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173165472 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173167824 -> 1953173165472
	1953173167824 -> 1953172385008 [dir=none]
	1953172385008 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173167824 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173165280 -> 1953173167824
	1953173165280 [label="AddBackward0
------------
alpha: 1"]
	1953173164848 -> 1953173165280
	1953173164848 -> 1953172305568 [dir=none]
	1953172305568 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173164848 -> 1953172385328 [dir=none]
	1953172385328 [label="result1
 (1024)" fillcolor=orange]
	1953173164848 -> 1953172385168 [dir=none]
	1953172385168 [label="result2
 (1024)" fillcolor=orange]
	1953173164848 -> 1953172385408 [dir=none]
	1953172385408 [label="result3
 (0)" fillcolor=orange]
	1953173164848 -> 1953000425408 [dir=none]
	1953000425408 [label="running_mean
 (1024)" fillcolor=orange]
	1953173164848 -> 1953000433728 [dir=none]
	1953000433728 [label="running_var
 (1024)" fillcolor=orange]
	1953173164848 -> 1953000432768 [dir=none]
	1953000432768 [label="weight
 (1024)" fillcolor=orange]
	1953173164848 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173164560 -> 1953173164848
	1953173164560 -> 1953172305488 [dir=none]
	1953172305488 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173164560 -> 1953000429408 [dir=none]
	1953000429408 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173164560 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173164224 -> 1953173164560
	1953173164224 -> 1953172385648 [dir=none]
	1953172385648 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173164224 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173163888 -> 1953173164224
	1953173163888 -> 1953172305728 [dir=none]
	1953172305728 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173163888 -> 1953172385488 [dir=none]
	1953172385488 [label="result1
 (256)" fillcolor=orange]
	1953173163888 -> 1953172386208 [dir=none]
	1953172386208 [label="result2
 (256)" fillcolor=orange]
	1953173163888 -> 1953172385728 [dir=none]
	1953172385728 [label="result3
 (0)" fillcolor=orange]
	1953173163888 -> 1953000426688 [dir=none]
	1953000426688 [label="running_mean
 (256)" fillcolor=orange]
	1953173163888 -> 1953000424768 [dir=none]
	1953000424768 [label="running_var
 (256)" fillcolor=orange]
	1953173163888 -> 1953000423968 [dir=none]
	1953000423968 [label="weight
 (256)" fillcolor=orange]
	1953173163888 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173164032 -> 1953173163888
	1953173164032 -> 1953172305808 [dir=none]
	1953172305808 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173164032 -> 1953000427328 [dir=none]
	1953000427328 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173164032 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173163216 -> 1953173164032
	1953173163216 -> 1953172385888 [dir=none]
	1953172385888 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173163216 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173163360 -> 1953173163216
	1953173163360 -> 1953172305248 [dir=none]
	1953172305248 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173163360 -> 1953172385808 [dir=none]
	1953172385808 [label="result1
 (256)" fillcolor=orange]
	1953173163360 -> 1953172386528 [dir=none]
	1953172386528 [label="result2
 (256)" fillcolor=orange]
	1953173163360 -> 1953172386048 [dir=none]
	1953172386048 [label="result3
 (0)" fillcolor=orange]
	1953173163360 -> 1953000439328 [dir=none]
	1953000439328 [label="running_mean
 (256)" fillcolor=orange]
	1953173163360 -> 1953000436368 [dir=none]
	1953000436368 [label="running_var
 (256)" fillcolor=orange]
	1953173163360 -> 1953000437008 [dir=none]
	1953000437008 [label="weight
 (256)" fillcolor=orange]
	1953173163360 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173162976 -> 1953173163360
	1953173162976 -> 1953172305088 [dir=none]
	1953172305088 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173162976 -> 1953000438368 [dir=none]
	1953000438368 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173162976 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173165328 -> 1953173162976
	1953173165328 -> 1953172385968 [dir=none]
	1953172385968 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173165328 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173162784 -> 1953173165328
	1953173162784 [label="AddBackward0
------------
alpha: 1"]
	1953173162352 -> 1953173162784
	1953173162352 -> 1953172305328 [dir=none]
	1953172305328 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173162352 -> 1953172386288 [dir=none]
	1953172386288 [label="result1
 (1024)" fillcolor=orange]
	1953173162352 -> 1953172386128 [dir=none]
	1953172386128 [label="result2
 (1024)" fillcolor=orange]
	1953173162352 -> 1953172386368 [dir=none]
	1953172386368 [label="result3
 (0)" fillcolor=orange]
	1953173162352 -> 1953000424288 [dir=none]
	1953000424288 [label="running_mean
 (1024)" fillcolor=orange]
	1953173162352 -> 1953000425248 [dir=none]
	1953000425248 [label="running_var
 (1024)" fillcolor=orange]
	1953173162352 -> 1953000439008 [dir=none]
	1953000439008 [label="weight
 (1024)" fillcolor=orange]
	1953173162352 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173162064 -> 1953173162352
	1953173162064 -> 1953172305008 [dir=none]
	1953172305008 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173162064 -> 1953000435728 [dir=none]
	1953000435728 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173162064 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173161728 -> 1953173162064
	1953173161728 -> 1953172386608 [dir=none]
	1953172386608 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173161728 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173161392 -> 1953173161728
	1953173161392 -> 1953172304768 [dir=none]
	1953172304768 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173161392 -> 1953172386448 [dir=none]
	1953172386448 [label="result1
 (256)" fillcolor=orange]
	1953173161392 -> 1953172387168 [dir=none]
	1953172387168 [label="result2
 (256)" fillcolor=orange]
	1953173161392 -> 1953172386688 [dir=none]
	1953172386688 [label="result3
 (0)" fillcolor=orange]
	1953173161392 -> 1953000670608 [dir=none]
	1953000670608 [label="running_mean
 (256)" fillcolor=orange]
	1953173161392 -> 1953000426528 [dir=none]
	1953000426528 [label="running_var
 (256)" fillcolor=orange]
	1953173161392 -> 1953000426848 [dir=none]
	1953000426848 [label="weight
 (256)" fillcolor=orange]
	1953173161392 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173161536 -> 1953173161392
	1953173161536 -> 1953172304848 [dir=none]
	1953172304848 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173161536 -> 1953000427568 [dir=none]
	1953000427568 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173161536 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173160720 -> 1953173161536
	1953173160720 -> 1953172386848 [dir=none]
	1953172386848 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173160720 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173160864 -> 1953173160720
	1953173160864 -> 1953172303008 [dir=none]
	1953172303008 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173160864 -> 1953172386768 [dir=none]
	1953172386768 [label="result1
 (256)" fillcolor=orange]
	1953173160864 -> 1953172387488 [dir=none]
	1953172387488 [label="result2
 (256)" fillcolor=orange]
	1953173160864 -> 1953172387008 [dir=none]
	1953172387008 [label="result3
 (0)" fillcolor=orange]
	1953173160864 -> 1953000438528 [dir=none]
	1953000438528 [label="running_mean
 (256)" fillcolor=orange]
	1953173160864 -> 1953000425168 [dir=none]
	1953000425168 [label="running_var
 (256)" fillcolor=orange]
	1953173160864 -> 1953000428528 [dir=none]
	1953000428528 [label="weight
 (256)" fillcolor=orange]
	1953173160864 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173160480 -> 1953173160864
	1953173160480 -> 1953172304368 [dir=none]
	1953172304368 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173160480 -> 1953000428208 [dir=none]
	1953000428208 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173160480 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173162832 -> 1953173160480
	1953173162832 -> 1953172386928 [dir=none]
	1953172386928 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173162832 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173160288 -> 1953173162832
	1953173160288 [label="AddBackward0
------------
alpha: 1"]
	1953173160336 -> 1953173160288
	1953173160336 -> 1953172304288 [dir=none]
	1953172304288 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173160336 -> 1953172387248 [dir=none]
	1953172387248 [label="result1
 (1024)" fillcolor=orange]
	1953173160336 -> 1953172387088 [dir=none]
	1953172387088 [label="result2
 (1024)" fillcolor=orange]
	1953173160336 -> 1953172387328 [dir=none]
	1953172387328 [label="result3
 (0)" fillcolor=orange]
	1953173160336 -> 1953000736864 [dir=none]
	1953000736864 [label="running_mean
 (1024)" fillcolor=orange]
	1953173160336 -> 1953000436608 [dir=none]
	1953000436608 [label="running_var
 (1024)" fillcolor=orange]
	1953173160336 -> 1953000436128 [dir=none]
	1953000436128 [label="weight
 (1024)" fillcolor=orange]
	1953173160336 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173126352 -> 1953173160336
	1953173126352 -> 1953172304528 [dir=none]
	1953172304528 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173126352 -> 1953000430208 [dir=none]
	1953000430208 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173126352 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173125728 -> 1953173126352
	1953173125728 -> 1953172387568 [dir=none]
	1953172387568 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173125728 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173125056 -> 1953173125728
	1953173125056 -> 1953172304608 [dir=none]
	1953172304608 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173125056 -> 1953172387408 [dir=none]
	1953172387408 [label="result1
 (256)" fillcolor=orange]
	1953173125056 -> 1953172387888 [dir=none]
	1953172387888 [label="result2
 (256)" fillcolor=orange]
	1953173125056 -> 1953172387648 [dir=none]
	1953172387648 [label="result3
 (0)" fillcolor=orange]
	1953173125056 -> 1953000747424 [dir=none]
	1953000747424 [label="running_mean
 (256)" fillcolor=orange]
	1953173125056 -> 1953000747824 [dir=none]
	1953000747824 [label="running_var
 (256)" fillcolor=orange]
	1953173125056 -> 1953000437408 [dir=none]
	1953000437408 [label="weight
 (256)" fillcolor=orange]
	1953173125056 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173125296 -> 1953173125056
	1953173125296 -> 1953172304128 [dir=none]
	1953172304128 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173125296 -> 1953000436528 [dir=none]
	1953000436528 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173125296 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173124672 -> 1953173125296
	1953173124672 -> 1953172387808 [dir=none]
	1953172387808 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173124672 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173124000 -> 1953173124672
	1953173124000 -> 1953172303888 [dir=none]
	1953172303888 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173124000 -> 1953172387728 [dir=none]
	1953172387728 [label="result1
 (256)" fillcolor=orange]
	1953173124000 -> 1953172388688 [dir=none]
	1953172388688 [label="result2
 (256)" fillcolor=orange]
	1953173124000 -> 1953172387968 [dir=none]
	1953172387968 [label="result3
 (0)" fillcolor=orange]
	1953173124000 -> 1953000739984 [dir=none]
	1953000739984 [label="running_mean
 (256)" fillcolor=orange]
	1953173124000 -> 1953000747264 [dir=none]
	1953000747264 [label="running_var
 (256)" fillcolor=orange]
	1953173124000 -> 1953000745424 [dir=none]
	1953000745424 [label="weight
 (256)" fillcolor=orange]
	1953173124000 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173123232 -> 1953173124000
	1953173123232 -> 1953172304048 [dir=none]
	1953172304048 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173123232 -> 1953000747584 [dir=none]
	1953000747584 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173123232 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173160096 -> 1953173123232
	1953173160096 -> 1953172388368 [dir=none]
	1953172388368 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173160096 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173122800 -> 1953173160096
	1953173122800 [label="AddBackward0
------------
alpha: 1"]
	1953173121984 -> 1953173122800
	1953173121984 -> 1953172303648 [dir=none]
	1953172303648 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173121984 -> 1953172389168 [dir=none]
	1953172389168 [label="result1
 (1024)" fillcolor=orange]
	1953173121984 -> 1953172388528 [dir=none]
	1953172388528 [label="result2
 (1024)" fillcolor=orange]
	1953173121984 -> 1953172388768 [dir=none]
	1953172388768 [label="result3
 (0)" fillcolor=orange]
	1953173121984 -> 1953000738944 [dir=none]
	1953000738944 [label="running_mean
 (1024)" fillcolor=orange]
	1953173121984 -> 1953000739424 [dir=none]
	1953000739424 [label="running_var
 (1024)" fillcolor=orange]
	1953173121984 -> 1953000737984 [dir=none]
	1953000737984 [label="weight
 (1024)" fillcolor=orange]
	1953173121984 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173121360 -> 1953173121984
	1953173121360 -> 1953172303568 [dir=none]
	1953172303568 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173121360 -> 1953000738624 [dir=none]
	1953000738624 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173121360 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173120736 -> 1953173121360
	1953173120736 -> 1953172389488 [dir=none]
	1953172389488 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173120736 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173120064 -> 1953173120736
	1953173120064 -> 1953172303808 [dir=none]
	1953172303808 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173120064 -> 1953172389328 [dir=none]
	1953172389328 [label="result1
 (256)" fillcolor=orange]
	1953173120064 -> 1953172374048 [dir=none]
	1953172374048 [label="result2
 (256)" fillcolor=orange]
	1953173120064 -> 1953172389568 [dir=none]
	1953172389568 [label="result3
 (0)" fillcolor=orange]
	1953173120064 -> 1953000749184 [dir=none]
	1953000749184 [label="running_mean
 (256)" fillcolor=orange]
	1953173120064 -> 1953000749504 [dir=none]
	1953000749504 [label="running_var
 (256)" fillcolor=orange]
	1953173120064 -> 1953000748464 [dir=none]
	1953000748464 [label="weight
 (256)" fillcolor=orange]
	1953173120064 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173120304 -> 1953173120064
	1953173120304 -> 1953172298928 [dir=none]
	1953172298928 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173120304 -> 1953000734864 [dir=none]
	1953000734864 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173120304 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173119680 -> 1953173120304
	1953173119680 -> 1953172389648 [dir=none]
	1953172389648 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173119680 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173119008 -> 1953173119680
	1953173119008 -> 1953172303168 [dir=none]
	1953172303168 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173119008 -> 1953172389808 [dir=none]
	1953172389808 [label="result1
 (256)" fillcolor=orange]
	1953173119008 -> 1953172313872 [dir=none]
	1953172313872 [label="result2
 (256)" fillcolor=orange]
	1953173119008 -> 1953172324272 [dir=none]
	1953172324272 [label="result3
 (0)" fillcolor=orange]
	1953173119008 -> 1953000748304 [dir=none]
	1953000748304 [label="running_mean
 (256)" fillcolor=orange]
	1953173119008 -> 1953000747664 [dir=none]
	1953000747664 [label="running_var
 (256)" fillcolor=orange]
	1953173119008 -> 1953000735504 [dir=none]
	1953000735504 [label="weight
 (256)" fillcolor=orange]
	1953173119008 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173118240 -> 1953173119008
	1953173118240 -> 1953172303088 [dir=none]
	1953172303088 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173118240 -> 1953000747744 [dir=none]
	1953000747744 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173118240 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173121936 -> 1953173118240
	1953173121936 -> 1953172308032 [dir=none]
	1953172308032 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173121936 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173117808 -> 1953173121936
	1953173117808 [label="AddBackward0
------------
alpha: 1"]
	1953173116992 -> 1953173117808
	1953173116992 -> 1953172303328 [dir=none]
	1953172303328 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173116992 -> 1953172308592 [dir=none]
	1953172308592 [label="result1
 (1024)" fillcolor=orange]
	1953173116992 -> 1953172308512 [dir=none]
	1953172308512 [label="result2
 (1024)" fillcolor=orange]
	1953173116992 -> 1953172308432 [dir=none]
	1953172308432 [label="result3
 (0)" fillcolor=orange]
	1953173116992 -> 1953000743344 [dir=none]
	1953000743344 [label="running_mean
 (1024)" fillcolor=orange]
	1953173116992 -> 1953000748224 [dir=none]
	1953000748224 [label="running_var
 (1024)" fillcolor=orange]
	1953173116992 -> 1953000748944 [dir=none]
	1953000748944 [label="weight
 (1024)" fillcolor=orange]
	1953173116992 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173116368 -> 1953173116992
	1953173116368 -> 1953172303408 [dir=none]
	1953172303408 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173116368 -> 1953000748064 [dir=none]
	1953000748064 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173116368 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173115744 -> 1953173116368
	1953173115744 -> 1953172308272 [dir=none]
	1953172308272 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173115744 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173115072 -> 1953173115744
	1953173115072 -> 1953172302688 [dir=none]
	1953172302688 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173115072 -> 1953172308912 [dir=none]
	1953172308912 [label="result1
 (256)" fillcolor=orange]
	1953173115072 -> 1953172308672 [dir=none]
	1953172308672 [label="result2
 (256)" fillcolor=orange]
	1953173115072 -> 1953172308752 [dir=none]
	1953172308752 [label="result3
 (0)" fillcolor=orange]
	1953173115072 -> 1953000747984 [dir=none]
	1953000747984 [label="running_mean
 (256)" fillcolor=orange]
	1953173115072 -> 1953000741744 [dir=none]
	1953000741744 [label="running_var
 (256)" fillcolor=orange]
	1953173115072 -> 1953000749024 [dir=none]
	1953000749024 [label="weight
 (256)" fillcolor=orange]
	1953173115072 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173115312 -> 1953173115072
	1953173115312 -> 1953172302608 [dir=none]
	1953172302608 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173115312 -> 1953000750544 [dir=none]
	1953000750544 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173115312 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173114688 -> 1953173115312
	1953173114688 -> 1953172308192 [dir=none]
	1953172308192 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173114688 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173114016 -> 1953173114688
	1953173114016 -> 1953172302848 [dir=none]
	1953172302848 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173114016 -> 1953172309232 [dir=none]
	1953172309232 [label="result1
 (256)" fillcolor=orange]
	1953173114016 -> 1953172309152 [dir=none]
	1953172309152 [label="result2
 (256)" fillcolor=orange]
	1953173114016 -> 1953172308992 [dir=none]
	1953172308992 [label="result3
 (0)" fillcolor=orange]
	1953173114016 -> 1953000746384 [dir=none]
	1953000746384 [label="running_mean
 (256)" fillcolor=orange]
	1953173114016 -> 1953000750864 [dir=none]
	1953000750864 [label="running_var
 (256)" fillcolor=orange]
	1953173114016 -> 1953000746144 [dir=none]
	1953000746144 [label="weight
 (256)" fillcolor=orange]
	1953173114016 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173113248 -> 1953173114016
	1953173113248 -> 1953172302928 [dir=none]
	1953172302928 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173113248 -> 1953000737584 [dir=none]
	1953000737584 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173113248 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173116944 -> 1953173113248
	1953173116944 -> 1953172309392 [dir=none]
	1953172309392 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173116944 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173112816 -> 1953173116944
	1953173112816 [label="AddBackward0
------------
alpha: 1"]
	1953173112000 -> 1953173112816
	1953173112000 -> 1953172302208 [dir=none]
	1953172302208 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173112000 -> 1953172309472 [dir=none]
	1953172309472 [label="result1
 (1024)" fillcolor=orange]
	1953173112000 -> 1953172309632 [dir=none]
	1953172309632 [label="result2
 (1024)" fillcolor=orange]
	1953173112000 -> 1953172310112 [dir=none]
	1953172310112 [label="result3
 (0)" fillcolor=orange]
	1953173112000 -> 1953000744784 [dir=none]
	1953000744784 [label="running_mean
 (1024)" fillcolor=orange]
	1953173112000 -> 1953000738704 [dir=none]
	1953000738704 [label="running_var
 (1024)" fillcolor=orange]
	1953173112000 -> 1953000749904 [dir=none]
	1953000749904 [label="weight
 (1024)" fillcolor=orange]
	1953173112000 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173111376 -> 1953173112000
	1953173111376 -> 1953172302128 [dir=none]
	1953172302128 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173111376 -> 1953000744864 [dir=none]
	1953000744864 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173111376 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173110944 -> 1953173111376
	1953173110944 -> 1953172309712 [dir=none]
	1953172309712 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173110944 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173126640 -> 1953173110944
	1953173126640 -> 1953172302368 [dir=none]
	1953172302368 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173126640 -> 1953172309872 [dir=none]
	1953172309872 [label="result1
 (256)" fillcolor=orange]
	1953173126640 -> 1953172310352 [dir=none]
	1953172310352 [label="result2
 (256)" fillcolor=orange]
	1953173126640 -> 1953172310432 [dir=none]
	1953172310432 [label="result3
 (0)" fillcolor=orange]
	1953173126640 -> 1953000740064 [dir=none]
	1953000740064 [label="running_mean
 (256)" fillcolor=orange]
	1953173126640 -> 1953000746224 [dir=none]
	1953000746224 [label="running_var
 (256)" fillcolor=orange]
	1953173126640 -> 1953000735824 [dir=none]
	1953000735824 [label="weight
 (256)" fillcolor=orange]
	1953173126640 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173126784 -> 1953173126640
	1953173126784 -> 1953172302448 [dir=none]
	1953172302448 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173126784 -> 1953000735584 [dir=none]
	1953000735584 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173126784 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173126448 -> 1953173126784
	1953173126448 -> 1953172309952 [dir=none]
	1953172309952 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173126448 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173126112 -> 1953173126448
	1953173126112 -> 1953172301728 [dir=none]
	1953172301728 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173126112 -> 1953172310672 [dir=none]
	1953172310672 [label="result1
 (256)" fillcolor=orange]
	1953173126112 -> 1953172310832 [dir=none]
	1953172310832 [label="result2
 (256)" fillcolor=orange]
	1953173126112 -> 1953172310592 [dir=none]
	1953172310592 [label="result3
 (0)" fillcolor=orange]
	1953173126112 -> 1953000737024 [dir=none]
	1953000737024 [label="running_mean
 (256)" fillcolor=orange]
	1953173126112 -> 1953000740544 [dir=none]
	1953000740544 [label="running_var
 (256)" fillcolor=orange]
	1953173126112 -> 1953000750704 [dir=none]
	1953000750704 [label="weight
 (256)" fillcolor=orange]
	1953173126112 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173126256 -> 1953173126112
	1953173126256 -> 1953172301648 [dir=none]
	1953172301648 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173126256 -> 1953000736224 [dir=none]
	1953000736224 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173126256 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173111952 -> 1953173126256
	1953173111952 -> 1953172310192 [dir=none]
	1953172310192 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173111952 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173125536 -> 1953173111952
	1953173125536 [label="AddBackward0
------------
alpha: 1"]
	1953173125632 -> 1953173125536
	1953173125632 -> 1953172301888 [dir=none]
	1953172301888 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173125632 -> 1953172311312 [dir=none]
	1953172311312 [label="result1
 (1024)" fillcolor=orange]
	1953173125632 -> 1953172311152 [dir=none]
	1953172311152 [label="result2
 (1024)" fillcolor=orange]
	1953173125632 -> 1953172310912 [dir=none]
	1953172310912 [label="result3
 (0)" fillcolor=orange]
	1953173125632 -> 1953000745344 [dir=none]
	1953000745344 [label="running_mean
 (1024)" fillcolor=orange]
	1953173125632 -> 1953000739664 [dir=none]
	1953000739664 [label="running_var
 (1024)" fillcolor=orange]
	1953173125632 -> 1953000736064 [dir=none]
	1953000736064 [label="weight
 (1024)" fillcolor=orange]
	1953173125632 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173124816 -> 1953173125632
	1953173124816 -> 1953172301968 [dir=none]
	1953172301968 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173124816 -> 1953000735744 [dir=none]
	1953000735744 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173124816 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173125008 -> 1953173124816
	1953173125008 -> 1953172311792 [dir=none]
	1953172311792 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173125008 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173124144 -> 1953173125008
	1953173124144 -> 1953172301248 [dir=none]
	1953172301248 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173124144 -> 1953172311632 [dir=none]
	1953172311632 [label="result1
 (256)" fillcolor=orange]
	1953173124144 -> 1953172311552 [dir=none]
	1953172311552 [label="result2
 (256)" fillcolor=orange]
	1953173124144 -> 1953172311392 [dir=none]
	1953172311392 [label="result3
 (0)" fillcolor=orange]
	1953173124144 -> 1953000739184 [dir=none]
	1953000739184 [label="running_mean
 (256)" fillcolor=orange]
	1953173124144 -> 1953000739344 [dir=none]
	1953000739344 [label="running_var
 (256)" fillcolor=orange]
	1953173124144 -> 1953000750304 [dir=none]
	1953000750304 [label="weight
 (256)" fillcolor=orange]
	1953173124144 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173124288 -> 1953173124144
	1953173124288 -> 1953172301168 [dir=none]
	1953172301168 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173124288 -> 1953000739824 [dir=none]
	1953000739824 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173124288 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173123952 -> 1953173124288
	1953173123952 -> 1953172311072 [dir=none]
	1953172311072 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173123952 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173123616 -> 1953173123952
	1953173123616 -> 1953172301408 [dir=none]
	1953172301408 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173123616 -> 1953172311872 [dir=none]
	1953172311872 [label="result1
 (256)" fillcolor=orange]
	1953173123616 -> 1953172312592 [dir=none]
	1953172312592 [label="result2
 (256)" fillcolor=orange]
	1953173123616 -> 1953172312032 [dir=none]
	1953172312032 [label="result3
 (0)" fillcolor=orange]
	1953173123616 -> 1953000744544 [dir=none]
	1953000744544 [label="running_mean
 (256)" fillcolor=orange]
	1953173123616 -> 1953000744464 [dir=none]
	1953000744464 [label="running_var
 (256)" fillcolor=orange]
	1953173123616 -> 1953000740304 [dir=none]
	1953000740304 [label="weight
 (256)" fillcolor=orange]
	1953173123616 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173123760 -> 1953173123616
	1953173123760 -> 1953172301488 [dir=none]
	1953172301488 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173123760 -> 1953000741504 [dir=none]
	1953000741504 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173123760 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173125584 -> 1953173123760
	1953173125584 -> 1953172312112 [dir=none]
	1953172312112 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173125584 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173123040 -> 1953173125584
	1953173123040 [label="AddBackward0
------------
alpha: 1"]
	1953173123136 -> 1953173123040
	1953173123136 -> 1953172300768 [dir=none]
	1953172300768 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173123136 -> 1953172312512 [dir=none]
	1953172312512 [label="result1
 (1024)" fillcolor=orange]
	1953173123136 -> 1953172312272 [dir=none]
	1953172312272 [label="result2
 (1024)" fillcolor=orange]
	1953173123136 -> 1953172312352 [dir=none]
	1953172312352 [label="result3
 (0)" fillcolor=orange]
	1953173123136 -> 1953000740464 [dir=none]
	1953000740464 [label="running_mean
 (1024)" fillcolor=orange]
	1953173123136 -> 1953000736544 [dir=none]
	1953000736544 [label="running_var
 (1024)" fillcolor=orange]
	1953173123136 -> 1953000745664 [dir=none]
	1953000745664 [label="weight
 (1024)" fillcolor=orange]
	1953173123136 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173122320 -> 1953173123136
	1953173122320 -> 1953172300688 [dir=none]
	1953172300688 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173122320 -> 1953000741984 [dir=none]
	1953000741984 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173122320 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173122512 -> 1953173122320
	1953173122512 -> 1953172312992 [dir=none]
	1953172312992 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173122512 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173121648 -> 1953173122512
	1953173121648 -> 1953172300928 [dir=none]
	1953172300928 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173121648 -> 1953172312752 [dir=none]
	1953172312752 [label="result1
 (256)" fillcolor=orange]
	1953173121648 -> 1953172313472 [dir=none]
	1953172313472 [label="result2
 (256)" fillcolor=orange]
	1953173121648 -> 1953172312832 [dir=none]
	1953172312832 [label="result3
 (0)" fillcolor=orange]
	1953173121648 -> 1953000741104 [dir=none]
	1953000741104 [label="running_mean
 (256)" fillcolor=orange]
	1953173121648 -> 1953000740624 [dir=none]
	1953000740624 [label="running_var
 (256)" fillcolor=orange]
	1953173121648 -> 1953000737744 [dir=none]
	1953000737744 [label="weight
 (256)" fillcolor=orange]
	1953173121648 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173121792 -> 1953173121648
	1953173121792 -> 1953172300448 [dir=none]
	1953172300448 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173121792 -> 1953000738144 [dir=none]
	1953000738144 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173121792 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173121456 -> 1953173121792
	1953173121456 -> 1953172313072 [dir=none]
	1953172313072 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173121456 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173121120 -> 1953173121456
	1953173121120 -> 1953172301008 [dir=none]
	1953172301008 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173121120 -> 1953172313312 [dir=none]
	1953172313312 [label="result1
 (256)" fillcolor=orange]
	1953173121120 -> 1953172313712 [dir=none]
	1953172313712 [label="result2
 (256)" fillcolor=orange]
	1953173121120 -> 1953172313792 [dir=none]
	1953172313792 [label="result3
 (0)" fillcolor=orange]
	1953173121120 -> 1953000740944 [dir=none]
	1953000740944 [label="running_mean
 (256)" fillcolor=orange]
	1953173121120 -> 1953000741184 [dir=none]
	1953000741184 [label="running_var
 (256)" fillcolor=orange]
	1953173121120 -> 1953000740704 [dir=none]
	1953000740704 [label="weight
 (256)" fillcolor=orange]
	1953173121120 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173121264 -> 1953173121120
	1953173121264 -> 1953172300528 [dir=none]
	1953172300528 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173121264 -> 1953000744704 [dir=none]
	1953000744704 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	1953173121264 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173123088 -> 1953173121264
	1953173123088 -> 1953172313232 [dir=none]
	1953172313232 [label="result
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173123088 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173120544 -> 1953173123088
	1953173120544 [label="AddBackward0
------------
alpha: 1"]
	1953173120640 -> 1953173120544
	1953173120640 -> 1953172299328 [dir=none]
	1953172299328 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173120640 -> 1953172313552 [dir=none]
	1953172313552 [label="result1
 (1024)" fillcolor=orange]
	1953173120640 -> 1953172314032 [dir=none]
	1953172314032 [label="result2
 (1024)" fillcolor=orange]
	1953173120640 -> 1953172313952 [dir=none]
	1953172313952 [label="result3
 (0)" fillcolor=orange]
	1953173120640 -> 1953000744624 [dir=none]
	1953000744624 [label="running_mean
 (1024)" fillcolor=orange]
	1953173120640 -> 1953000743184 [dir=none]
	1953000743184 [label="running_var
 (1024)" fillcolor=orange]
	1953173120640 -> 1953000742944 [dir=none]
	1953000742944 [label="weight
 (1024)" fillcolor=orange]
	1953173120640 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173119824 -> 1953173120640
	1953173119824 -> 1953172299488 [dir=none]
	1953172299488 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173119824 -> 1953000743104 [dir=none]
	1953000743104 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	1953173119824 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173120016 -> 1953173119824
	1953173120016 -> 1953172314672 [dir=none]
	1953172314672 [label="result
 (1, 256, 21, 21)" fillcolor=orange]
	1953173120016 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173119152 -> 1953173120016
	1953173119152 -> 1953172300048 [dir=none]
	1953172300048 [label="input
 (1, 256, 21, 21)" fillcolor=orange]
	1953173119152 -> 1953172314512 [dir=none]
	1953172314512 [label="result1
 (256)" fillcolor=orange]
	1953173119152 -> 1953172314432 [dir=none]
	1953172314432 [label="result2
 (256)" fillcolor=orange]
	1953173119152 -> 1953172314272 [dir=none]
	1953172314272 [label="result3
 (0)" fillcolor=orange]
	1953173119152 -> 1953000605712 [dir=none]
	1953000605712 [label="running_mean
 (256)" fillcolor=orange]
	1953173119152 -> 1953000743264 [dir=none]
	1953000743264 [label="running_var
 (256)" fillcolor=orange]
	1953173119152 -> 1953000739584 [dir=none]
	1953000739584 [label="weight
 (256)" fillcolor=orange]
	1953173119152 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173119344 -> 1953173119152
	1953173119344 -> 1953172299248 [dir=none]
	1953172299248 [label="input
 (1, 256, 42, 42)" fillcolor=orange]
	1953173119344 -> 1953000743424 [dir=none]
	1953000743424 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	1953173119344 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	1953173118528 -> 1953173119344
	1953173118528 -> 1953172314192 [dir=none]
	1953172314192 [label="result
 (1, 256, 42, 42)" fillcolor=orange]
	1953173118528 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173118672 -> 1953173118528
	1953173118672 -> 1953172299008 [dir=none]
	1953172299008 [label="input
 (1, 256, 42, 42)" fillcolor=orange]
	1953173118672 -> 1953172314992 [dir=none]
	1953172314992 [label="result1
 (256)" fillcolor=orange]
	1953173118672 -> 1953172314912 [dir=none]
	1953172314912 [label="result2
 (256)" fillcolor=orange]
	1953173118672 -> 1953172314752 [dir=none]
	1953172314752 [label="result3
 (0)" fillcolor=orange]
	1953173118672 -> 1953000738864 [dir=none]
	1953000738864 [label="running_mean
 (256)" fillcolor=orange]
	1953173118672 -> 1953000746944 [dir=none]
	1953000746944 [label="running_var
 (256)" fillcolor=orange]
	1953173118672 -> 1953000746864 [dir=none]
	1953000746864 [label="weight
 (256)" fillcolor=orange]
	1953173118672 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173118288 -> 1953173118672
	1953173118288 -> 1953172299088 [dir=none]
	1953172299088 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1953173118288 -> 1953000749264 [dir=none]
	1953000749264 [label="weight
 (256, 512, 1, 1)" fillcolor=orange]
	1953173118288 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173118000 -> 1953173118288
	1953173118000 -> 1953172315152 [dir=none]
	1953172315152 [label="result
 (1, 512, 42, 42)" fillcolor=orange]
	1953173118000 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173118144 -> 1953173118000
	1953173118144 [label="AddBackward0
------------
alpha: 1"]
	1953173117712 -> 1953173118144
	1953173117712 -> 1953172298848 [dir=none]
	1953172298848 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1953173117712 -> 1953172308352 [dir=none]
	1953172308352 [label="result1
 (512)" fillcolor=orange]
	1953173117712 -> 1953172315392 [dir=none]
	1953172315392 [label="result2
 (512)" fillcolor=orange]
	1953173117712 -> 1953172315232 [dir=none]
	1953172315232 [label="result3
 (0)" fillcolor=orange]
	1953173117712 -> 1953000742384 [dir=none]
	1953000742384 [label="running_mean
 (512)" fillcolor=orange]
	1953173117712 -> 1953000744384 [dir=none]
	1953000744384 [label="running_var
 (512)" fillcolor=orange]
	1953173117712 -> 1953000743984 [dir=none]
	1953000743984 [label="weight
 (512)" fillcolor=orange]
	1953173117712 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173117424 -> 1953173117712
	1953173117424 -> 1953172298608 [dir=none]
	1953172298608 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1953173117424 -> 1953000735424 [dir=none]
	1953000735424 [label="weight
 (512, 128, 1, 1)" fillcolor=orange]
	1953173117424 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173117088 -> 1953173117424
	1953173117088 -> 1953172315552 [dir=none]
	1953172315552 [label="result
 (1, 128, 42, 42)" fillcolor=orange]
	1953173117088 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173116752 -> 1953173117088
	1953173116752 -> 1953172298768 [dir=none]
	1953172298768 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1953173116752 -> 1953172315472 [dir=none]
	1953172315472 [label="result1
 (128)" fillcolor=orange]
	1953173116752 -> 1953172315712 [dir=none]
	1953172315712 [label="result2
 (128)" fillcolor=orange]
	1953173116752 -> 1953172308112 [dir=none]
	1953172308112 [label="result3
 (0)" fillcolor=orange]
	1953173116752 -> 1953000742544 [dir=none]
	1953000742544 [label="running_mean
 (128)" fillcolor=orange]
	1953173116752 -> 1953000743024 [dir=none]
	1953000743024 [label="running_var
 (128)" fillcolor=orange]
	1953173116752 -> 1953000736624 [dir=none]
	1953000736624 [label="weight
 (128)" fillcolor=orange]
	1953173116752 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173116896 -> 1953173116752
	1953173116896 -> 1953172298288 [dir=none]
	1953172298288 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1953173116896 -> 1953000735104 [dir=none]
	1953000735104 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	1953173116896 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173116080 -> 1953173116896
	1953173116080 -> 1953172315872 [dir=none]
	1953172315872 [label="result
 (1, 128, 42, 42)" fillcolor=orange]
	1953173116080 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173116224 -> 1953173116080
	1953173116224 -> 1953172298128 [dir=none]
	1953172298128 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1953173116224 -> 1953172316032 [dir=none]
	1953172316032 [label="result1
 (128)" fillcolor=orange]
	1953173116224 -> 1953172315952 [dir=none]
	1953172315952 [label="result2
 (128)" fillcolor=orange]
	1953173116224 -> 1953172316352 [dir=none]
	1953172316352 [label="result3
 (0)" fillcolor=orange]
	1953173116224 -> 1953000749984 [dir=none]
	1953000749984 [label="running_mean
 (128)" fillcolor=orange]
	1953173116224 -> 1953000750784 [dir=none]
	1953000750784 [label="running_var
 (128)" fillcolor=orange]
	1953173116224 -> 1953000742064 [dir=none]
	1953000742064 [label="weight
 (128)" fillcolor=orange]
	1953173116224 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173115840 -> 1953173116224
	1953173115840 -> 1953172298368 [dir=none]
	1953172298368 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1953173115840 -> 1953000748784 [dir=none]
	1953000748784 [label="weight
 (128, 512, 1, 1)" fillcolor=orange]
	1953173115840 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173117664 -> 1953173115840
	1953173117664 -> 1953172315632 [dir=none]
	1953172315632 [label="result
 (1, 512, 42, 42)" fillcolor=orange]
	1953173117664 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173115648 -> 1953173117664
	1953173115648 [label="AddBackward0
------------
alpha: 1"]
	1953173115216 -> 1953173115648
	1953173115216 -> 1953172298528 [dir=none]
	1953172298528 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1953173115216 -> 1953172316192 [dir=none]
	1953172316192 [label="result1
 (512)" fillcolor=orange]
	1953173115216 -> 1953172316272 [dir=none]
	1953172316272 [label="result2
 (512)" fillcolor=orange]
	1953173115216 -> 1953172316672 [dir=none]
	1953172316672 [label="result3
 (0)" fillcolor=orange]
	1953173115216 -> 1953000747344 [dir=none]
	1953000747344 [label="running_mean
 (512)" fillcolor=orange]
	1953173115216 -> 1953000738464 [dir=none]
	1953000738464 [label="running_var
 (512)" fillcolor=orange]
	1953173115216 -> 1953000747104 [dir=none]
	1953000747104 [label="weight
 (512)" fillcolor=orange]
	1953173115216 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173114928 -> 1953173115216
	1953173114928 -> 1953172297808 [dir=none]
	1953172297808 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1953173114928 -> 1953000739024 [dir=none]
	1953000739024 [label="weight
 (512, 128, 1, 1)" fillcolor=orange]
	1953173114928 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173114592 -> 1953173114928
	1953173114592 -> 1953172315792 [dir=none]
	1953172315792 [label="result
 (1, 128, 42, 42)" fillcolor=orange]
	1953173114592 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173114256 -> 1953173114592
	1953173114256 -> 1953172297648 [dir=none]
	1953172297648 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1953173114256 -> 1953172316512 [dir=none]
	1953172316512 [label="result1
 (128)" fillcolor=orange]
	1953173114256 -> 1953172316592 [dir=none]
	1953172316592 [label="result2
 (128)" fillcolor=orange]
	1953173114256 -> 1953172316992 [dir=none]
	1953172316992 [label="result3
 (0)" fillcolor=orange]
	1953173114256 -> 1953000747184 [dir=none]
	1953000747184 [label="running_mean
 (128)" fillcolor=orange]
	1953173114256 -> 1953000746784 [dir=none]
	1953000746784 [label="running_var
 (128)" fillcolor=orange]
	1953173114256 -> 1953000738064 [dir=none]
	1953000738064 [label="weight
 (128)" fillcolor=orange]
	1953173114256 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173114400 -> 1953173114256
	1953173114400 -> 1953172297888 [dir=none]
	1953172297888 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1953173114400 -> 1953000737344 [dir=none]
	1953000737344 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	1953173114400 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173113584 -> 1953173114400
	1953173113584 -> 1953172316112 [dir=none]
	1953172316112 [label="result
 (1, 128, 42, 42)" fillcolor=orange]
	1953173113584 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173113728 -> 1953173113584
	1953173113728 -> 1953172298048 [dir=none]
	1953172298048 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1953173113728 -> 1953172316832 [dir=none]
	1953172316832 [label="result1
 (128)" fillcolor=orange]
	1953173113728 -> 1953172316912 [dir=none]
	1953172316912 [label="result2
 (128)" fillcolor=orange]
	1953173113728 -> 1953172317312 [dir=none]
	1953172317312 [label="result3
 (0)" fillcolor=orange]
	1953173113728 -> 1953000610832 [dir=none]
	1953000610832 [label="running_mean
 (128)" fillcolor=orange]
	1953173113728 -> 1953000612992 [dir=none]
	1953000612992 [label="running_var
 (128)" fillcolor=orange]
	1953173113728 -> 1953000609392 [dir=none]
	1953000609392 [label="weight
 (128)" fillcolor=orange]
	1953173113728 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173113344 -> 1953173113728
	1953173113344 -> 1953172297408 [dir=none]
	1953172297408 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1953173113344 -> 1953000611952 [dir=none]
	1953000611952 [label="weight
 (128, 512, 1, 1)" fillcolor=orange]
	1953173113344 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173115168 -> 1953173113344
	1953173115168 -> 1953172316432 [dir=none]
	1953172316432 [label="result
 (1, 512, 42, 42)" fillcolor=orange]
	1953173115168 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173113152 -> 1953173115168
	1953173113152 [label="AddBackward0
------------
alpha: 1"]
	1953173112720 -> 1953173113152
	1953173112720 -> 1953172297328 [dir=none]
	1953172297328 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1953173112720 -> 1953172317152 [dir=none]
	1953172317152 [label="result1
 (512)" fillcolor=orange]
	1953173112720 -> 1953172317472 [dir=none]
	1953172317472 [label="result2
 (512)" fillcolor=orange]
	1953173112720 -> 1953172317232 [dir=none]
	1953172317232 [label="result3
 (0)" fillcolor=orange]
	1953173112720 -> 1953000606112 [dir=none]
	1953000606112 [label="running_mean
 (512)" fillcolor=orange]
	1953173112720 -> 1953000605552 [dir=none]
	1953000605552 [label="running_var
 (512)" fillcolor=orange]
	1953173112720 -> 1953000611872 [dir=none]
	1953000611872 [label="weight
 (512)" fillcolor=orange]
	1953173112720 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173112432 -> 1953173112720
	1953173112432 -> 1953172297568 [dir=none]
	1953172297568 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1953173112432 -> 1953000612672 [dir=none]
	1953000612672 [label="weight
 (512, 128, 1, 1)" fillcolor=orange]
	1953173112432 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173112096 -> 1953173112432
	1953173112096 -> 1953172316752 [dir=none]
	1953172316752 [label="result
 (1, 128, 42, 42)" fillcolor=orange]
	1953173112096 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173111760 -> 1953173112096
	1953173111760 -> 1953172299168 [dir=none]
	1953172299168 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1953173111760 -> 1953172317792 [dir=none]
	1953172317792 [label="result1
 (128)" fillcolor=orange]
	1953173111760 -> 1953172317632 [dir=none]
	1953172317632 [label="result2
 (128)" fillcolor=orange]
	1953173111760 -> 1953172317392 [dir=none]
	1953172317392 [label="result3
 (0)" fillcolor=orange]
	1953173111760 -> 1954164390096 [dir=none]
	1954164390096 [label="running_mean
 (128)" fillcolor=orange]
	1953173111760 -> 1953000614032 [dir=none]
	1953000614032 [label="running_var
 (128)" fillcolor=orange]
	1953173111760 -> 1953000613552 [dir=none]
	1953000613552 [label="weight
 (128)" fillcolor=orange]
	1953173111760 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173111904 -> 1953173111760
	1953173111904 -> 1953172303248 [dir=none]
	1953172303248 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1953173111904 -> 1953000611552 [dir=none]
	1953000611552 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	1953173111904 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173111088 -> 1953173111904
	1953173111088 -> 1953172317072 [dir=none]
	1953172317072 [label="result
 (1, 128, 42, 42)" fillcolor=orange]
	1953173111088 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173111232 -> 1953173111088
	1953173111232 -> 1953172297168 [dir=none]
	1953172297168 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1953173111232 -> 1953172317552 [dir=none]
	1953172317552 [label="result1
 (128)" fillcolor=orange]
	1953173111232 -> 1953172317872 [dir=none]
	1953172317872 [label="result2
 (128)" fillcolor=orange]
	1953173111232 -> 1953172318272 [dir=none]
	1953172318272 [label="result3
 (0)" fillcolor=orange]
	1953173111232 -> 1954164377696 [dir=none]
	1954164377696 [label="running_mean
 (128)" fillcolor=orange]
	1953173111232 -> 1953000612032 [dir=none]
	1953000612032 [label="running_var
 (128)" fillcolor=orange]
	1953173111232 -> 1953000605392 [dir=none]
	1953000605392 [label="weight
 (128)" fillcolor=orange]
	1953173111232 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173111280 -> 1953173111232
	1953173111280 -> 1953172296688 [dir=none]
	1953172296688 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1953173111280 -> 1953000613872 [dir=none]
	1953000613872 [label="weight
 (128, 512, 1, 1)" fillcolor=orange]
	1953173111280 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173112672 -> 1953173111280
	1953173112672 -> 1953172317952 [dir=none]
	1953172317952 [label="result
 (1, 512, 42, 42)" fillcolor=orange]
	1953173112672 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173043856 -> 1953173112672
	1953173043856 [label="AddBackward0
------------
alpha: 1"]
	1953173044048 -> 1953173043856
	1953173044048 -> 1953172296608 [dir=none]
	1953172296608 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1953173044048 -> 1953172318112 [dir=none]
	1953172318112 [label="result1
 (512)" fillcolor=orange]
	1953173044048 -> 1953172318192 [dir=none]
	1953172318192 [label="result2
 (512)" fillcolor=orange]
	1953173044048 -> 1953172318592 [dir=none]
	1953172318592 [label="result3
 (0)" fillcolor=orange]
	1953173044048 -> 1953000605632 [dir=none]
	1953000605632 [label="running_mean
 (512)" fillcolor=orange]
	1953173044048 -> 1953000609872 [dir=none]
	1953000609872 [label="running_var
 (512)" fillcolor=orange]
	1953173044048 -> 1953000607792 [dir=none]
	1953000607792 [label="weight
 (512)" fillcolor=orange]
	1953173044048 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173043424 -> 1953173044048
	1953173043424 -> 1953172296848 [dir=none]
	1953172296848 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1953173043424 -> 1953000610192 [dir=none]
	1953000610192 [label="weight
 (512, 128, 1, 1)" fillcolor=orange]
	1953173043424 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173042800 -> 1953173043424
	1953173042800 -> 1953172317712 [dir=none]
	1953172317712 [label="result
 (1, 128, 42, 42)" fillcolor=orange]
	1953173042800 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173042032 -> 1953173042800
	1953173042032 -> 1953172306368 [dir=none]
	1953172306368 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1953173042032 -> 1953172318432 [dir=none]
	1953172318432 [label="result1
 (128)" fillcolor=orange]
	1953173042032 -> 1953172318352 [dir=none]
	1953172318352 [label="result2
 (128)" fillcolor=orange]
	1953173042032 -> 1953172318752 [dir=none]
	1953172318752 [label="result3
 (0)" fillcolor=orange]
	1953173042032 -> 1954164383616 [dir=none]
	1954164383616 [label="running_mean
 (128)" fillcolor=orange]
	1953173042032 -> 1953000606192 [dir=none]
	1953000606192 [label="running_var
 (128)" fillcolor=orange]
	1953173042032 -> 1953000609632 [dir=none]
	1953000609632 [label="weight
 (128)" fillcolor=orange]
	1953173042032 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173041360 -> 1953173042032
	1953173041360 -> 1953172296448 [dir=none]
	1953172296448 [label="input
 (1, 128, 84, 84)" fillcolor=orange]
	1953173041360 -> 1953000608112 [dir=none]
	1953000608112 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	1953173041360 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	1953173040736 -> 1953173041360
	1953173040736 -> 1953172318032 [dir=none]
	1953172318032 [label="result
 (1, 128, 84, 84)" fillcolor=orange]
	1953173040736 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173040976 -> 1953173040736
	1953173040976 -> 1953172296208 [dir=none]
	1953172296208 [label="input
 (1, 128, 84, 84)" fillcolor=orange]
	1953173040976 -> 1953172318832 [dir=none]
	1953172318832 [label="result1
 (128)" fillcolor=orange]
	1953173040976 -> 1953172318912 [dir=none]
	1953172318912 [label="result2
 (128)" fillcolor=orange]
	1953173040976 -> 1953172319072 [dir=none]
	1953172319072 [label="result3
 (0)" fillcolor=orange]
	1953173040976 -> 1954164376496 [dir=none]
	1954164376496 [label="running_mean
 (128)" fillcolor=orange]
	1953173040976 -> 1954164387296 [dir=none]
	1954164387296 [label="running_var
 (128)" fillcolor=orange]
	1953173040976 -> 1953000609072 [dir=none]
	1953000609072 [label="weight
 (128)" fillcolor=orange]
	1953173040976 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173040304 -> 1953173040976
	1953173040304 -> 1953172296368 [dir=none]
	1953172296368 [label="input
 (1, 256, 84, 84)" fillcolor=orange]
	1953173040304 -> 1953000615072 [dir=none]
	1953000615072 [label="weight
 (128, 256, 1, 1)" fillcolor=orange]
	1953173040304 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173039680 -> 1953173040304
	1953173039680 -> 1953172318512 [dir=none]
	1953172318512 [label="result
 (1, 256, 84, 84)" fillcolor=orange]
	1953173039680 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173038912 -> 1953173039680
	1953173038912 [label="AddBackward0
------------
alpha: 1"]
	1953173039104 -> 1953173038912
	1953173039104 -> 1953172295888 [dir=none]
	1953172295888 [label="input
 (1, 256, 84, 84)" fillcolor=orange]
	1953173039104 -> 1953172319152 [dir=none]
	1953172319152 [label="result1
 (256)" fillcolor=orange]
	1953173039104 -> 1953172319232 [dir=none]
	1953172319232 [label="result2
 (256)" fillcolor=orange]
	1953173039104 -> 1953172319392 [dir=none]
	1953172319392 [label="result3
 (0)" fillcolor=orange]
	1953173039104 -> 1954164375696 [dir=none]
	1954164375696 [label="running_mean
 (256)" fillcolor=orange]
	1953173039104 -> 1954164388816 [dir=none]
	1954164388816 [label="running_var
 (256)" fillcolor=orange]
	1953173039104 -> 1954164382096 [dir=none]
	1954164382096 [label="weight
 (256)" fillcolor=orange]
	1953173039104 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173038480 -> 1953173039104
	1953173038480 -> 1953172295728 [dir=none]
	1953172295728 [label="input
 (1, 64, 84, 84)" fillcolor=orange]
	1953173038480 -> 1954164388736 [dir=none]
	1954164388736 [label="weight
 (256, 64, 1, 1)" fillcolor=orange]
	1953173038480 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173037856 -> 1953173038480
	1953173037856 -> 1953172318672 [dir=none]
	1953172318672 [label="result
 (1, 64, 84, 84)" fillcolor=orange]
	1953173037856 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173037184 -> 1953173037856
	1953173037184 -> 1953172295968 [dir=none]
	1953172295968 [label="input
 (1, 64, 84, 84)" fillcolor=orange]
	1953173037184 -> 1953172319872 [dir=none]
	1953172319872 [label="result1
 (64)" fillcolor=orange]
	1953173037184 -> 1953172318992 [dir=none]
	1953172318992 [label="result2
 (64)" fillcolor=orange]
	1953173037184 -> 1953172319312 [dir=none]
	1953172319312 [label="result3
 (0)" fillcolor=orange]
	1953173037184 -> 1954164382416 [dir=none]
	1954164382416 [label="running_mean
 (64)" fillcolor=orange]
	1953173037184 -> 1954164382336 [dir=none]
	1954164382336 [label="running_var
 (64)" fillcolor=orange]
	1953173037184 -> 1954164375776 [dir=none]
	1954164375776 [label="weight
 (64)" fillcolor=orange]
	1953173037184 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173036416 -> 1953173037184
	1953173036416 -> 1953172296128 [dir=none]
	1953172296128 [label="input
 (1, 64, 84, 84)" fillcolor=orange]
	1953173036416 -> 1954164388976 [dir=none]
	1954164388976 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	1953173036416 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173035792 -> 1953173036416
	1953173035792 -> 1953172319552 [dir=none]
	1953172319552 [label="result
 (1, 64, 84, 84)" fillcolor=orange]
	1953173035792 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173035120 -> 1953173035792
	1953173035120 -> 1953172295408 [dir=none]
	1953172295408 [label="input
 (1, 64, 84, 84)" fillcolor=orange]
	1953173035120 -> 1953172319792 [dir=none]
	1953172319792 [label="result1
 (64)" fillcolor=orange]
	1953173035120 -> 1953172319712 [dir=none]
	1953172319712 [label="result2
 (64)" fillcolor=orange]
	1953173035120 -> 1953172320192 [dir=none]
	1953172320192 [label="result3
 (0)" fillcolor=orange]
	1953173035120 -> 1954164389296 [dir=none]
	1954164389296 [label="running_mean
 (64)" fillcolor=orange]
	1953173035120 -> 1954164382576 [dir=none]
	1954164382576 [label="running_var
 (64)" fillcolor=orange]
	1953173035120 -> 1954164376016 [dir=none]
	1954164376016 [label="weight
 (64)" fillcolor=orange]
	1953173035120 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173035360 -> 1953173035120
	1953173035360 -> 1953172295248 [dir=none]
	1953172295248 [label="input
 (1, 256, 84, 84)" fillcolor=orange]
	1953173035360 -> 1954164382496 [dir=none]
	1954164382496 [label="weight
 (64, 256, 1, 1)" fillcolor=orange]
	1953173035360 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173039056 -> 1953173035360
	1953173039056 -> 1953172319632 [dir=none]
	1953172319632 [label="result
 (1, 256, 84, 84)" fillcolor=orange]
	1953173039056 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173033920 -> 1953173039056
	1953173033920 [label="AddBackward0
------------
alpha: 1"]
	1953173034112 -> 1953173033920
	1953173034112 -> 1953172295488 [dir=none]
	1953172295488 [label="input
 (1, 256, 84, 84)" fillcolor=orange]
	1953173034112 -> 1953172319472 [dir=none]
	1953172319472 [label="result1
 (256)" fillcolor=orange]
	1953173034112 -> 1953172320112 [dir=none]
	1953172320112 [label="result2
 (256)" fillcolor=orange]
	1953173034112 -> 1953172320512 [dir=none]
	1953172320512 [label="result3
 (0)" fillcolor=orange]
	1953173034112 -> 1954164376336 [dir=none]
	1954164376336 [label="running_mean
 (256)" fillcolor=orange]
	1953173034112 -> 1954164389456 [dir=none]
	1954164389456 [label="running_var
 (256)" fillcolor=orange]
	1953173034112 -> 1954164382736 [dir=none]
	1954164382736 [label="weight
 (256)" fillcolor=orange]
	1953173034112 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173033488 -> 1953173034112
	1953173033488 -> 1953172295648 [dir=none]
	1953172295648 [label="input
 (1, 64, 84, 84)" fillcolor=orange]
	1953173033488 -> 1954164389376 [dir=none]
	1954164389376 [label="weight
 (256, 64, 1, 1)" fillcolor=orange]
	1953173033488 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173032864 -> 1953173033488
	1953173032864 -> 1953172320032 [dir=none]
	1953172320032 [label="result
 (1, 64, 84, 84)" fillcolor=orange]
	1953173032864 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173032192 -> 1953173032864
	1953173032192 -> 1953172299568 [dir=none]
	1953172299568 [label="input
 (1, 64, 84, 84)" fillcolor=orange]
	1953173032192 -> 1953172320672 [dir=none]
	1953172320672 [label="result1
 (64)" fillcolor=orange]
	1953173032192 -> 1953172319952 [dir=none]
	1953172319952 [label="result2
 (64)" fillcolor=orange]
	1953173032192 -> 1953172320272 [dir=none]
	1953172320272 [label="result3
 (0)" fillcolor=orange]
	1953173032192 -> 1954164383216 [dir=none]
	1954164383216 [label="running_mean
 (64)" fillcolor=orange]
	1953173032192 -> 1954164383136 [dir=none]
	1954164383136 [label="running_var
 (64)" fillcolor=orange]
	1953173032192 -> 1954164384496 [dir=none]
	1954164384496 [label="weight
 (64)" fillcolor=orange]
	1953173032192 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173031424 -> 1953173032192
	1953173031424 -> 1953172299728 [dir=none]
	1953172299728 [label="input
 (1, 64, 84, 84)" fillcolor=orange]
	1953173031424 -> 1954164376576 [dir=none]
	1954164376576 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	1953173031424 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173030800 -> 1953173031424
	1953173030800 -> 1953172320352 [dir=none]
	1953172320352 [label="result
 (1, 64, 84, 84)" fillcolor=orange]
	1953173030800 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173030128 -> 1953173030800
	1953173030128 -> 1953172299968 [dir=none]
	1953172299968 [label="input
 (1, 64, 84, 84)" fillcolor=orange]
	1953173030128 -> 1953172320832 [dir=none]
	1953172320832 [label="result1
 (64)" fillcolor=orange]
	1953173030128 -> 1953172320992 [dir=none]
	1953172320992 [label="result2
 (64)" fillcolor=orange]
	1953173030128 -> 1953172320432 [dir=none]
	1953172320432 [label="result3
 (0)" fillcolor=orange]
	1953173030128 -> 1954164391376 [dir=none]
	1954164391376 [label="running_mean
 (64)" fillcolor=orange]
	1953173030128 -> 1954164383376 [dir=none]
	1954164383376 [label="running_var
 (64)" fillcolor=orange]
	1953173030128 -> 1954164376816 [dir=none]
	1954164376816 [label="weight
 (64)" fillcolor=orange]
	1953173030128 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173030368 -> 1953173030128
	1953173030368 -> 1953172299408 [dir=none]
	1953172299408 [label="input
 (1, 256, 84, 84)" fillcolor=orange]
	1953173030368 -> 1954164383296 [dir=none]
	1954164383296 [label="weight
 (64, 256, 1, 1)" fillcolor=orange]
	1953173030368 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173034064 -> 1953173030368
	1953173034064 -> 1953172321312 [dir=none]
	1953172321312 [label="result
 (1, 256, 84, 84)" fillcolor=orange]
	1953173034064 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173029072 -> 1953173034064
	1953173029072 [label="AddBackward0
------------
alpha: 1"]
	1953173045200 -> 1953173029072
	1953173045200 -> 1953172306608 [dir=none]
	1953172306608 [label="input
 (1, 256, 84, 84)" fillcolor=orange]
	1953173045200 -> 1953172320592 [dir=none]
	1953172320592 [label="result1
 (256)" fillcolor=orange]
	1953173045200 -> 1953172321152 [dir=none]
	1953172321152 [label="result2
 (256)" fillcolor=orange]
	1953173045200 -> 1953172320752 [dir=none]
	1953172320752 [label="result3
 (0)" fillcolor=orange]
	1953173045200 -> 1954164377136 [dir=none]
	1954164377136 [label="running_mean
 (256)" fillcolor=orange]
	1953173045200 -> 1954164390256 [dir=none]
	1954164390256 [label="running_var
 (256)" fillcolor=orange]
	1953173045200 -> 1954164383536 [dir=none]
	1954164383536 [label="weight
 (256)" fillcolor=orange]
	1953173045200 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173044960 -> 1953173045200
	1953173044960 -> 1953172303488 [dir=none]
	1953172303488 [label="input
 (1, 64, 84, 84)" fillcolor=orange]
	1953173044960 -> 1954164390176 [dir=none]
	1954164390176 [label="weight
 (256, 64, 1, 1)" fillcolor=orange]
	1953173044960 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173044624 -> 1953173044960
	1953173044624 -> 1953172320912 [dir=none]
	1953172320912 [label="result
 (1, 64, 84, 84)" fillcolor=orange]
	1953173044624 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173044288 -> 1953173044624
	1953173044288 -> 1953172306848 [dir=none]
	1953172306848 [label="input
 (1, 64, 84, 84)" fillcolor=orange]
	1953173044288 -> 1953172321552 [dir=none]
	1953172321552 [label="result1
 (64)" fillcolor=orange]
	1953173044288 -> 1953172321232 [dir=none]
	1953172321232 [label="result2
 (64)" fillcolor=orange]
	1953173044288 -> 1953172321472 [dir=none]
	1953172321472 [label="result3
 (0)" fillcolor=orange]
	1953173044288 -> 1953173270544 [dir=none]
	1953173270544 [label="running_mean
 (64)" fillcolor=orange]
	1953173044288 -> 1954164383696 [dir=none]
	1954164383696 [label="running_var
 (64)" fillcolor=orange]
	1953173044288 -> 1954164377376 [dir=none]
	1954164377376 [label="weight
 (64)" fillcolor=orange]
	1953173044288 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173044432 -> 1953173044288
	1953173044432 -> 1953172303728 [dir=none]
	1953172303728 [label="input
 (1, 64, 84, 84)" fillcolor=orange]
	1953173044432 -> 1954164390576 [dir=none]
	1954164390576 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	1953173044432 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173043616 -> 1953173044432
	1953173043616 -> 1953172321072 [dir=none]
	1953172321072 [label="result
 (1, 64, 84, 84)" fillcolor=orange]
	1953173043616 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173043760 -> 1953173043616
	1953173043760 -> 1953172299648 [dir=none]
	1953172299648 [label="input
 (1, 64, 84, 84)" fillcolor=orange]
	1953173043760 -> 1953172322112 [dir=none]
	1953172322112 [label="result1
 (64)" fillcolor=orange]
	1953173043760 -> 1953172321792 [dir=none]
	1953172321792 [label="result2
 (64)" fillcolor=orange]
	1953173043760 -> 1953172321392 [dir=none]
	1953172321392 [label="result3
 (0)" fillcolor=orange]
	1953173043760 -> 1953173270304 [dir=none]
	1953173270304 [label="running_mean
 (64)" fillcolor=orange]
	1953173043760 -> 1954164383936 [dir=none]
	1954164383936 [label="running_var
 (64)" fillcolor=orange]
	1953173043760 -> 1954164377216 [dir=none]
	1954164377216 [label="weight
 (64)" fillcolor=orange]
	1953173043760 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173043376 -> 1953173043760
	1953173043376 -> 1953172302048 [dir=none]
	1953172302048 [label="input
 (1, 64, 84, 84)" fillcolor=orange]
	1953173043376 -> 1954164377296 [dir=none]
	1954164377296 [label="weight
 (64, 64, 1, 1)" fillcolor=orange]
	1953173043376 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173043088 -> 1953173043376
	1953173043088 -> 1953172321632 [dir=none]
	1953172321632 [label="result1
 (1, 64, 84, 84)" fillcolor=orange]
	1953173043088 -> 1953172307568 [dir=none]
	1953172307568 [label="self
 (1, 64, 167, 167)" fillcolor=orange]
	1953173043088 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (3, 3)
padding    :         (1, 1)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	1953173042704 -> 1953173043088
	1953173042704 -> 1953172322432 [dir=none]
	1953172322432 [label="result
 (1, 64, 167, 167)" fillcolor=orange]
	1953173042704 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173042368 -> 1953173042704
	1953173042368 -> 1953172297968 [dir=none]
	1953172297968 [label="input
 (1, 64, 167, 167)" fillcolor=orange]
	1953173042368 -> 1953172321712 [dir=none]
	1953172321712 [label="result1
 (64)" fillcolor=orange]
	1953173042368 -> 1953172313392 [dir=none]
	1953172313392 [label="result2
 (64)" fillcolor=orange]
	1953173042368 -> 1953172322032 [dir=none]
	1953172322032 [label="result3
 (0)" fillcolor=orange]
	1953173042368 -> 1954164384416 [dir=none]
	1954164384416 [label="running_mean
 (64)" fillcolor=orange]
	1953173042368 -> 1954164377856 [dir=none]
	1954164377856 [label="running_var
 (64)" fillcolor=orange]
	1953173042368 -> 1954164390976 [dir=none]
	1954164390976 [label="weight
 (64)" fillcolor=orange]
	1953173042368 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173042512 -> 1953173042368
	1953173042512 -> 1953172298208 [dir=none]
	1953172298208 [label="input
 (1, 32, 167, 167)" fillcolor=orange]
	1953173042512 -> 1954164391056 [dir=none]
	1954164391056 [label="weight
 (64, 32, 3, 3)" fillcolor=orange]
	1953173042512 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173041696 -> 1953173042512
	1953173041696 -> 1953172322352 [dir=none]
	1953172322352 [label="result
 (1, 32, 167, 167)" fillcolor=orange]
	1953173041696 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173041840 -> 1953173041696
	1953173041840 -> 1953172302288 [dir=none]
	1953172302288 [label="input
 (1, 32, 167, 167)" fillcolor=orange]
	1953173041840 -> 1953172321872 [dir=none]
	1953172321872 [label="result1
 (32)" fillcolor=orange]
	1953173041840 -> 1953172321952 [dir=none]
	1953172321952 [label="result2
 (32)" fillcolor=orange]
	1953173041840 -> 1953172322272 [dir=none]
	1953172322272 [label="result3
 (0)" fillcolor=orange]
	1953173041840 -> 1953173270464 [dir=none]
	1953173270464 [label="running_mean
 (32)" fillcolor=orange]
	1953173041840 -> 1954164384576 [dir=none]
	1954164384576 [label="running_var
 (32)" fillcolor=orange]
	1953173041840 -> 1954164378016 [dir=none]
	1954164378016 [label="weight
 (32)" fillcolor=orange]
	1953173041840 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173041456 -> 1953173041840
	1953173041456 -> 1953172307328 [dir=none]
	1953172307328 [label="input
 (1, 32, 167, 167)" fillcolor=orange]
	1953173041456 -> 1954164378096 [dir=none]
	1954164378096 [label="weight
 (32, 32, 3, 3)" fillcolor=orange]
	1953173041456 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173041168 -> 1953173041456
	1953173041168 -> 1953172322672 [dir=none]
	1953172322672 [label="result
 (1, 32, 167, 167)" fillcolor=orange]
	1953173041168 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	1953173041312 -> 1953173041168
	1953173041312 -> 1953172302528 [dir=none]
	1953172302528 [label="input
 (1, 32, 167, 167)" fillcolor=orange]
	1953173041312 -> 1953172322192 [dir=none]
	1953172322192 [label="result1
 (32)" fillcolor=orange]
	1953173041312 -> 1953172322912 [dir=none]
	1953172322912 [label="result2
 (32)" fillcolor=orange]
	1953173041312 -> 1953172308832 [dir=none]
	1953172308832 [label="result3
 (0)" fillcolor=orange]
	1953173041312 -> 1953173270224 [dir=none]
	1953173270224 [label="running_mean
 (32)" fillcolor=orange]
	1953173041312 -> 1952874307536 [dir=none]
	1952874307536 [label="running_var
 (32)" fillcolor=orange]
	1953173041312 -> 1952874308176 [dir=none]
	1952874308176 [label="weight
 (32)" fillcolor=orange]
	1953173041312 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173040448 -> 1953173041312
	1953173040448 -> 1953172298448 [dir=none]
	1953172298448 [label="input
 (1, 3, 333, 333)" fillcolor=orange]
	1953173040448 -> 1954164391296 [dir=none]
	1954164391296 [label="weight
 (32, 3, 3, 3)" fillcolor=orange]
	1953173040448 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	1953173040640 -> 1953173040448
	1954164391296 [label="conv1.0.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	1954164391296 -> 1953173040640
	1953173040640 [label=AccumulateGrad]
	1953173040832 -> 1953173041312
	1952874308176 [label="conv1.1.weight
 (32)" fillcolor=lightblue]
	1952874308176 -> 1953173040832
	1953173040832 [label=AccumulateGrad]
	1953173041216 -> 1953173041312
	1953000646480 [label="conv1.1.bias
 (32)" fillcolor=lightblue]
	1953000646480 -> 1953173041216
	1953173041216 [label=AccumulateGrad]
	1953173041120 -> 1953173041456
	1954164378096 [label="conv1.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1954164378096 -> 1953173041120
	1953173041120 [label=AccumulateGrad]
	1953173041888 -> 1953173041840
	1954164378016 [label="conv1.4.weight
 (32)" fillcolor=lightblue]
	1954164378016 -> 1953173041888
	1953173041888 [label=AccumulateGrad]
	1953173041744 -> 1953173041840
	1954164391216 [label="conv1.4.bias
 (32)" fillcolor=lightblue]
	1954164391216 -> 1953173041744
	1953173041744 [label=AccumulateGrad]
	1953173042128 -> 1953173042512
	1954164391056 [label="conv1.6.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	1954164391056 -> 1953173042128
	1953173042128 [label=AccumulateGrad]
	1953173042416 -> 1953173042368
	1954164390976 [label="bn1.weight
 (64)" fillcolor=lightblue]
	1954164390976 -> 1953173042416
	1953173042416 [label=AccumulateGrad]
	1953173043136 -> 1953173042368
	1954164384336 [label="bn1.bias
 (64)" fillcolor=lightblue]
	1954164384336 -> 1953173043136
	1953173043136 [label=AccumulateGrad]
	1953173043040 -> 1953173043376
	1954164377296 [label="layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	1954164377296 -> 1953173043040
	1953173043040 [label=AccumulateGrad]
	1953173043808 -> 1953173043760
	1954164377216 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	1954164377216 -> 1953173043808
	1953173043808 [label=AccumulateGrad]
	1953173043664 -> 1953173043760
	1954164390416 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	1954164390416 -> 1953173043664
	1953173043664 [label=AccumulateGrad]
	1953173043568 -> 1953173044432
	1954164390576 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1954164390576 -> 1953173043568
	1953173043568 [label=AccumulateGrad]
	1953173044336 -> 1953173044288
	1954164377376 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	1954164377376 -> 1953173044336
	1953173044336 [label=AccumulateGrad]
	1953173044192 -> 1953173044288
	1954164390496 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	1954164390496 -> 1953173044192
	1953173044192 [label=AccumulateGrad]
	1953173044576 -> 1953173044960
	1954164390176 [label="layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1954164390176 -> 1953173044576
	1953173044576 [label=AccumulateGrad]
	1953173044864 -> 1953173045200
	1954164383536 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	1954164383536 -> 1953173044864
	1953173044864 [label=AccumulateGrad]
	1953173044816 -> 1953173045200
	1954164383456 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	1954164383456 -> 1953173044816
	1953173044816 [label=AccumulateGrad]
	1953173029120 -> 1953173029072
	1953173029120 -> 1953172299808 [dir=none]
	1953172299808 [label="input
 (1, 256, 84, 84)" fillcolor=orange]
	1953173029120 -> 1953033090640 [dir=none]
	1953033090640 [label="result1
 (256)" fillcolor=orange]
	1953173029120 -> 1953172322992 [dir=none]
	1953172322992 [label="result2
 (256)" fillcolor=orange]
	1953173029120 -> 1953172322512 [dir=none]
	1953172322512 [label="result3
 (0)" fillcolor=orange]
	1953173029120 -> 1953173270384 [dir=none]
	1953173270384 [label="running_mean
 (256)" fillcolor=orange]
	1953173029120 -> 1954164390816 [dir=none]
	1954164390816 [label="running_var
 (256)" fillcolor=orange]
	1953173029120 -> 1954164384096 [dir=none]
	1954164384096 [label="weight
 (256)" fillcolor=orange]
	1953173029120 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173044000 -> 1953173029120
	1953173044000 -> 1953172302048 [dir=none]
	1953172302048 [label="input
 (1, 64, 84, 84)" fillcolor=orange]
	1953173044000 -> 1954164384176 [dir=none]
	1954164384176 [label="weight
 (256, 64, 1, 1)" fillcolor=orange]
	1953173044000 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173043088 -> 1953173044000
	1953173042944 -> 1953173044000
	1954164384176 [label="layer1.0.downsample.1.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1954164384176 -> 1953173042944
	1953173042944 [label=AccumulateGrad]
	1953173045056 -> 1953173029120
	1954164384096 [label="layer1.0.downsample.2.weight
 (256)" fillcolor=lightblue]
	1954164384096 -> 1953173045056
	1953173045056 [label=AccumulateGrad]
	1953173045008 -> 1953173029120
	1954164377616 [label="layer1.0.downsample.2.bias
 (256)" fillcolor=lightblue]
	1954164377616 -> 1953173045008
	1953173045008 [label=AccumulateGrad]
	1953173029744 -> 1953173030368
	1954164383296 [label="layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	1954164383296 -> 1953173029744
	1953173029744 [label=AccumulateGrad]
	1953173030176 -> 1953173030128
	1954164376816 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	1954164376816 -> 1953173030176
	1953173030176 [label=AccumulateGrad]
	1953173030944 -> 1953173030128
	1954164376736 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	1954164376736 -> 1953173030944
	1953173030944 [label=AccumulateGrad]
	1953173030752 -> 1953173031424
	1954164376576 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1954164376576 -> 1953173030752
	1953173030752 [label=AccumulateGrad]
	1953173032240 -> 1953173032192
	1954164384496 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	1954164384496 -> 1953173032240
	1953173032240 [label=AccumulateGrad]
	1953173032000 -> 1953173032192
	1954164384736 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	1954164384736 -> 1953173032000
	1953173032000 [label=AccumulateGrad]
	1953173032816 -> 1953173033488
	1954164389376 [label="layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1954164389376 -> 1953173032816
	1953173032816 [label=AccumulateGrad]
	1953173033296 -> 1953173034112
	1954164382736 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	1954164382736 -> 1953173033296
	1953173033296 [label=AccumulateGrad]
	1953173033248 -> 1953173034112
	1954164382656 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	1954164382656 -> 1953173033248
	1953173033248 [label=AccumulateGrad]
	1953173034064 -> 1953173033920
	1953173034736 -> 1953173035360
	1954164382496 [label="layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	1954164382496 -> 1953173034736
	1953173034736 [label=AccumulateGrad]
	1953173035168 -> 1953173035120
	1954164376016 [label="layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	1954164376016 -> 1953173035168
	1953173035168 [label=AccumulateGrad]
	1953173035936 -> 1953173035120
	1954164375936 [label="layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	1954164375936 -> 1953173035936
	1953173035936 [label=AccumulateGrad]
	1953173035744 -> 1953173036416
	1954164388976 [label="layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1954164388976 -> 1953173035744
	1953173035744 [label=AccumulateGrad]
	1953173037232 -> 1953173037184
	1954164375776 [label="layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	1954164375776 -> 1953173037232
	1953173037232 [label=AccumulateGrad]
	1953173036992 -> 1953173037184
	1954164388896 [label="layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	1954164388896 -> 1953173036992
	1953173036992 [label=AccumulateGrad]
	1953173037808 -> 1953173038480
	1954164388736 [label="layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1954164388736 -> 1953173037808
	1953173037808 [label=AccumulateGrad]
	1953173038288 -> 1953173039104
	1954164382096 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	1954164382096 -> 1953173038288
	1953173038288 [label=AccumulateGrad]
	1953173038240 -> 1953173039104
	1954164382016 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	1954164382016 -> 1953173038240
	1953173038240 [label=AccumulateGrad]
	1953173039056 -> 1953173038912
	1953173039536 -> 1953173040304
	1953000615072 [label="layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	1953000615072 -> 1953173039536
	1953173039536 [label=AccumulateGrad]
	1953173040112 -> 1953173040976
	1953000609072 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	1953000609072 -> 1953173040112
	1953173040112 [label=AccumulateGrad]
	1953173040784 -> 1953173040976
	1953000606592 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	1953000606592 -> 1953173040784
	1953173040784 [label=AccumulateGrad]
	1953173041600 -> 1953173041360
	1953000608112 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1953000608112 -> 1953173041600
	1953173041600 [label=AccumulateGrad]
	1953173042176 -> 1953173042032
	1953000609632 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	1953000609632 -> 1953173042176
	1953173042176 [label=AccumulateGrad]
	1953173042848 -> 1953173042032
	1953000618432 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	1953000618432 -> 1953173042848
	1953173042848 [label=AccumulateGrad]
	1953173042656 -> 1953173043424
	1953000610192 [label="layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1953000610192 -> 1953173042656
	1953173042656 [label=AccumulateGrad]
	1953173043232 -> 1953173044048
	1953000607792 [label="layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	1953000607792 -> 1953173043232
	1953173043232 [label=AccumulateGrad]
	1953173044096 -> 1953173044048
	1953000615872 [label="layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	1953000615872 -> 1953173044096
	1953173044096 [label=AccumulateGrad]
	1953173043904 -> 1953173043856
	1953173043904 -> 1953172296928 [dir=none]
	1953172296928 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1953173043904 -> 1953172323072 [dir=none]
	1953172323072 [label="result1
 (512)" fillcolor=orange]
	1953173043904 -> 1953172323232 [dir=none]
	1953172323232 [label="result2
 (512)" fillcolor=orange]
	1953173043904 -> 1953172322592 [dir=none]
	1953172322592 [label="result3
 (0)" fillcolor=orange]
	1953173043904 -> 1953000604912 [dir=none]
	1953000604912 [label="running_mean
 (512)" fillcolor=orange]
	1953173043904 -> 1954164376416 [dir=none]
	1954164376416 [label="running_var
 (512)" fillcolor=orange]
	1953173043904 -> 1954164389536 [dir=none]
	1954164389536 [label="weight
 (512)" fillcolor=orange]
	1953173043904 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173041552 -> 1953173043904
	1953173041552 -> 1953172297088 [dir=none]
	1953172297088 [label="input
 (1, 256, 42, 42)" fillcolor=orange]
	1953173041552 -> 1954164389616 [dir=none]
	1954164389616 [label="weight
 (512, 256, 1, 1)" fillcolor=orange]
	1953173041552 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173040352 -> 1953173041552
	1953173040352 -> 1953172296368 [dir=none]
	1953172296368 [label="self
 (1, 256, 84, 84)" fillcolor=orange]
	1953173040352 [label="AvgPool2DBackward0
---------------------------------
ceil_mode        :           True
count_include_pad:          False
divisor_override :           None
kernel_size      :         (2, 2)
padding          :         (0, 0)
self             : [saved tensor]
stride           :         (2, 2)"]
	1953173039680 -> 1953173040352
	1953173039488 -> 1953173041552
	1954164389616 [label="layer2.0.downsample.1.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	1954164389616 -> 1953173039488
	1953173039488 [label=AccumulateGrad]
	1953173042608 -> 1953173043904
	1954164389536 [label="layer2.0.downsample.2.weight
 (512)" fillcolor=lightblue]
	1954164389536 -> 1953173042608
	1953173042608 [label=AccumulateGrad]
	1953173043472 -> 1953173043904
	1954164382896 [label="layer2.0.downsample.2.bias
 (512)" fillcolor=lightblue]
	1954164382896 -> 1953173043472
	1953173043472 [label=AccumulateGrad]
	1953173044672 -> 1953173111280
	1953000613872 [label="layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1953000613872 -> 1953173044672
	1953173044672 [label=AccumulateGrad]
	1953173111136 -> 1953173111232
	1953000605392 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	1953000605392 -> 1953173111136
	1953173111136 [label=AccumulateGrad]
	1953173045104 -> 1953173111232
	1953000606352 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	1953000606352 -> 1953173045104
	1953173045104 [label=AccumulateGrad]
	1953173111040 -> 1953173111904
	1953000611552 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1953000611552 -> 1953173111040
	1953173111040 [label=AccumulateGrad]
	1953173111808 -> 1953173111760
	1953000613552 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	1953000613552 -> 1953173111808
	1953173111808 [label=AccumulateGrad]
	1953173111664 -> 1953173111760
	1953000606912 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	1953000606912 -> 1953173111664
	1953173111664 [label=AccumulateGrad]
	1953173112048 -> 1953173112432
	1953000612672 [label="layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1953000612672 -> 1953173112048
	1953173112048 [label=AccumulateGrad]
	1953173112336 -> 1953173112720
	1953000611872 [label="layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	1953000611872 -> 1953173112336
	1953173112336 [label=AccumulateGrad]
	1953173112288 -> 1953173112720
	1953000604752 [label="layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	1953000604752 -> 1953173112288
	1953173112288 [label=AccumulateGrad]
	1953173112672 -> 1953173113152
	1953173113056 -> 1953173113344
	1953000611952 [label="layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1953000611952 -> 1953173113056
	1953173113056 [label=AccumulateGrad]
	1953173113776 -> 1953173113728
	1953000609392 [label="layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	1953000609392 -> 1953173113776
	1953173113776 [label=AccumulateGrad]
	1953173113632 -> 1953173113728
	1953000604192 [label="layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	1953000604192 -> 1953173113632
	1953173113632 [label=AccumulateGrad]
	1953173113536 -> 1953173114400
	1953000737344 [label="layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1953000737344 -> 1953173113536
	1953173113536 [label=AccumulateGrad]
	1953173114304 -> 1953173114256
	1953000738064 [label="layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	1953000738064 -> 1953173114304
	1953173114304 [label=AccumulateGrad]
	1953173114160 -> 1953173114256
	1953000739264 [label="layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	1953000739264 -> 1953173114160
	1953173114160 [label=AccumulateGrad]
	1953173114544 -> 1953173114928
	1953000739024 [label="layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1953000739024 -> 1953173114544
	1953173114544 [label=AccumulateGrad]
	1953173114832 -> 1953173115216
	1953000747104 [label="layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	1953000747104 -> 1953173114832
	1953173114832 [label=AccumulateGrad]
	1953173114784 -> 1953173115216
	1953000744304 [label="layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	1953000744304 -> 1953173114784
	1953173114784 [label=AccumulateGrad]
	1953173115168 -> 1953173115648
	1953173115552 -> 1953173115840
	1953000748784 [label="layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1953000748784 -> 1953173115552
	1953173115552 [label=AccumulateGrad]
	1953173116272 -> 1953173116224
	1953000742064 [label="layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	1953000742064 -> 1953173116272
	1953173116272 [label=AccumulateGrad]
	1953173116128 -> 1953173116224
	1953000742464 [label="layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	1953000742464 -> 1953173116128
	1953173116128 [label=AccumulateGrad]
	1953173116032 -> 1953173116896
	1953000735104 [label="layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1953000735104 -> 1953173116032
	1953173116032 [label=AccumulateGrad]
	1953173116800 -> 1953173116752
	1953000736624 [label="layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	1953000736624 -> 1953173116800
	1953173116800 [label=AccumulateGrad]
	1953173116656 -> 1953173116752
	1953000734944 [label="layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	1953000734944 -> 1953173116656
	1953173116656 [label=AccumulateGrad]
	1953173117040 -> 1953173117424
	1953000735424 [label="layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1953000735424 -> 1953173117040
	1953173117040 [label=AccumulateGrad]
	1953173117328 -> 1953173117712
	1953000743984 [label="layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	1953000743984 -> 1953173117328
	1953173117328 [label=AccumulateGrad]
	1953173117280 -> 1953173117712
	1953000740384 [label="layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	1953000740384 -> 1953173117280
	1953173117280 [label=AccumulateGrad]
	1953173117664 -> 1953173118144
	1953173117952 -> 1953173118288
	1953000749264 [label="layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	1953000749264 -> 1953173117952
	1953173117952 [label=AccumulateGrad]
	1953173118720 -> 1953173118672
	1953000746864 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	1953000746864 -> 1953173118720
	1953173118720 [label=AccumulateGrad]
	1953173118576 -> 1953173118672
	1953000749424 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	1953000749424 -> 1953173118576
	1953173118576 [label=AccumulateGrad]
	1953173118960 -> 1953173119344
	1953000743424 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000743424 -> 1953173118960
	1953173118960 [label=AccumulateGrad]
	1953173119248 -> 1953173119152
	1953000739584 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	1953000739584 -> 1953173119248
	1953173119248 [label=AccumulateGrad]
	1953173119200 -> 1953173119152
	1953000737904 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	1953000737904 -> 1953173119200
	1953173119200 [label=AccumulateGrad]
	1953173119968 -> 1953173119824
	1953000743104 [label="layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000743104 -> 1953173119968
	1953173119968 [label=AccumulateGrad]
	1953173120208 -> 1953173120640
	1953000742944 [label="layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000742944 -> 1953173120208
	1953173120208 [label=AccumulateGrad]
	1953173120160 -> 1953173120640
	1953000742864 [label="layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000742864 -> 1953173120160
	1953173120160 [label=AccumulateGrad]
	1953173120592 -> 1953173120544
	1953173120592 -> 1953172300288 [dir=none]
	1953172300288 [label="input
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173120592 -> 1953172323312 [dir=none]
	1953172323312 [label="result1
 (1024)" fillcolor=orange]
	1953173120592 -> 1953172323152 [dir=none]
	1953172323152 [label="result2
 (1024)" fillcolor=orange]
	1953173120592 -> 1953172323632 [dir=none]
	1953172323632 [label="result3
 (0)" fillcolor=orange]
	1953173120592 -> 1954164380896 [dir=none]
	1954164380896 [label="running_mean
 (1024)" fillcolor=orange]
	1953173120592 -> 1953000746464 [dir=none]
	1953000746464 [label="running_var
 (1024)" fillcolor=orange]
	1953173120592 -> 1953000745264 [dir=none]
	1953000745264 [label="weight
 (1024)" fillcolor=orange]
	1953173120592 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173118912 -> 1953173120592
	1953173118912 -> 1953172300208 [dir=none]
	1953172300208 [label="input
 (1, 512, 21, 21)" fillcolor=orange]
	1953173118912 -> 1953000746304 [dir=none]
	1953000746304 [label="weight
 (1024, 512, 1, 1)" fillcolor=orange]
	1953173118912 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173118336 -> 1953173118912
	1953173118336 -> 1953172299088 [dir=none]
	1953172299088 [label="self
 (1, 512, 42, 42)" fillcolor=orange]
	1953173118336 [label="AvgPool2DBackward0
---------------------------------
ceil_mode        :           True
count_include_pad:          False
divisor_override :           None
kernel_size      :         (2, 2)
padding          :         (0, 0)
self             : [saved tensor]
stride           :         (2, 2)"]
	1953173118000 -> 1953173118336
	1953173117904 -> 1953173118912
	1953000746304 [label="layer3.0.downsample.1.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	1953000746304 -> 1953173117904
	1953173117904 [label=AccumulateGrad]
	1953173119920 -> 1953173120592
	1953000745264 [label="layer3.0.downsample.2.weight
 (1024)" fillcolor=lightblue]
	1953000745264 -> 1953173119920
	1953173119920 [label=AccumulateGrad]
	1953173119872 -> 1953173120592
	1953000736304 [label="layer3.0.downsample.2.bias
 (1024)" fillcolor=lightblue]
	1953000736304 -> 1953173119872
	1953173119872 [label=AccumulateGrad]
	1953173120448 -> 1953173121264
	1953000744704 [label="layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000744704 -> 1953173120448
	1953173120448 [label=AccumulateGrad]
	1953173121168 -> 1953173121120
	1953000740704 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	1953000740704 -> 1953173121168
	1953173121168 [label=AccumulateGrad]
	1953173121024 -> 1953173121120
	1953000744224 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	1953000744224 -> 1953173121024
	1953173121024 [label=AccumulateGrad]
	1953173121408 -> 1953173121792
	1953000738144 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000738144 -> 1953173121408
	1953173121408 [label=AccumulateGrad]
	1953173121696 -> 1953173121648
	1953000737744 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	1953000737744 -> 1953173121696
	1953173121696 [label=AccumulateGrad]
	1953173122032 -> 1953173121648
	1953000741664 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	1953000741664 -> 1953173122032
	1953173122032 [label=AccumulateGrad]
	1953173122464 -> 1953173122320
	1953000741984 [label="layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000741984 -> 1953173122464
	1953173122464 [label=AccumulateGrad]
	1953173122704 -> 1953173123136
	1953000745664 [label="layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000745664 -> 1953173122704
	1953173122704 [label=AccumulateGrad]
	1953173122656 -> 1953173123136
	1953000750624 [label="layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000750624 -> 1953173122656
	1953173122656 [label=AccumulateGrad]
	1953173123088 -> 1953173123040
	1953173122944 -> 1953173123760
	1953000741504 [label="layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000741504 -> 1953173122944
	1953173122944 [label=AccumulateGrad]
	1953173123664 -> 1953173123616
	1953000740304 [label="layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	1953000740304 -> 1953173123664
	1953173123664 [label=AccumulateGrad]
	1953173123520 -> 1953173123616
	1953000744144 [label="layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	1953000744144 -> 1953173123520
	1953173123520 [label=AccumulateGrad]
	1953173123904 -> 1953173124288
	1953000739824 [label="layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000739824 -> 1953173123904
	1953173123904 [label=AccumulateGrad]
	1953173124192 -> 1953173124144
	1953000750304 [label="layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	1953000750304 -> 1953173124192
	1953173124192 [label=AccumulateGrad]
	1953173124528 -> 1953173124144
	1953000750144 [label="layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	1953000750144 -> 1953173124528
	1953173124528 [label=AccumulateGrad]
	1953173124960 -> 1953173124816
	1953000735744 [label="layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000735744 -> 1953173124960
	1953173124960 [label=AccumulateGrad]
	1953173125200 -> 1953173125632
	1953000736064 [label="layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000736064 -> 1953173125200
	1953173125200 [label=AccumulateGrad]
	1953173125152 -> 1953173125632
	1953000750464 [label="layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000750464 -> 1953173125152
	1953173125152 [label=AccumulateGrad]
	1953173125584 -> 1953173125536
	1953173125440 -> 1953173126256
	1953000736224 [label="layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000736224 -> 1953173125440
	1953173125440 [label=AccumulateGrad]
	1953173126160 -> 1953173126112
	1953000750704 [label="layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	1953000750704 -> 1953173126160
	1953173126160 [label=AccumulateGrad]
	1953173126016 -> 1953173126112
	1953000740864 [label="layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	1953000740864 -> 1953173126016
	1953173126016 [label=AccumulateGrad]
	1953173126400 -> 1953173126784
	1953000735584 [label="layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000735584 -> 1953173126400
	1953173126400 [label=AccumulateGrad]
	1953173126688 -> 1953173126640
	1953000735824 [label="layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	1953000735824 -> 1953173126688
	1953173126688 [label=AccumulateGrad]
	1953173127024 -> 1953173126640
	1953000736464 [label="layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	1953000736464 -> 1953173127024
	1953173127024 [label=AccumulateGrad]
	1953173110896 -> 1953173111376
	1953000744864 [label="layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000744864 -> 1953173110896
	1953173110896 [label=AccumulateGrad]
	1953173112192 -> 1953173112000
	1953000749904 [label="layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000749904 -> 1953173112192
	1953173112192 [label=AccumulateGrad]
	1953173112144 -> 1953173112000
	1953000735264 [label="layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000735264 -> 1953173112144
	1953173112144 [label=AccumulateGrad]
	1953173111952 -> 1953173112816
	1953173112624 -> 1953173113248
	1953000737584 [label="layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000737584 -> 1953173112624
	1953173112624 [label=AccumulateGrad]
	1953173114064 -> 1953173114016
	1953000746144 [label="layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	1953000746144 -> 1953173114064
	1953173114064 [label=AccumulateGrad]
	1953173113824 -> 1953173114016
	1953000745104 [label="layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	1953000745104 -> 1953173113824
	1953173113824 [label=AccumulateGrad]
	1953173114640 -> 1953173115312
	1953000750544 [label="layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000750544 -> 1953173114640
	1953173114640 [label=AccumulateGrad]
	1953173115120 -> 1953173115072
	1953000749024 [label="layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	1953000749024 -> 1953173115120
	1953173115120 [label=AccumulateGrad]
	1953173115888 -> 1953173115072
	1953000737184 [label="layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	1953000737184 -> 1953173115888
	1953173115888 [label=AccumulateGrad]
	1953173115696 -> 1953173116368
	1953000748064 [label="layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000748064 -> 1953173115696
	1953173115696 [label=AccumulateGrad]
	1953173117184 -> 1953173116992
	1953000748944 [label="layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000748944 -> 1953173117184
	1953173117184 [label=AccumulateGrad]
	1953173117136 -> 1953173116992
	1953000748384 [label="layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000748384 -> 1953173117136
	1953173117136 [label=AccumulateGrad]
	1953173116944 -> 1953173117808
	1953173117616 -> 1953173118240
	1953000747744 [label="layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000747744 -> 1953173117616
	1953173117616 [label=AccumulateGrad]
	1953173119056 -> 1953173119008
	1953000735504 [label="layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	1953000735504 -> 1953173119056
	1953173119056 [label=AccumulateGrad]
	1953173118816 -> 1953173119008
	1953000748704 [label="layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	1953000748704 -> 1953173118816
	1953173118816 [label=AccumulateGrad]
	1953173119632 -> 1953173120304
	1953000734864 [label="layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000734864 -> 1953173119632
	1953173119632 [label=AccumulateGrad]
	1953173120112 -> 1953173120064
	1953000748464 [label="layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	1953000748464 -> 1953173120112
	1953173120112 [label=AccumulateGrad]
	1953173120880 -> 1953173120064
	1953000748144 [label="layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	1953000748144 -> 1953173120880
	1953173120880 [label=AccumulateGrad]
	1953173120688 -> 1953173121360
	1953000738624 [label="layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000738624 -> 1953173120688
	1953173120688 [label=AccumulateGrad]
	1953173122176 -> 1953173121984
	1953000737984 [label="layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000737984 -> 1953173122176
	1953173122176 [label=AccumulateGrad]
	1953173122128 -> 1953173121984
	1953000738784 [label="layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000738784 -> 1953173122128
	1953173122128 [label=AccumulateGrad]
	1953173121936 -> 1953173122800
	1953173122608 -> 1953173123232
	1953000747584 [label="layer3.6.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000747584 -> 1953173122608
	1953173122608 [label=AccumulateGrad]
	1953173124048 -> 1953173124000
	1953000745424 [label="layer3.6.bn1.weight
 (256)" fillcolor=lightblue]
	1953000745424 -> 1953173124048
	1953173124048 [label=AccumulateGrad]
	1953173123808 -> 1953173124000
	1953000747024 [label="layer3.6.bn1.bias
 (256)" fillcolor=lightblue]
	1953000747024 -> 1953173123808
	1953173123808 [label=AccumulateGrad]
	1953173124624 -> 1953173125296
	1953000436528 [label="layer3.6.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000436528 -> 1953173124624
	1953173124624 [label=AccumulateGrad]
	1953173125104 -> 1953173125056
	1953000437408 [label="layer3.6.bn2.weight
 (256)" fillcolor=lightblue]
	1953000437408 -> 1953173125104
	1953173125104 [label=AccumulateGrad]
	1953173125872 -> 1953173125056
	1953000426448 [label="layer3.6.bn2.bias
 (256)" fillcolor=lightblue]
	1953000426448 -> 1953173125872
	1953173125872 [label=AccumulateGrad]
	1953173125680 -> 1953173126352
	1953000430208 [label="layer3.6.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000430208 -> 1953173125680
	1953173125680 [label=AccumulateGrad]
	1953173127120 -> 1953173160336
	1953000436128 [label="layer3.6.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000436128 -> 1953173127120
	1953173127120 [label=AccumulateGrad]
	1953173126976 -> 1953173160336
	1953000438288 [label="layer3.6.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000438288 -> 1953173126976
	1953173126976 [label=AccumulateGrad]
	1953173160096 -> 1953173160288
	1953173160192 -> 1953173160480
	1953000428208 [label="layer3.7.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000428208 -> 1953173160192
	1953173160192 [label=AccumulateGrad]
	1953173160912 -> 1953173160864
	1953000428528 [label="layer3.7.bn1.weight
 (256)" fillcolor=lightblue]
	1953000428528 -> 1953173160912
	1953173160912 [label=AccumulateGrad]
	1953173160768 -> 1953173160864
	1953000429248 [label="layer3.7.bn1.bias
 (256)" fillcolor=lightblue]
	1953000429248 -> 1953173160768
	1953173160768 [label=AccumulateGrad]
	1953173161152 -> 1953173161536
	1953000427568 [label="layer3.7.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000427568 -> 1953173161152
	1953173161152 [label=AccumulateGrad]
	1953173161440 -> 1953173161392
	1953000426848 [label="layer3.7.bn2.weight
 (256)" fillcolor=lightblue]
	1953000426848 -> 1953173161440
	1953173161440 [label=AccumulateGrad]
	1953173161776 -> 1953173161392
	1953000425888 [label="layer3.7.bn2.bias
 (256)" fillcolor=lightblue]
	1953000425888 -> 1953173161776
	1953173161776 [label=AccumulateGrad]
	1953173162208 -> 1953173162064
	1953000435728 [label="layer3.7.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000435728 -> 1953173162208
	1953173162208 [label=AccumulateGrad]
	1953173161968 -> 1953173162352
	1953000439008 [label="layer3.7.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000439008 -> 1953173161968
	1953173161968 [label=AccumulateGrad]
	1953173162400 -> 1953173162352
	1953000437968 [label="layer3.7.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000437968 -> 1953173162400
	1953173162400 [label=AccumulateGrad]
	1953173162832 -> 1953173162784
	1953173162688 -> 1953173162976
	1953000438368 [label="layer3.8.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000438368 -> 1953173162688
	1953173162688 [label=AccumulateGrad]
	1953173163408 -> 1953173163360
	1953000437008 [label="layer3.8.bn1.weight
 (256)" fillcolor=lightblue]
	1953000437008 -> 1953173163408
	1953173163408 [label=AccumulateGrad]
	1953173163264 -> 1953173163360
	1953000435088 [label="layer3.8.bn1.bias
 (256)" fillcolor=lightblue]
	1953000435088 -> 1953173163264
	1953173163264 [label=AccumulateGrad]
	1953173163648 -> 1953173164032
	1953000427328 [label="layer3.8.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000427328 -> 1953173163648
	1953173163648 [label=AccumulateGrad]
	1953173163936 -> 1953173163888
	1953000423968 [label="layer3.8.bn2.weight
 (256)" fillcolor=lightblue]
	1953000423968 -> 1953173163936
	1953173163936 [label=AccumulateGrad]
	1953173164272 -> 1953173163888
	1953000428048 [label="layer3.8.bn2.bias
 (256)" fillcolor=lightblue]
	1953000428048 -> 1953173164272
	1953173164272 [label=AccumulateGrad]
	1953173164704 -> 1953173164560
	1953000429408 [label="layer3.8.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000429408 -> 1953173164704
	1953173164704 [label=AccumulateGrad]
	1953173164464 -> 1953173164848
	1953000432768 [label="layer3.8.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000432768 -> 1953173164464
	1953173164464 [label=AccumulateGrad]
	1953173164896 -> 1953173164848
	1953000432128 [label="layer3.8.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000432128 -> 1953173164896
	1953173164896 [label=AccumulateGrad]
	1953173165328 -> 1953173165280
	1953173165184 -> 1953173165472
	1953000432448 [label="layer3.9.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000432448 -> 1953173165184
	1953173165184 [label=AccumulateGrad]
	1953173165904 -> 1953173165856
	1953000435408 [label="layer3.9.bn1.weight
 (256)" fillcolor=lightblue]
	1953000435408 -> 1953173165904
	1953173165904 [label=AccumulateGrad]
	1953173165760 -> 1953173165856
	1953000427008 [label="layer3.9.bn1.bias
 (256)" fillcolor=lightblue]
	1953000427008 -> 1953173165760
	1953173165760 [label=AccumulateGrad]
	1953173166144 -> 1953173166528
	1953000431648 [label="layer3.9.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000431648 -> 1953173166144
	1953173166144 [label=AccumulateGrad]
	1953173166432 -> 1953173166384
	1953000434768 [label="layer3.9.bn2.weight
 (256)" fillcolor=lightblue]
	1953000434768 -> 1953173166432
	1953173166432 [label=AccumulateGrad]
	1953173166768 -> 1953173166384
	1953000429088 [label="layer3.9.bn2.bias
 (256)" fillcolor=lightblue]
	1953000429088 -> 1953173166768
	1953173166768 [label=AccumulateGrad]
	1953173167200 -> 1953173167056
	1953000430528 [label="layer3.9.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000430528 -> 1953173167200
	1953173167200 [label=AccumulateGrad]
	1953173166960 -> 1953173167344
	1953000429568 [label="layer3.9.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000429568 -> 1953173166960
	1953173166960 [label=AccumulateGrad]
	1953173167392 -> 1953173167344
	1953000429888 [label="layer3.9.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000429888 -> 1953173167392
	1953173167392 [label=AccumulateGrad]
	1953173167824 -> 1953173167776
	1953173167680 -> 1953173167968
	1953000504784 [label="layer3.10.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000504784 -> 1953173167680
	1953173167680 [label=AccumulateGrad]
	1953173168400 -> 1953173168352
	1953000489264 [label="layer3.10.bn1.weight
 (256)" fillcolor=lightblue]
	1953000489264 -> 1953173168400
	1953173168400 [label=AccumulateGrad]
	1953173168256 -> 1953173168352
	1953000490624 [label="layer3.10.bn1.bias
 (256)" fillcolor=lightblue]
	1953000490624 -> 1953173168256
	1953173168256 [label=AccumulateGrad]
	1953173168640 -> 1953173169024
	1953000489104 [label="layer3.10.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000489104 -> 1953173168640
	1953173168640 [label=AccumulateGrad]
	1953173168928 -> 1953173168880
	1953000489424 [label="layer3.10.bn2.weight
 (256)" fillcolor=lightblue]
	1953000489424 -> 1953173168928
	1953173168928 [label=AccumulateGrad]
	1953173169264 -> 1953173168880
	1953000490064 [label="layer3.10.bn2.bias
 (256)" fillcolor=lightblue]
	1953000490064 -> 1953173169264
	1953173169264 [label=AccumulateGrad]
	1953173169696 -> 1953173169552
	1953000491344 [label="layer3.10.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000491344 -> 1953173169696
	1953173169696 [label=AccumulateGrad]
	1953173169456 -> 1953173169840
	1953000492224 [label="layer3.10.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000492224 -> 1953173169456
	1953173169456 [label=AccumulateGrad]
	1953173169888 -> 1953173169840
	1953000492544 [label="layer3.10.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000492544 -> 1953173169888
	1953173169888 [label=AccumulateGrad]
	1953173170320 -> 1953173170272
	1953173170176 -> 1953173170464
	1953000491184 [label="layer3.11.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000491184 -> 1953173170176
	1953173170176 [label=AccumulateGrad]
	1953173170896 -> 1953173170848
	1953000491024 [label="layer3.11.bn1.weight
 (256)" fillcolor=lightblue]
	1953000491024 -> 1953173170896
	1953173170896 [label=AccumulateGrad]
	1953173170752 -> 1953173170848
	1953000492704 [label="layer3.11.bn1.bias
 (256)" fillcolor=lightblue]
	1953000492704 -> 1953173170752
	1953173170752 [label=AccumulateGrad]
	1953173171136 -> 1953173171520
	1953000493824 [label="layer3.11.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000493824 -> 1953173171136
	1953173171136 [label=AccumulateGrad]
	1953173171424 -> 1953173171376
	1953000494304 [label="layer3.11.bn2.weight
 (256)" fillcolor=lightblue]
	1953000494304 -> 1953173171424
	1953173171424 [label=AccumulateGrad]
	1953173171760 -> 1953173171376
	1953000493984 [label="layer3.11.bn2.bias
 (256)" fillcolor=lightblue]
	1953000493984 -> 1953173171760
	1953173171760 [label=AccumulateGrad]
	1953173172192 -> 1953173172048
	1953000494944 [label="layer3.11.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000494944 -> 1953173172192
	1953173172192 [label=AccumulateGrad]
	1953173171952 -> 1953173172336
	1953000494464 [label="layer3.11.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000494464 -> 1953173171952
	1953173171952 [label=AccumulateGrad]
	1953173172384 -> 1953173172336
	1953000494144 [label="layer3.11.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000494144 -> 1953173172384
	1953173172384 [label=AccumulateGrad]
	1953173172816 -> 1953173172768
	1953173172672 -> 1953173172960
	1953000495744 [label="layer3.12.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000495744 -> 1953173172672
	1953173172672 [label=AccumulateGrad]
	1953173173392 -> 1953173173344
	1953000495904 [label="layer3.12.bn1.weight
 (256)" fillcolor=lightblue]
	1953000495904 -> 1953173173392
	1953173173392 [label=AccumulateGrad]
	1953173173248 -> 1953173173344
	1953000495584 [label="layer3.12.bn1.bias
 (256)" fillcolor=lightblue]
	1953000495584 -> 1953173173248
	1953173173248 [label=AccumulateGrad]
	1953173173632 -> 1953173174016
	1953000497264 [label="layer3.12.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000497264 -> 1953173173632
	1953173173632 [label=AccumulateGrad]
	1953173173920 -> 1953173173872
	1953000497424 [label="layer3.12.bn2.weight
 (256)" fillcolor=lightblue]
	1953000497424 -> 1953173173920
	1953173173920 [label=AccumulateGrad]
	1953173174256 -> 1953173173872
	1953000497104 [label="layer3.12.bn2.bias
 (256)" fillcolor=lightblue]
	1953000497104 -> 1953173174256
	1953173174256 [label=AccumulateGrad]
	1953173174688 -> 1953173174544
	1953000498064 [label="layer3.12.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000498064 -> 1953173174688
	1953173174688 [label=AccumulateGrad]
	1953173174448 -> 1953173174832
	1953000498704 [label="layer3.12.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000498704 -> 1953173174448
	1953173174448 [label=AccumulateGrad]
	1953173174880 -> 1953173174832
	1953000499504 [label="layer3.12.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000499504 -> 1953173174880
	1953173174880 [label=AccumulateGrad]
	1953173175312 -> 1953173175264
	1953173175168 -> 1953173175456
	1953000499664 [label="layer3.13.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000499664 -> 1953173175168
	1953173175168 [label=AccumulateGrad]
	1953173175888 -> 1953173175840
	1953000499824 [label="layer3.13.bn1.weight
 (256)" fillcolor=lightblue]
	1953000499824 -> 1953173175888
	1953173175888 [label=AccumulateGrad]
	1953173175744 -> 1953173175840
	1953000499344 [label="layer3.13.bn1.bias
 (256)" fillcolor=lightblue]
	1953000499344 -> 1953173175744
	1953173175744 [label=AccumulateGrad]
	1953173176128 -> 1953173160576
	1953000501744 [label="layer3.13.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000501744 -> 1953173176128
	1953173176128 [label=AccumulateGrad]
	1953173160384 -> 1953173161248
	1953000501104 [label="layer3.13.bn2.weight
 (256)" fillcolor=lightblue]
	1953000501104 -> 1953173160384
	1953173160384 [label=AccumulateGrad]
	1953173161056 -> 1953173161248
	1953000502624 [label="layer3.13.bn2.bias
 (256)" fillcolor=lightblue]
	1953000502624 -> 1953173161056
	1953173161056 [label=AccumulateGrad]
	1953173161872 -> 1953173161632
	1953000499184 [label="layer3.13.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000499184 -> 1953173161872
	1953173161872 [label=AccumulateGrad]
	1953173162448 -> 1953173162256
	1953000498864 [label="layer3.13.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000498864 -> 1953173162448
	1953173162448 [label=AccumulateGrad]
	1953173162304 -> 1953173162256
	1953000502784 [label="layer3.13.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000502784 -> 1953173162304
	1953173162304 [label=AccumulateGrad]
	1953173163120 -> 1953173163072
	1953173162880 -> 1953173163504
	1953000504064 [label="layer3.14.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000504064 -> 1953173162880
	1953173162880 [label=AccumulateGrad]
	1953173164320 -> 1953173164176
	1953000503904 [label="layer3.14.bn1.weight
 (256)" fillcolor=lightblue]
	1953000503904 -> 1953173164320
	1953173164320 [label=AccumulateGrad]
	1953173164992 -> 1953173164176
	1953000503744 [label="layer3.14.bn1.bias
 (256)" fillcolor=lightblue]
	1953000503744 -> 1953173164992
	1953173164992 [label=AccumulateGrad]
	1953173164800 -> 1953173165568
	1953000505264 [label="layer3.14.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000505264 -> 1953173164800
	1953173164800 [label=AccumulateGrad]
	1953173165376 -> 1953173166240
	1953000504384 [label="layer3.14.bn2.weight
 (256)" fillcolor=lightblue]
	1953000504384 -> 1953173165376
	1953173165376 [label=AccumulateGrad]
	1953173166048 -> 1953173166240
	1953000503984 [label="layer3.14.bn2.bias
 (256)" fillcolor=lightblue]
	1953000503984 -> 1953173166048
	1953173166048 [label=AccumulateGrad]
	1953173166864 -> 1953173166624
	1953000504624 [label="layer3.14.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000504624 -> 1953173166864
	1953173166864 [label=AccumulateGrad]
	1953173167440 -> 1953173167248
	1953000505184 [label="layer3.14.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000505184 -> 1953173167440
	1953173167440 [label=AccumulateGrad]
	1953173167296 -> 1953173167248
	1953000504864 [label="layer3.14.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000504864 -> 1953173167296
	1953173167296 [label=AccumulateGrad]
	1953173168112 -> 1953173168064
	1953173167872 -> 1953173168496
	1953000500704 [label="layer3.15.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000500704 -> 1953173167872
	1953173167872 [label=AccumulateGrad]
	1953173169312 -> 1953173169168
	1953000500384 [label="layer3.15.bn1.weight
 (256)" fillcolor=lightblue]
	1953000500384 -> 1953173169312
	1953173169312 [label=AccumulateGrad]
	1953173169984 -> 1953173169168
	1953000497184 [label="layer3.15.bn1.bias
 (256)" fillcolor=lightblue]
	1953000497184 -> 1953173169984
	1953173169984 [label=AccumulateGrad]
	1953173169792 -> 1953173170560
	1953000498464 [label="layer3.15.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000498464 -> 1953173169792
	1953173169792 [label=AccumulateGrad]
	1953173170368 -> 1953173171232
	1953000498784 [label="layer3.15.bn2.weight
 (256)" fillcolor=lightblue]
	1953000498784 -> 1953173170368
	1953173170368 [label=AccumulateGrad]
	1953173171040 -> 1953173171232
	1953000495344 [label="layer3.15.bn2.bias
 (256)" fillcolor=lightblue]
	1953000495344 -> 1953173171040
	1953173171040 [label=AccumulateGrad]
	1953173171856 -> 1953173171616
	1953000495984 [label="layer3.15.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000495984 -> 1953173171856
	1953173171856 [label=AccumulateGrad]
	1953173172432 -> 1953173172240
	1953000501024 [label="layer3.15.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000501024 -> 1953173172432
	1953173172432 [label=AccumulateGrad]
	1953173172288 -> 1953173172240
	1953000502384 [label="layer3.15.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000502384 -> 1953173172288
	1953173172288 [label=AccumulateGrad]
	1953173173104 -> 1953173173056
	1953173172864 -> 1953173173488
	1953000493424 [label="layer3.16.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000493424 -> 1953173172864
	1953173172864 [label=AccumulateGrad]
	1953173174304 -> 1953173174160
	1953000492464 [label="layer3.16.bn1.weight
 (256)" fillcolor=lightblue]
	1953000492464 -> 1953173174304
	1953173174304 [label=AccumulateGrad]
	1953173174976 -> 1953173174160
	1953000489344 [label="layer3.16.bn1.bias
 (256)" fillcolor=lightblue]
	1953000489344 -> 1953173174976
	1953173174976 [label=AccumulateGrad]
	1953173174784 -> 1953173175552
	1953000312480 [label="layer3.16.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000312480 -> 1953173174784
	1953173174784 [label=AccumulateGrad]
	1953173175360 -> 1953173176224
	1953000312160 [label="layer3.16.bn2.weight
 (256)" fillcolor=lightblue]
	1953000312160 -> 1953173175360
	1953173175360 [label=AccumulateGrad]
	1953173176032 -> 1953173176224
	1953000312320 [label="layer3.16.bn2.bias
 (256)" fillcolor=lightblue]
	1953000312320 -> 1953173176032
	1953173176032 [label=AccumulateGrad]
	1953173225728 -> 1953173225632
	1953000312880 [label="layer3.16.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000312880 -> 1953173225728
	1953173225728 [label=AccumulateGrad]
	1953173225536 -> 1953173225920
	1953000319600 [label="layer3.16.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000319600 -> 1953173225536
	1953173225536 [label=AccumulateGrad]
	1953173225968 -> 1953173225920
	1953000317040 [label="layer3.16.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000317040 -> 1953173225968
	1953173225968 [label=AccumulateGrad]
	1953173226400 -> 1953173226352
	1953173226256 -> 1953173226544
	1953000312240 [label="layer3.17.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000312240 -> 1953173226256
	1953173226256 [label=AccumulateGrad]
	1953173226976 -> 1953173226928
	1953000315840 [label="layer3.17.bn1.weight
 (256)" fillcolor=lightblue]
	1953000315840 -> 1953173226976
	1953173226976 [label=AccumulateGrad]
	1953173226832 -> 1953173226928
	1953000315760 [label="layer3.17.bn1.bias
 (256)" fillcolor=lightblue]
	1953000315760 -> 1953173226832
	1953173226832 [label=AccumulateGrad]
	1953173227216 -> 1953173227600
	1953000310640 [label="layer3.17.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000310640 -> 1953173227216
	1953173227216 [label=AccumulateGrad]
	1953173227504 -> 1953173227456
	1953000315600 [label="layer3.17.bn2.weight
 (256)" fillcolor=lightblue]
	1953000315600 -> 1953173227504
	1953173227504 [label=AccumulateGrad]
	1953173227840 -> 1953173227456
	1953000310880 [label="layer3.17.bn2.bias
 (256)" fillcolor=lightblue]
	1953000310880 -> 1953173227840
	1953173227840 [label=AccumulateGrad]
	1953173228272 -> 1953173228128
	1953000313280 [label="layer3.17.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000313280 -> 1953173228272
	1953173228272 [label=AccumulateGrad]
	1953173228032 -> 1953173228416
	1953000313600 [label="layer3.17.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000313600 -> 1953173228032
	1953173228032 [label=AccumulateGrad]
	1953173228464 -> 1953173228416
	1953000313920 [label="layer3.17.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000313920 -> 1953173228464
	1953173228464 [label=AccumulateGrad]
	1953173228896 -> 1953173228848
	1953173228752 -> 1953173229040
	1953000316160 [label="layer3.18.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000316160 -> 1953173228752
	1953173228752 [label=AccumulateGrad]
	1953173229472 -> 1953173229424
	1953000314400 [label="layer3.18.bn1.weight
 (256)" fillcolor=lightblue]
	1953000314400 -> 1953173229472
	1953173229472 [label=AccumulateGrad]
	1953173229328 -> 1953173229424
	1953000314720 [label="layer3.18.bn1.bias
 (256)" fillcolor=lightblue]
	1953000314720 -> 1953173229328
	1953173229328 [label=AccumulateGrad]
	1953173229712 -> 1953173230096
	1953000317440 [label="layer3.18.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000317440 -> 1953173229712
	1953173229712 [label=AccumulateGrad]
	1953173230000 -> 1953173229952
	1953000316960 [label="layer3.18.bn2.weight
 (256)" fillcolor=lightblue]
	1953000316960 -> 1953173230000
	1953173230000 [label=AccumulateGrad]
	1953173230336 -> 1953173229952
	1953000317280 [label="layer3.18.bn2.bias
 (256)" fillcolor=lightblue]
	1953000317280 -> 1953173230336
	1953173230336 [label=AccumulateGrad]
	1953173230768 -> 1953173230624
	1953000318240 [label="layer3.18.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000318240 -> 1953173230768
	1953173230768 [label=AccumulateGrad]
	1953173230528 -> 1953173230912
	1953000318720 [label="layer3.18.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000318720 -> 1953173230528
	1953173230528 [label=AccumulateGrad]
	1953173230960 -> 1953173230912
	1953000318560 [label="layer3.18.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000318560 -> 1953173230960
	1953173230960 [label=AccumulateGrad]
	1953173231392 -> 1953173231344
	1953173231248 -> 1953173231536
	1953000319520 [label="layer3.19.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000319520 -> 1953173231248
	1953173231248 [label=AccumulateGrad]
	1953173231968 -> 1953173231920
	1953000320000 [label="layer3.19.bn1.weight
 (256)" fillcolor=lightblue]
	1953000320000 -> 1953173231968
	1953173231968 [label=AccumulateGrad]
	1953173231824 -> 1953173231920
	1953000319840 [label="layer3.19.bn1.bias
 (256)" fillcolor=lightblue]
	1953000319840 -> 1953173231824
	1953173231824 [label=AccumulateGrad]
	1953173232208 -> 1953173232592
	1953000321520 [label="layer3.19.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000321520 -> 1953173232208
	1953173232208 [label=AccumulateGrad]
	1953173232496 -> 1953173232448
	1953000320960 [label="layer3.19.bn2.weight
 (256)" fillcolor=lightblue]
	1953000320960 -> 1953173232496
	1953173232496 [label=AccumulateGrad]
	1953173232832 -> 1953173232448
	1953000321360 [label="layer3.19.bn2.bias
 (256)" fillcolor=lightblue]
	1953000321360 -> 1953173232832
	1953173232832 [label=AccumulateGrad]
	1953173233264 -> 1953173233120
	1953000322640 [label="layer3.19.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000322640 -> 1953173233264
	1953173233264 [label=AccumulateGrad]
	1953173233024 -> 1953173233408
	1953000323520 [label="layer3.19.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000323520 -> 1953173233024
	1953173233024 [label=AccumulateGrad]
	1953173233456 -> 1953173233408
	1953000323120 [label="layer3.19.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000323120 -> 1953173233456
	1953173233456 [label=AccumulateGrad]
	1953173233888 -> 1953173233840
	1953173233744 -> 1953173234032
	1953000324240 [label="layer3.20.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000324240 -> 1953173233744
	1953173233744 [label=AccumulateGrad]
	1953173234464 -> 1953173234416
	1953000324880 [label="layer3.20.bn1.weight
 (256)" fillcolor=lightblue]
	1953000324880 -> 1953173234464
	1953173234464 [label=AccumulateGrad]
	1953173234320 -> 1953173234416
	1953000324560 [label="layer3.20.bn1.bias
 (256)" fillcolor=lightblue]
	1953000324560 -> 1953173234320
	1953173234320 [label=AccumulateGrad]
	1953173234704 -> 1953173235088
	1953000323840 [label="layer3.20.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000323840 -> 1953173234704
	1953173234704 [label=AccumulateGrad]
	1953173234992 -> 1953173234944
	1953000323440 [label="layer3.20.bn2.weight
 (256)" fillcolor=lightblue]
	1953000323440 -> 1953173234992
	1953173234992 [label=AccumulateGrad]
	1953173235328 -> 1953173234944
	1953000322480 [label="layer3.20.bn2.bias
 (256)" fillcolor=lightblue]
	1953000322480 -> 1953173235328
	1953173235328 [label=AccumulateGrad]
	1953173235760 -> 1953173235616
	1953000320080 [label="layer3.20.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000320080 -> 1953173235760
	1953173235760 [label=AccumulateGrad]
	1953173235520 -> 1953173235904
	1953000320400 [label="layer3.20.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000320400 -> 1953173235520
	1953173235520 [label=AccumulateGrad]
	1953173235952 -> 1953173235904
	1953000319440 [label="layer3.20.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000319440 -> 1953173235952
	1953173235952 [label=AccumulateGrad]
	1953173236384 -> 1953173236336
	1953173236240 -> 1953173236528
	1953000317520 [label="layer3.21.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000317520 -> 1953173236240
	1953173236240 [label=AccumulateGrad]
	1953173236960 -> 1953173236912
	1953000317840 [label="layer3.21.bn1.weight
 (256)" fillcolor=lightblue]
	1953000317840 -> 1953173236960
	1953173236960 [label=AccumulateGrad]
	1953173236816 -> 1953173236912
	1953000317200 [label="layer3.21.bn1.bias
 (256)" fillcolor=lightblue]
	1953000317200 -> 1953173236816
	1953173236816 [label=AccumulateGrad]
	1953173237200 -> 1953173237584
	1953000314880 [label="layer3.21.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000314880 -> 1953173237200
	1953173237200 [label=AccumulateGrad]
	1953173237488 -> 1953173237440
	1953000315040 [label="layer3.21.bn2.weight
 (256)" fillcolor=lightblue]
	1953000315040 -> 1953173237488
	1953173237488 [label=AccumulateGrad]
	1953173237824 -> 1953173237440
	1953000315120 [label="layer3.21.bn2.bias
 (256)" fillcolor=lightblue]
	1953000315120 -> 1953173237824
	1953173237824 [label=AccumulateGrad]
	1953173238256 -> 1953173238112
	1953000310480 [label="layer3.21.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000310480 -> 1953173238256
	1953173238256 [label=AccumulateGrad]
	1953173238016 -> 1953173238400
	1953000313040 [label="layer3.21.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000313040 -> 1953173238016
	1953173238016 [label=AccumulateGrad]
	1953173238448 -> 1953173238400
	1953000310800 [label="layer3.21.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000310800 -> 1953173238448
	1953173238448 [label=AccumulateGrad]
	1953173238880 -> 1953173238832
	1953173238736 -> 1953173239024
	1953000314960 [label="layer3.22.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1953000314960 -> 1953173238736
	1953173238736 [label=AccumulateGrad]
	1953173239504 -> 1953173239456
	1953000318000 [label="layer3.22.bn1.weight
 (256)" fillcolor=lightblue]
	1953000318000 -> 1953173239504
	1953173239504 [label=AccumulateGrad]
	1953173239360 -> 1953173239456
	1953000317360 [label="layer3.22.bn1.bias
 (256)" fillcolor=lightblue]
	1953000317360 -> 1953173239360
	1953173239360 [label=AccumulateGrad]
	1953173239264 -> 1953173240128
	1953000324480 [label="layer3.22.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1953000324480 -> 1953173239264
	1953173239264 [label=AccumulateGrad]
	1953173240032 -> 1953173239984
	1953000321440 [label="layer3.22.bn2.weight
 (256)" fillcolor=lightblue]
	1953000321440 -> 1953173240032
	1953173240032 [label=AccumulateGrad]
	1953173239888 -> 1953173239984
	1953000323600 [label="layer3.22.bn2.bias
 (256)" fillcolor=lightblue]
	1953000323600 -> 1953173239888
	1953173239888 [label=AccumulateGrad]
	1953173240272 -> 1953173240656
	1953000317680 [label="layer3.22.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1953000317680 -> 1953173240272
	1953173240272 [label=AccumulateGrad]
	1953173240608 -> 1953173240512
	1953000314000 [label="layer3.22.bn3.weight
 (1024)" fillcolor=lightblue]
	1953000314000 -> 1953173240608
	1953173240608 [label=AccumulateGrad]
	1953173240560 -> 1953173240512
	1953000315200 [label="layer3.22.bn3.bias
 (1024)" fillcolor=lightblue]
	1953000315200 -> 1953173240560
	1953173240560 [label=AccumulateGrad]
	1953173240944 -> 1953173240896
	1953173241232 -> 1953173241568
	1953000311440 [label="layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	1953000311440 -> 1953173241232
	1953173241232 [label=AccumulateGrad]
	1953173241520 -> 1953173241808
	1953000565200 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	1953000565200 -> 1953173241520
	1953173241520 [label=AccumulateGrad]
	1953173226064 -> 1953173241808
	1953000554560 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	1953000554560 -> 1953173226064
	1953173226064 [label=AccumulateGrad]
	1953173225872 -> 1953173226640
	1953000557440 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1953000557440 -> 1953173225872
	1953173225872 [label=AccumulateGrad]
	1953173226496 -> 1953173226448
	1953000567680 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	1953000567680 -> 1953173226496
	1953173226496 [label=AccumulateGrad]
	1953173227264 -> 1953173226448
	1953000559200 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	1953000559200 -> 1953173227264
	1953173227264 [label=AccumulateGrad]
	1953173227072 -> 1953173227744
	1953000558640 [label="layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	1953000558640 -> 1953173227072
	1953173227072 [label=AccumulateGrad]
	1953173227696 -> 1953173228512
	1953000567600 [label="layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	1953000567600 -> 1953173227696
	1953173227696 [label=AccumulateGrad]
	1953173228560 -> 1953173228512
	1953000566320 [label="layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	1953000566320 -> 1953173228560
	1953173228560 [label=AccumulateGrad]
	1953173228368 -> 1953173228320
	1953173228368 -> 1952874310896 [dir=none]
	1952874310896 [label="input
 (1, 2048, 11, 11)" fillcolor=orange]
	1953173228368 -> 1953172323552 [dir=none]
	1953172323552 [label="result1
 (2048)" fillcolor=orange]
	1953173228368 -> 1953172323712 [dir=none]
	1953172323712 [label="result2
 (2048)" fillcolor=orange]
	1953173228368 -> 1953172322832 [dir=none]
	1953172322832 [label="result3
 (0)" fillcolor=orange]
	1953173228368 -> 1953000607632 [dir=none]
	1953000607632 [label="running_mean
 (2048)" fillcolor=orange]
	1953173228368 -> 1953000315520 [dir=none]
	1953000315520 [label="running_var
 (2048)" fillcolor=orange]
	1953173228368 -> 1953000311200 [dir=none]
	1953000311200 [label="weight
 (2048)" fillcolor=orange]
	1953173228368 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1953173225824 -> 1953173228368
	1953173225824 -> 1952874309856 [dir=none]
	1952874309856 [label="input
 (1, 1024, 11, 11)" fillcolor=orange]
	1953173225824 -> 1953000321040 [dir=none]
	1953000321040 [label="weight
 (2048, 1024, 1, 1)" fillcolor=orange]
	1953173225824 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1953173241136 -> 1953173225824
	1953173241136 -> 1953172304928 [dir=none]
	1953172304928 [label="self
 (1, 1024, 21, 21)" fillcolor=orange]
	1953173241136 [label="AvgPool2DBackward0
---------------------------------
ceil_mode        :           True
count_include_pad:          False
divisor_override :           None
kernel_size      :         (2, 2)
padding          :         (0, 0)
self             : [saved tensor]
stride           :         (2, 2)"]
	1953173241280 -> 1953173241136
	1953173241184 -> 1953173225824
	1953000321040 [label="layer4.0.downsample.1.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	1953000321040 -> 1953173241184
	1953173241184 [label=AccumulateGrad]
	1953173227936 -> 1953173228368
	1953000311200 [label="layer4.0.downsample.2.weight
 (2048)" fillcolor=lightblue]
	1953000311200 -> 1953173227936
	1953173227936 [label=AccumulateGrad]
	1953173227888 -> 1953173228368
	1953000324800 [label="layer4.0.downsample.2.bias
 (2048)" fillcolor=lightblue]
	1953000324800 -> 1953173227888
	1953173227888 [label=AccumulateGrad]
	1953173229136 -> 1953173229760
	1953000569200 [label="layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	1953000569200 -> 1953173229136
	1953173229136 [label=AccumulateGrad]
	1953173229616 -> 1953173229568
	1953000559040 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	1953000559040 -> 1953173229616
	1953173229616 [label=AccumulateGrad]
	1953173230384 -> 1953173229568
	1953000563920 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	1953000563920 -> 1953173230384
	1953173230384 [label=AccumulateGrad]
	1953173230192 -> 1953173230864
	1953000556480 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1953000556480 -> 1953173230192
	1953173230192 [label=AccumulateGrad]
	1953173230816 -> 1953173231680
	1953000562160 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	1953000562160 -> 1953173230816
	1953173230816 [label=AccumulateGrad]
	1953173231488 -> 1953173231680
	1953000555760 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	1953000555760 -> 1953173231488
	1953173231488 [label=AccumulateGrad]
	1953173232304 -> 1953173232064
	1953000559360 [label="layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	1953000559360 -> 1953173232304
	1953173232304 [label=AccumulateGrad]
	1953173232928 -> 1953173232736
	1953000560960 [label="layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	1953000560960 -> 1953173232928
	1953173232928 [label=AccumulateGrad]
	1953173232880 -> 1953173232736
	1953000560640 [label="layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	1953000560640 -> 1953173232880
	1953173232880 [label=AccumulateGrad]
	1953173232688 -> 1953173233552
	1953173233360 -> 1953173233984
	1953000563760 [label="layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	1953000563760 -> 1953173233360
	1953173233360 [label=AccumulateGrad]
	1953173233936 -> 1953173234800
	1953000562960 [label="layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	1953000562960 -> 1953173233936
	1953173233936 [label=AccumulateGrad]
	1953173234608 -> 1953173234800
	1953000566640 [label="layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	1953000566640 -> 1953173234608
	1953173234608 [label=AccumulateGrad]
	1953173235424 -> 1953173235184
	1953000566800 [label="layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1953000566800 -> 1953173235424
	1953173235424 [label=AccumulateGrad]
	1953173236048 -> 1953173236000
	1953000565840 [label="layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	1953000565840 -> 1953173236048
	1953173236048 [label=AccumulateGrad]
	1953173235808 -> 1953173236000
	1953000564720 [label="layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	1953000564720 -> 1953173235808
	1953173235808 [label=AccumulateGrad]
	1953173236624 -> 1953173237296
	1953000568400 [label="layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	1953000568400 -> 1953173236624
	1953173236624 [label=AccumulateGrad]
	1953173237248 -> 1953173237056
	1953000568080 [label="layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	1953000568080 -> 1953173237248
	1953173237248 [label=AccumulateGrad]
	1953173237104 -> 1953173237056
	1953000569040 [label="layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	1953000569040 -> 1953173237104
	1953173237104 [label=AccumulateGrad]
	1953173237920 -> 1953173237872
	1953173238304 -> 1953173239792
	1953173238304 [label=TBackward0]
	1953173237728 -> 1953173238304
	1953000316880 [label="fc.weight
 (4, 2048)" fillcolor=lightblue]
	1953000316880 -> 1953173237728
	1953173237728 [label=AccumulateGrad]
	1953173239792 -> 1953000314480
}
