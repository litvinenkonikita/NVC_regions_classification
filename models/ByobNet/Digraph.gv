digraph {
	graph [size="389.7,389.7"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1267568940256 [label="
 (1, 4)" fillcolor=darkolivegreen1]
	1267569833536 -> 1267568940096 [dir=none]
	1267568940096 [label="mat1
 (1, 2048)" fillcolor=orange]
	1267569833536 -> 1267568962800 [dir=none]
	1267568962800 [label="mat2
 (2048, 4)" fillcolor=orange]
	1267569833536 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :      (1, 2048)
mat1_sym_strides:      (2048, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (2048, 4)
mat2_sym_strides:      (1, 2048)"]
	1267569832096 -> 1267569833536
	1267420127184 [label="head.fc.bias
 (4)" fillcolor=lightblue]
	1267420127184 -> 1267569832096
	1267569832096 [label=AccumulateGrad]
	1267569832912 -> 1267569833536
	1267569832912 [label="ReshapeAliasBackward0
-------------------------------
self_sym_sizes: (1, 2048, 1, 1)"]
	1267569832768 -> 1267569832912
	1267569832768 -> 1267569889328 [dir=none]
	1267569889328 [label="self
 (1, 2048, 11, 11)" fillcolor=orange]
	1267569832768 [label="MeanBackward1
----------------------------------------
dim           : (4294967295, 4294967294)
keepdim       :                     True
self          :           [saved tensor]
self_sym_sizes:        (1, 2048, 11, 11)"]
	1267569832336 -> 1267569832768
	1267569832336 -> 1267568960560 [dir=none]
	1267568960560 [label="self
 (1, 2048, 11, 11)" fillcolor=orange]
	1267569832336 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569831520 -> 1267569832336
	1267569831520 -> 1267569890288 [dir=none]
	1267569890288 [label="input
 (1, 2048, 11, 11)" fillcolor=orange]
	1267569831520 -> 1267568952160 [dir=none]
	1267568952160 [label="result1
 (2048)" fillcolor=orange]
	1267569831520 -> 1267568964960 [dir=none]
	1267568964960 [label="result2
 (2048)" fillcolor=orange]
	1267569831520 -> 1267568966560 [dir=none]
	1267568966560 [label="result3
 (0)" fillcolor=orange]
	1267569831520 -> 1267420235872 [dir=none]
	1267420235872 [label="running_mean
 (2048)" fillcolor=orange]
	1267569831520 -> 1267420129664 [dir=none]
	1267420129664 [label="running_var
 (2048)" fillcolor=orange]
	1267569831520 -> 1267420134384 [dir=none]
	1267420134384 [label="weight
 (2048)" fillcolor=orange]
	1267569831520 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569831712 -> 1267569831520
	1267569831712 -> 1267568940336 [dir=none]
	1267568940336 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569831712 -> 1267420134064 [dir=none]
	1267420134064 [label="weight
 (2048, 1536, 1, 1)" fillcolor=orange]
	1267569831712 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569831088 -> 1267569831712
	1267569831088 -> 1267568966320 [dir=none]
	1267568966320 [label="self
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569831088 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569830416 -> 1267569831088
	1267569830416 [label="AddBackward0
------------
alpha: 1"]
	1267569829600 -> 1267569830416
	1267569829600 -> 1267568939776 [dir=none]
	1267568939776 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569829600 -> 1267568951360 [dir=none]
	1267568951360 [label="result1
 (1536)" fillcolor=orange]
	1267569829600 -> 1267568951840 [dir=none]
	1267568951840 [label="result2
 (1536)" fillcolor=orange]
	1267569829600 -> 1267568951760 [dir=none]
	1267568951760 [label="result3
 (0)" fillcolor=orange]
	1267569829600 -> 1267420133104 [dir=none]
	1267420133104 [label="running_mean
 (1536)" fillcolor=orange]
	1267569829600 -> 1267420130944 [dir=none]
	1267420130944 [label="running_var
 (1536)" fillcolor=orange]
	1267569829600 -> 1267420132544 [dir=none]
	1267420132544 [label="weight
 (1536)" fillcolor=orange]
	1267569829600 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569829840 -> 1267569829600
	1267569829840 -> 1267568939616 [dir=none]
	1267568939616 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569829840 -> 1267420132704 [dir=none]
	1267420132704 [label="weight
 (1536, 1536, 1, 1)" fillcolor=orange]
	1267569829840 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569829216 -> 1267569829840
	1267569829216 -> 1267568951600 [dir=none]
	1267568951600 [label="self
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569829216 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569828544 -> 1267569829216
	1267569828544 -> 1267568939856 [dir=none]
	1267568939856 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569828544 -> 1267568952320 [dir=none]
	1267568952320 [label="result1
 (1536)" fillcolor=orange]
	1267569828544 -> 1267568952080 [dir=none]
	1267568952080 [label="result2
 (1536)" fillcolor=orange]
	1267569828544 -> 1267568952240 [dir=none]
	1267568952240 [label="result3
 (0)" fillcolor=orange]
	1267569828544 -> 1267420130624 [dir=none]
	1267420130624 [label="running_mean
 (1536)" fillcolor=orange]
	1267569828544 -> 1267420130464 [dir=none]
	1267420130464 [label="running_var
 (1536)" fillcolor=orange]
	1267569828544 -> 1267420132864 [dir=none]
	1267420132864 [label="weight
 (1536)" fillcolor=orange]
	1267569828544 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569827728 -> 1267569828544
	1267569827728 -> 1267568940016 [dir=none]
	1267568940016 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569827728 -> 1267420132384 [dir=none]
	1267420132384 [label="weight
 (1536, 1, 3, 3)" fillcolor=orange]
	1267569827728 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1536
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569827104 -> 1267569827728
	1267569827104 -> 1267568952800 [dir=none]
	1267568952800 [label="self
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569827104 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569827344 -> 1267569827104
	1267569827344 -> 1267568939376 [dir=none]
	1267568939376 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569827344 -> 1267568952000 [dir=none]
	1267568952000 [label="result1
 (1536)" fillcolor=orange]
	1267569827344 -> 1267568952560 [dir=none]
	1267568952560 [label="result2
 (1536)" fillcolor=orange]
	1267569827344 -> 1267568952720 [dir=none]
	1267568952720 [label="result3
 (0)" fillcolor=orange]
	1267569827344 -> 1267420130144 [dir=none]
	1267420130144 [label="running_mean
 (1536)" fillcolor=orange]
	1267569827344 -> 1267420130304 [dir=none]
	1267420130304 [label="running_var
 (1536)" fillcolor=orange]
	1267569827344 -> 1267420131104 [dir=none]
	1267420131104 [label="weight
 (1536)" fillcolor=orange]
	1267569827344 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569826528 -> 1267569827344
	1267569826528 -> 1267568939296 [dir=none]
	1267568939296 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569826528 -> 1267420131904 [dir=none]
	1267420131904 [label="weight
 (1536, 1, 3, 3)" fillcolor=orange]
	1267569826528 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1536
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569825904 -> 1267569826528
	1267569825904 -> 1267568953200 [dir=none]
	1267568953200 [label="self
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569825904 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569825232 -> 1267569825904
	1267569825232 -> 1267568938896 [dir=none]
	1267568938896 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569825232 -> 1267568952400 [dir=none]
	1267568952400 [label="result1
 (1536)" fillcolor=orange]
	1267569825232 -> 1267568952960 [dir=none]
	1267568952960 [label="result2
 (1536)" fillcolor=orange]
	1267569825232 -> 1267568953040 [dir=none]
	1267568953040 [label="result3
 (0)" fillcolor=orange]
	1267569825232 -> 1267420128864 [dir=none]
	1267420128864 [label="running_mean
 (1536)" fillcolor=orange]
	1267569825232 -> 1267420128064 [dir=none]
	1267420128064 [label="running_var
 (1536)" fillcolor=orange]
	1267569825232 -> 1267420128224 [dir=none]
	1267420128224 [label="weight
 (1536)" fillcolor=orange]
	1267569825232 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569825424 -> 1267569825232
	1267569825424 -> 1267568939536 [dir=none]
	1267568939536 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569825424 -> 1267420127824 [dir=none]
	1267420127824 [label="weight
 (1536, 1536, 1, 1)" fillcolor=orange]
	1267569825424 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569830464 -> 1267569825424
	1267569830464 -> 1267568953280 [dir=none]
	1267568953280 [label="self
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569830464 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569823984 -> 1267569830464
	1267569823984 [label="AddBackward0
------------
alpha: 1"]
	1267569824176 -> 1267569823984
	1267569824176 -> 1267568938816 [dir=none]
	1267568938816 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569824176 -> 1267568953680 [dir=none]
	1267568953680 [label="result1
 (1536)" fillcolor=orange]
	1267569824176 -> 1267568953440 [dir=none]
	1267568953440 [label="result2
 (1536)" fillcolor=orange]
	1267569824176 -> 1267568953520 [dir=none]
	1267568953520 [label="result3
 (0)" fillcolor=orange]
	1267569824176 -> 1267420126704 [dir=none]
	1267420126704 [label="running_mean
 (1536)" fillcolor=orange]
	1267569824176 -> 1267420125744 [dir=none]
	1267420125744 [label="running_var
 (1536)" fillcolor=orange]
	1267569824176 -> 1267420127664 [dir=none]
	1267420127664 [label="weight
 (1536)" fillcolor=orange]
	1267569824176 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569823408 -> 1267569824176
	1267569823408 -> 1267568939056 [dir=none]
	1267568939056 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569823408 -> 1267420128384 [dir=none]
	1267420128384 [label="weight
 (1536, 1536, 1, 1)" fillcolor=orange]
	1267569823408 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569822784 -> 1267569823408
	1267569822784 -> 1267568953760 [dir=none]
	1267568953760 [label="self
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569822784 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569822112 -> 1267569822784
	1267569822112 -> 1267568939136 [dir=none]
	1267568939136 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569822112 -> 1267568954000 [dir=none]
	1267568954000 [label="result1
 (1536)" fillcolor=orange]
	1267569822112 -> 1267568953920 [dir=none]
	1267568953920 [label="result2
 (1536)" fillcolor=orange]
	1267569822112 -> 1267568954160 [dir=none]
	1267568954160 [label="result3
 (0)" fillcolor=orange]
	1267569822112 -> 1267420126544 [dir=none]
	1267420126544 [label="running_mean
 (1536)" fillcolor=orange]
	1267569822112 -> 1267420125904 [dir=none]
	1267420125904 [label="running_var
 (1536)" fillcolor=orange]
	1267569822112 -> 1267420126864 [dir=none]
	1267420126864 [label="weight
 (1536)" fillcolor=orange]
	1267569822112 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569822304 -> 1267569822112
	1267569822304 -> 1267568938416 [dir=none]
	1267568938416 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569822304 -> 1267420127024 [dir=none]
	1267420127024 [label="weight
 (1536, 1, 3, 3)" fillcolor=orange]
	1267569822304 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1536
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569821680 -> 1267569822304
	1267569821680 -> 1267568954240 [dir=none]
	1267568954240 [label="self
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569821680 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569820912 -> 1267569821680
	1267569820912 -> 1267568938336 [dir=none]
	1267568938336 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569820912 -> 1267568962560 [dir=none]
	1267568962560 [label="result1
 (1536)" fillcolor=orange]
	1267569820912 -> 1267568954720 [dir=none]
	1267568954720 [label="result2
 (1536)" fillcolor=orange]
	1267569820912 -> 1267568954640 [dir=none]
	1267568954640 [label="result3
 (0)" fillcolor=orange]
	1267569820912 -> 1268582176528 [dir=none]
	1268582176528 [label="running_mean
 (1536)" fillcolor=orange]
	1267569820912 -> 1267420125104 [dir=none]
	1267420125104 [label="running_var
 (1536)" fillcolor=orange]
	1267569820912 -> 1267420124784 [dir=none]
	1267420124784 [label="weight
 (1536)" fillcolor=orange]
	1267569820912 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569821104 -> 1267569820912
	1267569821104 -> 1267568938576 [dir=none]
	1267568938576 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569821104 -> 1267420124464 [dir=none]
	1267420124464 [label="weight
 (1536, 1, 3, 3)" fillcolor=orange]
	1267569821104 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1536
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569820480 -> 1267569821104
	1267569820480 -> 1267568955200 [dir=none]
	1267568955200 [label="self
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569820480 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569835936 -> 1267569820480
	1267569835936 -> 1267568938176 [dir=none]
	1267568938176 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569835936 -> 1267568954400 [dir=none]
	1267568954400 [label="result1
 (1536)" fillcolor=orange]
	1267569835936 -> 1267568955120 [dir=none]
	1267568955120 [label="result2
 (1536)" fillcolor=orange]
	1267569835936 -> 1267568954880 [dir=none]
	1267568954880 [label="result3
 (0)" fillcolor=orange]
	1267569835936 -> 1267420121984 [dir=none]
	1267420121984 [label="running_mean
 (1536)" fillcolor=orange]
	1267569835936 -> 1267420122464 [dir=none]
	1267420122464 [label="running_var
 (1536)" fillcolor=orange]
	1267569835936 -> 1267420124624 [dir=none]
	1267420124624 [label="weight
 (1536)" fillcolor=orange]
	1267569835936 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569835984 -> 1267569835936
	1267569835984 -> 1267568938656 [dir=none]
	1267568938656 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569835984 -> 1267420124144 [dir=none]
	1267420124144 [label="weight
 (1536, 1536, 1, 1)" fillcolor=orange]
	1267569835984 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569824032 -> 1267569835984
	1267569824032 -> 1267568954480 [dir=none]
	1267568954480 [label="self
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569824032 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569835360 -> 1267569824032
	1267569835360 [label="AddBackward0
------------
alpha: 1"]
	1267569834976 -> 1267569835360
	1267569834976 -> 1267568937936 [dir=none]
	1267568937936 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569834976 -> 1267568955680 [dir=none]
	1267568955680 [label="result1
 (1536)" fillcolor=orange]
	1267569834976 -> 1267568955600 [dir=none]
	1267568955600 [label="result2
 (1536)" fillcolor=orange]
	1267569834976 -> 1267568955360 [dir=none]
	1267568955360 [label="result3
 (0)" fillcolor=orange]
	1267569834976 -> 1267420122944 [dir=none]
	1267420122944 [label="running_mean
 (1536)" fillcolor=orange]
	1267569834976 -> 1267420120544 [dir=none]
	1267420120544 [label="running_var
 (1536)" fillcolor=orange]
	1267569834976 -> 1267420123504 [dir=none]
	1267420123504 [label="weight
 (1536)" fillcolor=orange]
	1267569834976 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569835120 -> 1267569834976
	1267569835120 -> 1267568938096 [dir=none]
	1267568938096 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569835120 -> 1267420123824 [dir=none]
	1267420123824 [label="weight
 (1536, 1536, 1, 1)" fillcolor=orange]
	1267569835120 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569834304 -> 1267569835120
	1267569834304 -> 1267568954960 [dir=none]
	1267568954960 [label="self
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569834304 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569834448 -> 1267569834304
	1267569834448 -> 1267568937696 [dir=none]
	1267568937696 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569834448 -> 1267568956160 [dir=none]
	1267568956160 [label="result1
 (1536)" fillcolor=orange]
	1267569834448 -> 1267568956080 [dir=none]
	1267568956080 [label="result2
 (1536)" fillcolor=orange]
	1267569834448 -> 1267568955840 [dir=none]
	1267568955840 [label="result3
 (0)" fillcolor=orange]
	1267569834448 -> 1267420120864 [dir=none]
	1267420120864 [label="running_mean
 (1536)" fillcolor=orange]
	1267569834448 -> 1267420121504 [dir=none]
	1267420121504 [label="running_var
 (1536)" fillcolor=orange]
	1267569834448 -> 1267420121664 [dir=none]
	1267420121664 [label="weight
 (1536)" fillcolor=orange]
	1267569834448 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569834064 -> 1267569834448
	1267569834064 -> 1267568937616 [dir=none]
	1267568937616 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569834064 -> 1267420121824 [dir=none]
	1267420121824 [label="weight
 (1536, 1, 3, 3)" fillcolor=orange]
	1267569834064 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1536
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569833776 -> 1267569834064
	1267569833776 -> 1267568956400 [dir=none]
	1267568956400 [label="self
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569833776 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569833920 -> 1267569833776
	1267569833920 -> 1267568937856 [dir=none]
	1267568937856 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569833920 -> 1267568955440 [dir=none]
	1267568955440 [label="result1
 (1536)" fillcolor=orange]
	1267569833920 -> 1267568956320 [dir=none]
	1267568956320 [label="result2
 (1536)" fillcolor=orange]
	1267569833920 -> 1267568956880 [dir=none]
	1267568956880 [label="result3
 (0)" fillcolor=orange]
	1267569833920 -> 1267420120224 [dir=none]
	1267420120224 [label="running_mean
 (1536)" fillcolor=orange]
	1267569833920 -> 1267420120064 [dir=none]
	1267420120064 [label="running_var
 (1536)" fillcolor=orange]
	1267569833920 -> 1267420119904 [dir=none]
	1267420119904 [label="weight
 (1536)" fillcolor=orange]
	1267569833920 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569833488 -> 1267569833920
	1267569833488 -> 1267568937216 [dir=none]
	1267568937216 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569833488 -> 1267420119584 [dir=none]
	1267420119584 [label="weight
 (1536, 1, 3, 3)" fillcolor=orange]
	1267569833488 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1536
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569833200 -> 1267569833488
	1267569833200 -> 1267568956560 [dir=none]
	1267568956560 [label="self
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569833200 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569832816 -> 1267569833200
	1267569832816 -> 1267568937376 [dir=none]
	1267568937376 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569832816 -> 1267568955920 [dir=none]
	1267568955920 [label="result1
 (1536)" fillcolor=orange]
	1267569832816 -> 1267568956640 [dir=none]
	1267568956640 [label="result2
 (1536)" fillcolor=orange]
	1267569832816 -> 1267568957280 [dir=none]
	1267568957280 [label="result3
 (0)" fillcolor=orange]
	1267569832816 -> 1267420057648 [dir=none]
	1267420057648 [label="running_mean
 (1536)" fillcolor=orange]
	1267569832816 -> 1267420056688 [dir=none]
	1267420056688 [label="running_var
 (1536)" fillcolor=orange]
	1267569832816 -> 1267420121424 [dir=none]
	1267420121424 [label="weight
 (1536)" fillcolor=orange]
	1267569832816 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569832432 -> 1267569832816
	1267569832432 -> 1267568949216 [dir=none]
	1267568949216 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569832432 -> 1267420120784 [dir=none]
	1267420120784 [label="weight
 (1536, 1536, 1, 1)" fillcolor=orange]
	1267569832432 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569834928 -> 1267569832432
	1267569834928 -> 1267568956800 [dir=none]
	1267568956800 [label="self
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569834928 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569832192 -> 1267569834928
	1267569832192 [label="AddBackward0
------------
alpha: 1"]
	1267569831808 -> 1267569832192
	1267569831808 -> 1267568937456 [dir=none]
	1267568937456 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569831808 -> 1267568957040 [dir=none]
	1267568957040 [label="result1
 (1536)" fillcolor=orange]
	1267569831808 -> 1267568957600 [dir=none]
	1267568957600 [label="result2
 (1536)" fillcolor=orange]
	1267569831808 -> 1267568957360 [dir=none]
	1267568957360 [label="result3
 (0)" fillcolor=orange]
	1267569831808 -> 1267420063568 [dir=none]
	1267420063568 [label="running_mean
 (1536)" fillcolor=orange]
	1267569831808 -> 1267420067488 [dir=none]
	1267420067488 [label="running_var
 (1536)" fillcolor=orange]
	1267569831808 -> 1267420066528 [dir=none]
	1267420066528 [label="weight
 (1536)" fillcolor=orange]
	1267569831808 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569831952 -> 1267569831808
	1267569831952 -> 1267568936256 [dir=none]
	1267568936256 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569831952 -> 1267420057968 [dir=none]
	1267420057968 [label="weight
 (1536, 1536, 1, 1)" fillcolor=orange]
	1267569831952 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569831616 -> 1267569831952
	1267569831616 -> 1267568957120 [dir=none]
	1267568957120 [label="self
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569831616 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569831280 -> 1267569831616
	1267569831280 -> 1267568936176 [dir=none]
	1267568936176 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569831280 -> 1267568958080 [dir=none]
	1267568958080 [label="result1
 (1536)" fillcolor=orange]
	1267569831280 -> 1267568958000 [dir=none]
	1267568958000 [label="result2
 (1536)" fillcolor=orange]
	1267569831280 -> 1267568957760 [dir=none]
	1267568957760 [label="result3
 (0)" fillcolor=orange]
	1267569831280 -> 1267420066848 [dir=none]
	1267420066848 [label="running_mean
 (1536)" fillcolor=orange]
	1267569831280 -> 1267420069488 [dir=none]
	1267420069488 [label="running_var
 (1536)" fillcolor=orange]
	1267569831280 -> 1267420066208 [dir=none]
	1267420066208 [label="weight
 (1536)" fillcolor=orange]
	1267569831280 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569831424 -> 1267569831280
	1267569831424 -> 1267568936416 [dir=none]
	1267568936416 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569831424 -> 1267420064928 [dir=none]
	1267420064928 [label="weight
 (1536, 1, 3, 3)" fillcolor=orange]
	1267569831424 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1536
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569830608 -> 1267569831424
	1267569830608 -> 1267568958480 [dir=none]
	1267568958480 [label="self
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569830608 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569830752 -> 1267569830608
	1267569830752 -> 1267568936976 [dir=none]
	1267568936976 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569830752 -> 1267568957520 [dir=none]
	1267568957520 [label="result1
 (1536)" fillcolor=orange]
	1267569830752 -> 1267568958320 [dir=none]
	1267568958320 [label="result2
 (1536)" fillcolor=orange]
	1267569830752 -> 1267568958240 [dir=none]
	1267568958240 [label="result3
 (0)" fillcolor=orange]
	1267569830752 -> 1267420057808 [dir=none]
	1267420057808 [label="running_mean
 (1536)" fillcolor=orange]
	1267569830752 -> 1267420063248 [dir=none]
	1267420063248 [label="running_var
 (1536)" fillcolor=orange]
	1267569830752 -> 1267420063888 [dir=none]
	1267420063888 [label="weight
 (1536)" fillcolor=orange]
	1267569830752 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569830368 -> 1267569830752
	1267569830368 -> 1267568936016 [dir=none]
	1267568936016 [label="input
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569830368 -> 1267420061808 [dir=none]
	1267420061808 [label="weight
 (1536, 1, 3, 3)" fillcolor=orange]
	1267569830368 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1536
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	1267569830080 -> 1267569830368
	1267569830080 -> 1267568958800 [dir=none]
	1267568958800 [label="self
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569830080 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569829696 -> 1267569830080
	1267569829696 -> 1267568935936 [dir=none]
	1267568935936 [label="input
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569829696 -> 1267568957840 [dir=none]
	1267568957840 [label="result1
 (1536)" fillcolor=orange]
	1267569829696 -> 1267568958560 [dir=none]
	1267568958560 [label="result2
 (1536)" fillcolor=orange]
	1267569829696 -> 1267568958720 [dir=none]
	1267568958720 [label="result3
 (0)" fillcolor=orange]
	1267569829696 -> 1267420067168 [dir=none]
	1267420067168 [label="running_mean
 (1536)" fillcolor=orange]
	1267569829696 -> 1267420058848 [dir=none]
	1267420058848 [label="running_var
 (1536)" fillcolor=orange]
	1267569829696 -> 1267420059168 [dir=none]
	1267420059168 [label="weight
 (1536)" fillcolor=orange]
	1267569829696 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569829360 -> 1267569829696
	1267569829360 -> 1267568935776 [dir=none]
	1267568935776 [label="input
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569829360 -> 1267420059888 [dir=none]
	1267420059888 [label="weight
 (1536, 1536, 1, 1)" fillcolor=orange]
	1267569829360 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569829552 -> 1267569829360
	1267569829552 -> 1267568958960 [dir=none]
	1267568958960 [label="self
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569829552 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569828688 -> 1267569829552
	1267569828688 [label="AddBackward0
------------
alpha: 1"]
	1267569828784 -> 1267569828688
	1267569828784 -> 1267568935456 [dir=none]
	1267568935456 [label="input
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569828784 -> 1267568959200 [dir=none]
	1267568959200 [label="result1
 (1536)" fillcolor=orange]
	1267569828784 -> 1267568959040 [dir=none]
	1267568959040 [label="result2
 (1536)" fillcolor=orange]
	1267569828784 -> 1267568959760 [dir=none]
	1267568959760 [label="result3
 (0)" fillcolor=orange]
	1267569828784 -> 1267420055728 [dir=none]
	1267420055728 [label="running_mean
 (1536)" fillcolor=orange]
	1267569828784 -> 1267420055408 [dir=none]
	1267420055408 [label="running_var
 (1536)" fillcolor=orange]
	1267569828784 -> 1267420057168 [dir=none]
	1267420057168 [label="weight
 (1536)" fillcolor=orange]
	1267569828784 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569828448 -> 1267569828784
	1267569828448 -> 1267568935296 [dir=none]
	1267568935296 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569828448 -> 1267420056528 [dir=none]
	1267420056528 [label="weight
 (1536, 384, 1, 1)" fillcolor=orange]
	1267569828448 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569828160 -> 1267569828448
	1267569828160 -> 1267568959680 [dir=none]
	1267568959680 [label="self
 (1, 384, 21, 21)" fillcolor=orange]
	1267569828160 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569828304 -> 1267569828160
	1267569828304 -> 1267568935536 [dir=none]
	1267568935536 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569828304 -> 1267568959280 [dir=none]
	1267568959280 [label="result1
 (384)" fillcolor=orange]
	1267569828304 -> 1267568959440 [dir=none]
	1267568959440 [label="result2
 (384)" fillcolor=orange]
	1267569828304 -> 1267568960000 [dir=none]
	1267568960000 [label="result3
 (0)" fillcolor=orange]
	1267569828304 -> 1267420056368 [dir=none]
	1267420056368 [label="running_mean
 (384)" fillcolor=orange]
	1267569828304 -> 1267420056048 [dir=none]
	1267420056048 [label="running_var
 (384)" fillcolor=orange]
	1267569828304 -> 1267420059008 [dir=none]
	1267420059008 [label="weight
 (384)" fillcolor=orange]
	1267569828304 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569827440 -> 1267569828304
	1267569827440 -> 1267568935696 [dir=none]
	1267568935696 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569827440 -> 1267420054128 [dir=none]
	1267420054128 [label="weight
 (384, 32, 3, 3)" fillcolor=orange]
	1267569827440 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             12
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569827632 -> 1267569827440
	1267569827632 -> 1267568959920 [dir=none]
	1267568959920 [label="self
 (1, 384, 21, 21)" fillcolor=orange]
	1267569827632 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569827248 -> 1267569827632
	1267569827248 -> 1267568935216 [dir=none]
	1267568935216 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569827248 -> 1267568960160 [dir=none]
	1267568960160 [label="result1
 (384)" fillcolor=orange]
	1267569827248 -> 1267568959520 [dir=none]
	1267568959520 [label="result2
 (384)" fillcolor=orange]
	1267569827248 -> 1267568960480 [dir=none]
	1267568960480 [label="result3
 (0)" fillcolor=orange]
	1267569827248 -> 1267420059328 [dir=none]
	1267420059328 [label="running_mean
 (384)" fillcolor=orange]
	1267569827248 -> 1267420060048 [dir=none]
	1267420060048 [label="running_var
 (384)" fillcolor=orange]
	1267569827248 -> 1267420061008 [dir=none]
	1267420061008 [label="weight
 (384)" fillcolor=orange]
	1267569827248 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569826912 -> 1267569827248
	1267569826912 -> 1267568944016 [dir=none]
	1267568944016 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569826912 -> 1267420054688 [dir=none]
	1267420054688 [label="weight
 (384, 32, 3, 3)" fillcolor=orange]
	1267569826912 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             12
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569826576 -> 1267569826912
	1267569826576 -> 1267568960240 [dir=none]
	1267568960240 [label="self
 (1, 384, 21, 21)" fillcolor=orange]
	1267569826576 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569826240 -> 1267569826576
	1267569826240 -> 1267568935616 [dir=none]
	1267568935616 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569826240 -> 1267568960400 [dir=none]
	1267568960400 [label="result1
 (384)" fillcolor=orange]
	1267569826240 -> 1267568960640 [dir=none]
	1267568960640 [label="result2
 (384)" fillcolor=orange]
	1267569826240 -> 1267568960880 [dir=none]
	1267568960880 [label="result3
 (0)" fillcolor=orange]
	1267569826240 -> 1267420060688 [dir=none]
	1267420060688 [label="running_mean
 (384)" fillcolor=orange]
	1267569826240 -> 1267420066448 [dir=none]
	1267420066448 [label="running_var
 (384)" fillcolor=orange]
	1267569826240 -> 1267420067968 [dir=none]
	1267420067968 [label="weight
 (384)" fillcolor=orange]
	1267569826240 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569826384 -> 1267569826240
	1267569826384 -> 1267568935056 [dir=none]
	1267568935056 [label="input
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569826384 -> 1267420067888 [dir=none]
	1267420067888 [label="weight
 (384, 1536, 1, 1)" fillcolor=orange]
	1267569826384 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569828736 -> 1267569826384
	1267569828736 -> 1267568960960 [dir=none]
	1267568960960 [label="self
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569828736 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569825664 -> 1267569828736
	1267569825664 [label="AddBackward0
------------
alpha: 1"]
	1267569825760 -> 1267569825664
	1267569825760 -> 1267568942096 [dir=none]
	1267568942096 [label="input
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569825760 -> 1267568961440 [dir=none]
	1267568961440 [label="result1
 (1536)" fillcolor=orange]
	1267569825760 -> 1267568961360 [dir=none]
	1267568961360 [label="result2
 (1536)" fillcolor=orange]
	1267569825760 -> 1267568961120 [dir=none]
	1267568961120 [label="result3
 (0)" fillcolor=orange]
	1267569825760 -> 1267420066048 [dir=none]
	1267420066048 [label="running_mean
 (1536)" fillcolor=orange]
	1267569825760 -> 1267420364944 [dir=none]
	1267420364944 [label="running_var
 (1536)" fillcolor=orange]
	1267569825760 -> 1267420056768 [dir=none]
	1267420056768 [label="weight
 (1536)" fillcolor=orange]
	1267569825760 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569824944 -> 1267569825760
	1267569824944 -> 1267568936656 [dir=none]
	1267568936656 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569824944 -> 1267420068528 [dir=none]
	1267420068528 [label="weight
 (1536, 384, 1, 1)" fillcolor=orange]
	1267569824944 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569825136 -> 1267569824944
	1267569825136 -> 1267568961200 [dir=none]
	1267568961200 [label="self
 (1, 384, 21, 21)" fillcolor=orange]
	1267569825136 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569824752 -> 1267569825136
	1267569824752 -> 1267568942336 [dir=none]
	1267568942336 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569824752 -> 1267568960720 [dir=none]
	1267568960720 [label="result1
 (384)" fillcolor=orange]
	1267569824752 -> 1267568961920 [dir=none]
	1267568961920 [label="result2
 (384)" fillcolor=orange]
	1267569824752 -> 1267568961600 [dir=none]
	1267568961600 [label="result3
 (0)" fillcolor=orange]
	1267569824752 -> 1267420370304 [dir=none]
	1267420370304 [label="running_mean
 (384)" fillcolor=orange]
	1267569824752 -> 1267420378624 [dir=none]
	1267420378624 [label="running_var
 (384)" fillcolor=orange]
	1267569824752 -> 1267420054848 [dir=none]
	1267420054848 [label="weight
 (384)" fillcolor=orange]
	1267569824752 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569824416 -> 1267569824752
	1267569824416 -> 1267568940416 [dir=none]
	1267568940416 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569824416 -> 1267420065808 [dir=none]
	1267420065808 [label="weight
 (384, 32, 3, 3)" fillcolor=orange]
	1267569824416 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             12
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569824080 -> 1267569824416
	1267569824080 -> 1267568961680 [dir=none]
	1267568961680 [label="self
 (1, 384, 21, 21)" fillcolor=orange]
	1267569824080 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569823744 -> 1267569824080
	1267569823744 -> 1267568950416 [dir=none]
	1267568950416 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569823744 -> 1267568962240 [dir=none]
	1267568962240 [label="result1
 (384)" fillcolor=orange]
	1267569823744 -> 1267568961840 [dir=none]
	1267568961840 [label="result2
 (384)" fillcolor=orange]
	1267569823744 -> 1267568962080 [dir=none]
	1267568962080 [label="result3
 (0)" fillcolor=orange]
	1267569823744 -> 1267420377584 [dir=none]
	1267420377584 [label="running_mean
 (384)" fillcolor=orange]
	1267569823744 -> 1267420375504 [dir=none]
	1267420375504 [label="running_var
 (384)" fillcolor=orange]
	1267569823744 -> 1267420375264 [dir=none]
	1267420375264 [label="weight
 (384)" fillcolor=orange]
	1267569823744 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569823888 -> 1267569823744
	1267569823888 -> 1267568936496 [dir=none]
	1267568936496 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569823888 -> 1267420374384 [dir=none]
	1267420374384 [label="weight
 (384, 32, 3, 3)" fillcolor=orange]
	1267569823888 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             12
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569823072 -> 1267569823888
	1267569823072 -> 1267568952640 [dir=none]
	1267568952640 [label="self
 (1, 384, 21, 21)" fillcolor=orange]
	1267569823072 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569823216 -> 1267569823072
	1267569823216 -> 1267568936896 [dir=none]
	1267568936896 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569823216 -> 1267568951440 [dir=none]
	1267568951440 [label="result1
 (384)" fillcolor=orange]
	1267569823216 -> 1267568962160 [dir=none]
	1267568962160 [label="result2
 (384)" fillcolor=orange]
	1267569823216 -> 1267568962320 [dir=none]
	1267568962320 [label="result3
 (0)" fillcolor=orange]
	1267569823216 -> 1267420369344 [dir=none]
	1267420369344 [label="running_mean
 (384)" fillcolor=orange]
	1267569823216 -> 1267420369984 [dir=none]
	1267420369984 [label="running_var
 (384)" fillcolor=orange]
	1267569823216 -> 1267420377344 [dir=none]
	1267420377344 [label="weight
 (384)" fillcolor=orange]
	1267569823216 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569822832 -> 1267569823216
	1267569822832 -> 1267568936736 [dir=none]
	1267568936736 [label="input
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569822832 -> 1267420369504 [dir=none]
	1267420369504 [label="weight
 (384, 1536, 1, 1)" fillcolor=orange]
	1267569822832 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569825712 -> 1267569822832
	1267569825712 -> 1267568966800 [dir=none]
	1267568966800 [label="self
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569825712 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569822640 -> 1267569825712
	1267569822640 [label="AddBackward0
------------
alpha: 1"]
	1267569822208 -> 1267569822640
	1267569822208 -> 1267568935856 [dir=none]
	1267568935856 [label="input
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569822208 -> 1267568962880 [dir=none]
	1267568962880 [label="result1
 (1536)" fillcolor=orange]
	1267569822208 -> 1267568962720 [dir=none]
	1267568962720 [label="result2
 (1536)" fillcolor=orange]
	1267569822208 -> 1267568951680 [dir=none]
	1267568951680 [label="result3
 (0)" fillcolor=orange]
	1267569822208 -> 1267420371104 [dir=none]
	1267420371104 [label="running_mean
 (1536)" fillcolor=orange]
	1267569822208 -> 1267420372384 [dir=none]
	1267420372384 [label="running_var
 (1536)" fillcolor=orange]
	1267569822208 -> 1267420365584 [dir=none]
	1267420365584 [label="weight
 (1536)" fillcolor=orange]
	1267569822208 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569821920 -> 1267569822208
	1267569821920 -> 1267568951136 [dir=none]
	1267568951136 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569821920 -> 1267420378944 [dir=none]
	1267420378944 [label="weight
 (1536, 384, 1, 1)" fillcolor=orange]
	1267569821920 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569821584 -> 1267569821920
	1267569821584 -> 1267568962640 [dir=none]
	1267568962640 [label="self
 (1, 384, 21, 21)" fillcolor=orange]
	1267569821584 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569821248 -> 1267569821584
	1267569821248 -> 1267568943776 [dir=none]
	1267568943776 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569821248 -> 1267568962480 [dir=none]
	1267568962480 [label="result1
 (384)" fillcolor=orange]
	1267569821248 -> 1267568963360 [dir=none]
	1267568963360 [label="result2
 (384)" fillcolor=orange]
	1267569821248 -> 1267568962960 [dir=none]
	1267568962960 [label="result3
 (0)" fillcolor=orange]
	1267569821248 -> 1267420372544 [dir=none]
	1267420372544 [label="running_mean
 (384)" fillcolor=orange]
	1267569821248 -> 1267420372464 [dir=none]
	1267420372464 [label="running_var
 (384)" fillcolor=orange]
	1267569821248 -> 1267420378544 [dir=none]
	1267420378544 [label="weight
 (384)" fillcolor=orange]
	1267569821248 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569821392 -> 1267569821248
	1267569821392 -> 1267568946576 [dir=none]
	1267568946576 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569821392 -> 1267420379424 [dir=none]
	1267420379424 [label="weight
 (384, 32, 3, 3)" fillcolor=orange]
	1267569821392 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             12
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569820576 -> 1267569821392
	1267569820576 -> 1267568963120 [dir=none]
	1267568963120 [label="self
 (1, 384, 21, 21)" fillcolor=orange]
	1267569820576 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569820720 -> 1267569820576
	1267569820720 -> 1267568946336 [dir=none]
	1267568946336 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569820720 -> 1267568963840 [dir=none]
	1267568963840 [label="result1
 (384)" fillcolor=orange]
	1267569820720 -> 1267568963200 [dir=none]
	1267568963200 [label="result2
 (384)" fillcolor=orange]
	1267569820720 -> 1267568963440 [dir=none]
	1267568963440 [label="result3
 (0)" fillcolor=orange]
	1267569820720 -> 1267420378704 [dir=none]
	1267420378704 [label="running_mean
 (384)" fillcolor=orange]
	1267569820720 -> 1267420377984 [dir=none]
	1267420377984 [label="running_var
 (384)" fillcolor=orange]
	1267569820720 -> 1267420378224 [dir=none]
	1267420378224 [label="weight
 (384)" fillcolor=orange]
	1267569820720 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569820336 -> 1267569820720
	1267569820336 -> 1267568947056 [dir=none]
	1267568947056 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569820336 -> 1267420378064 [dir=none]
	1267420378064 [label="weight
 (384, 32, 3, 3)" fillcolor=orange]
	1267569820336 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             12
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569820048 -> 1267569820336
	1267569820048 -> 1267568963600 [dir=none]
	1267568963600 [label="self
 (1, 384, 21, 21)" fillcolor=orange]
	1267569820048 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569820192 -> 1267569820048
	1267569820192 -> 1267568950656 [dir=none]
	1267568950656 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569820192 -> 1267568964320 [dir=none]
	1267568964320 [label="result1
 (384)" fillcolor=orange]
	1267569820192 -> 1267568963680 [dir=none]
	1267568963680 [label="result2
 (384)" fillcolor=orange]
	1267569820192 -> 1267568963920 [dir=none]
	1267568963920 [label="result3
 (0)" fillcolor=orange]
	1267569820192 -> 1267420376384 [dir=none]
	1267420376384 [label="running_mean
 (384)" fillcolor=orange]
	1267569820192 -> 1267420366224 [dir=none]
	1267420366224 [label="running_var
 (384)" fillcolor=orange]
	1267569820192 -> 1267420368064 [dir=none]
	1267420368064 [label="weight
 (384)" fillcolor=orange]
	1267569820192 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569819712 -> 1267569820192
	1267569819712 -> 1267568946816 [dir=none]
	1267568946816 [label="input
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569819712 -> 1267420365744 [dir=none]
	1267420365744 [label="weight
 (384, 1536, 1, 1)" fillcolor=orange]
	1267569819712 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569822688 -> 1267569819712
	1267569822688 -> 1267568964160 [dir=none]
	1267568964160 [label="self
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569822688 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569736384 -> 1267569822688
	1267569736384 [label="AddBackward0
------------
alpha: 1"]
	1267569736576 -> 1267569736384
	1267569736576 -> 1267568945616 [dir=none]
	1267568945616 [label="input
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569736576 -> 1267568964560 [dir=none]
	1267568964560 [label="result1
 (1536)" fillcolor=orange]
	1267569736576 -> 1267568964400 [dir=none]
	1267568964400 [label="result2
 (1536)" fillcolor=orange]
	1267569736576 -> 1267568964640 [dir=none]
	1267568964640 [label="result3
 (0)" fillcolor=orange]
	1267569736576 -> 1267420380944 [dir=none]
	1267420380944 [label="running_mean
 (1536)" fillcolor=orange]
	1267569736576 -> 1267420375184 [dir=none]
	1267420375184 [label="running_var
 (1536)" fillcolor=orange]
	1267569736576 -> 1267420364864 [dir=none]
	1267420364864 [label="weight
 (1536)" fillcolor=orange]
	1267569736576 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569735952 -> 1267569736576
	1267569735952 -> 1267568945376 [dir=none]
	1267568945376 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569735952 -> 1267420380784 [dir=none]
	1267420380784 [label="weight
 (1536, 384, 1, 1)" fillcolor=orange]
	1267569735952 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569735328 -> 1267569735952
	1267569735328 -> 1267568964880 [dir=none]
	1267568964880 [label="self
 (1, 384, 21, 21)" fillcolor=orange]
	1267569735328 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569734560 -> 1267569735328
	1267569734560 -> 1267568945216 [dir=none]
	1267568945216 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569734560 -> 1267568964080 [dir=none]
	1267568964080 [label="result1
 (384)" fillcolor=orange]
	1267569734560 -> 1267568964800 [dir=none]
	1267568964800 [label="result2
 (384)" fillcolor=orange]
	1267569734560 -> 1267568965280 [dir=none]
	1267568965280 [label="result3
 (0)" fillcolor=orange]
	1267569734560 -> 1267420367024 [dir=none]
	1267420367024 [label="running_mean
 (384)" fillcolor=orange]
	1267569734560 -> 1267420375024 [dir=none]
	1267420375024 [label="running_var
 (384)" fillcolor=orange]
	1267569734560 -> 1267420367904 [dir=none]
	1267420367904 [label="weight
 (384)" fillcolor=orange]
	1267569734560 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569733888 -> 1267569734560
	1267569733888 -> 1267568946096 [dir=none]
	1267568946096 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569733888 -> 1267420374944 [dir=none]
	1267420374944 [label="weight
 (384, 32, 3, 3)" fillcolor=orange]
	1267569733888 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             12
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569733264 -> 1267569733888
	1267569733264 -> 1267568965040 [dir=none]
	1267568965040 [label="self
 (1, 384, 21, 21)" fillcolor=orange]
	1267569733264 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569733504 -> 1267569733264
	1267569733504 -> 1267568950896 [dir=none]
	1267568950896 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569733504 -> 1267568965120 [dir=none]
	1267568965120 [label="result1
 (384)" fillcolor=orange]
	1267569733504 -> 1267568965360 [dir=none]
	1267568965360 [label="result2
 (384)" fillcolor=orange]
	1267569733504 -> 1267568965600 [dir=none]
	1267568965600 [label="result3
 (0)" fillcolor=orange]
	1267569733504 -> 1267420367584 [dir=none]
	1267420367584 [label="running_mean
 (384)" fillcolor=orange]
	1267569733504 -> 1267420376304 [dir=none]
	1267420376304 [label="running_var
 (384)" fillcolor=orange]
	1267569733504 -> 1267420366464 [dir=none]
	1267420366464 [label="weight
 (384)" fillcolor=orange]
	1267569733504 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569732832 -> 1267569733504
	1267569732832 -> 1267568945856 [dir=none]
	1267568945856 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569732832 -> 1267420366144 [dir=none]
	1267420366144 [label="weight
 (384, 32, 3, 3)" fillcolor=orange]
	1267569732832 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             12
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569732208 -> 1267569732832
	1267569732208 -> 1267568965520 [dir=none]
	1267568965520 [label="self
 (1, 384, 21, 21)" fillcolor=orange]
	1267569732208 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569731440 -> 1267569732208
	1267569731440 -> 1267280738592 [dir=none]
	1267280738592 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569731440 -> 1267568965760 [dir=none]
	1267568965760 [label="result1
 (384)" fillcolor=orange]
	1267569731440 -> 1267568962000 [dir=none]
	1267568962000 [label="result2
 (384)" fillcolor=orange]
	1267569731440 -> 1267568966000 [dir=none]
	1267568966000 [label="result3
 (0)" fillcolor=orange]
	1267569731440 -> 1267420371424 [dir=none]
	1267420371424 [label="running_mean
 (384)" fillcolor=orange]
	1267569731440 -> 1267420371744 [dir=none]
	1267420371744 [label="running_var
 (384)" fillcolor=orange]
	1267569731440 -> 1267420366944 [dir=none]
	1267420366944 [label="weight
 (384)" fillcolor=orange]
	1267569731440 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569730768 -> 1267569731440
	1267569730768 -> 1267568942576 [dir=none]
	1267568942576 [label="input
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569730768 -> 1267420367104 [dir=none]
	1267420367104 [label="weight
 (384, 1536, 1, 1)" fillcolor=orange]
	1267569730768 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569736432 -> 1267569730768
	1267569736432 -> 1267568966160 [dir=none]
	1267568966160 [label="self
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569736432 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569730336 -> 1267569736432
	1267569730336 [label="AddBackward0
------------
alpha: 1"]
	1267569729520 -> 1267569730336
	1267569729520 -> 1267287979760 [dir=none]
	1267287979760 [label="input
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569729520 -> 1267568965920 [dir=none]
	1267568965920 [label="result1
 (1536)" fillcolor=orange]
	1267569729520 -> 1267568966640 [dir=none]
	1267568966640 [label="result2
 (1536)" fillcolor=orange]
	1267569729520 -> 1267568966480 [dir=none]
	1267568966480 [label="result3
 (0)" fillcolor=orange]
	1267569729520 -> 1267420380064 [dir=none]
	1267420380064 [label="running_mean
 (1536)" fillcolor=orange]
	1267569729520 -> 1267420380224 [dir=none]
	1267420380224 [label="running_var
 (1536)" fillcolor=orange]
	1267569729520 -> 1267420367264 [dir=none]
	1267420367264 [label="weight
 (1536)" fillcolor=orange]
	1267569729520 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569728896 -> 1267569729520
	1267569728896 -> 1267287979120 [dir=none]
	1267287979120 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569728896 -> 1267420366784 [dir=none]
	1267420366784 [label="weight
 (1536, 384, 1, 1)" fillcolor=orange]
	1267569728896 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569728272 -> 1267569728896
	1267569728272 -> 1267568966240 [dir=none]
	1267568966240 [label="self
 (1, 384, 21, 21)" fillcolor=orange]
	1267569728272 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569728512 -> 1267569728272
	1267569728512 -> 1267569885248 [dir=none]
	1267569885248 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569728512 -> 1267568962400 [dir=none]
	1267568962400 [label="result1
 (384)" fillcolor=orange]
	1267569728512 -> 1267568966400 [dir=none]
	1267568966400 [label="result2
 (384)" fillcolor=orange]
	1267569728512 -> 1267568966960 [dir=none]
	1267568966960 [label="result3
 (0)" fillcolor=orange]
	1267569728512 -> 1267420376224 [dir=none]
	1267420376224 [label="running_mean
 (384)" fillcolor=orange]
	1267569728512 -> 1267420370384 [dir=none]
	1267420370384 [label="running_var
 (384)" fillcolor=orange]
	1267569728512 -> 1267420370464 [dir=none]
	1267420370464 [label="weight
 (384)" fillcolor=orange]
	1267569728512 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569727840 -> 1267569728512
	1267569727840 -> 1267569885328 [dir=none]
	1267569885328 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569727840 -> 1267420370544 [dir=none]
	1267420370544 [label="weight
 (384, 32, 3, 3)" fillcolor=orange]
	1267569727840 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             12
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569727216 -> 1267569727840
	1267569727216 -> 1267568966720 [dir=none]
	1267568966720 [label="self
 (1, 384, 21, 21)" fillcolor=orange]
	1267569727216 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569726448 -> 1267569727216
	1267569726448 -> 1267569885568 [dir=none]
	1267569885568 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569726448 -> 1267568966880 [dir=none]
	1267568966880 [label="result1
 (384)" fillcolor=orange]
	1267569726448 -> 1267568967120 [dir=none]
	1267568967120 [label="result2
 (384)" fillcolor=orange]
	1267569726448 -> 1267568967440 [dir=none]
	1267568967440 [label="result3
 (0)" fillcolor=orange]
	1267569726448 -> 1267420372304 [dir=none]
	1267420372304 [label="running_mean
 (384)" fillcolor=orange]
	1267569726448 -> 1267420372624 [dir=none]
	1267420372624 [label="running_var
 (384)" fillcolor=orange]
	1267569726448 -> 1267420380384 [dir=none]
	1267420380384 [label="weight
 (384)" fillcolor=orange]
	1267569726448 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569725776 -> 1267569726448
	1267569725776 -> 1267569885488 [dir=none]
	1267569885488 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569725776 -> 1267420370864 [dir=none]
	1267420370864 [label="weight
 (384, 32, 3, 3)" fillcolor=orange]
	1267569725776 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             12
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569725152 -> 1267569725776
	1267569725152 -> 1267568967200 [dir=none]
	1267568967200 [label="self
 (1, 384, 21, 21)" fillcolor=orange]
	1267569725152 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569725392 -> 1267569725152
	1267569725392 -> 1267569885888 [dir=none]
	1267569885888 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569725392 -> 1267568967360 [dir=none]
	1267568967360 [label="result1
 (384)" fillcolor=orange]
	1267569725392 -> 1267568967600 [dir=none]
	1267568967600 [label="result2
 (384)" fillcolor=orange]
	1267569725392 -> 1267568965840 [dir=none]
	1267568965840 [label="result3
 (0)" fillcolor=orange]
	1267569725392 -> 1267420369104 [dir=none]
	1267420369104 [label="running_mean
 (384)" fillcolor=orange]
	1267569725392 -> 1267420369424 [dir=none]
	1267420369424 [label="running_var
 (384)" fillcolor=orange]
	1267569725392 -> 1267420371584 [dir=none]
	1267420371584 [label="weight
 (384)" fillcolor=orange]
	1267569725392 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569724720 -> 1267569725392
	1267569724720 -> 1267569885648 [dir=none]
	1267569885648 [label="input
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569724720 -> 1267420380624 [dir=none]
	1267420380624 [label="weight
 (384, 1536, 1, 1)" fillcolor=orange]
	1267569724720 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569730384 -> 1267569724720
	1267569730384 -> 1267568967520 [dir=none]
	1267568967520 [label="self
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569730384 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569723280 -> 1267569730384
	1267569723280 [label="AddBackward0
------------
alpha: 1"]
	1267569723472 -> 1267569723280
	1267569723472 -> 1267569885968 [dir=none]
	1267569885968 [label="input
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569723472 -> 1267568952880 [dir=none]
	1267568952880 [label="result1
 (1536)" fillcolor=orange]
	1267569723472 -> 1267568963760 [dir=none]
	1267568963760 [label="result2
 (1536)" fillcolor=orange]
	1267569723472 -> 1267568954080 [dir=none]
	1267568954080 [label="result3
 (0)" fillcolor=orange]
	1267569723472 -> 1267420368304 [dir=none]
	1267420368304 [label="running_mean
 (1536)" fillcolor=orange]
	1267569723472 -> 1267420369584 [dir=none]
	1267420369584 [label="running_var
 (1536)" fillcolor=orange]
	1267569723472 -> 1267420372144 [dir=none]
	1267420372144 [label="weight
 (1536)" fillcolor=orange]
	1267569723472 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569722848 -> 1267569723472
	1267569722848 -> 1267569885808 [dir=none]
	1267569885808 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569722848 -> 1267420368624 [dir=none]
	1267420368624 [label="weight
 (1536, 384, 1, 1)" fillcolor=orange]
	1267569722848 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569722224 -> 1267569722848
	1267569722224 -> 1267568959120 [dir=none]
	1267568959120 [label="self
 (1, 384, 21, 21)" fillcolor=orange]
	1267569722224 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569721600 -> 1267569722224
	1267569721600 -> 1267569885728 [dir=none]
	1267569885728 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569721600 -> 1267568955760 [dir=none]
	1267568955760 [label="result1
 (384)" fillcolor=orange]
	1267569721600 -> 1267568955520 [dir=none]
	1267568955520 [label="result2
 (384)" fillcolor=orange]
	1267569721600 -> 1267568954560 [dir=none]
	1267568954560 [label="result3
 (0)" fillcolor=orange]
	1267569721600 -> 1267420376704 [dir=none]
	1267420376704 [label="running_mean
 (384)" fillcolor=orange]
	1267569721600 -> 1267420367424 [dir=none]
	1267420367424 [label="running_var
 (384)" fillcolor=orange]
	1267569721600 -> 1267420371904 [dir=none]
	1267420371904 [label="weight
 (384)" fillcolor=orange]
	1267569721600 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569737392 -> 1267569721600
	1267569737392 -> 1267569886208 [dir=none]
	1267569886208 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569737392 -> 1267420367504 [dir=none]
	1267420367504 [label="weight
 (384, 32, 3, 3)" fillcolor=orange]
	1267569737392 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             12
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569737584 -> 1267569737392
	1267569737584 -> 1267568957680 [dir=none]
	1267568957680 [label="self
 (1, 384, 21, 21)" fillcolor=orange]
	1267569737584 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569736720 -> 1267569737584
	1267569736720 -> 1267569886288 [dir=none]
	1267569886288 [label="input
 (1, 384, 21, 21)" fillcolor=orange]
	1267569736720 -> 1267568957920 [dir=none]
	1267568957920 [label="result1
 (384)" fillcolor=orange]
	1267569736720 -> 1267568967040 [dir=none]
	1267568967040 [label="result2
 (384)" fillcolor=orange]
	1267569736720 -> 1267568955040 [dir=none]
	1267568955040 [label="result3
 (0)" fillcolor=orange]
	1267569736720 -> 1267420377024 [dir=none]
	1267420377024 [label="running_mean
 (384)" fillcolor=orange]
	1267569736720 -> 1267420374304 [dir=none]
	1267420374304 [label="running_var
 (384)" fillcolor=orange]
	1267569736720 -> 1267420376544 [dir=none]
	1267420376544 [label="weight
 (384)" fillcolor=orange]
	1267569736720 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569736864 -> 1267569736720
	1267569736864 -> 1267569886128 [dir=none]
	1267569886128 [label="input
 (1, 384, 42, 42)" fillcolor=orange]
	1267569736864 -> 1267420366864 [dir=none]
	1267420366864 [label="weight
 (384, 32, 3, 3)" fillcolor=orange]
	1267569736864 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             12
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	1267569736528 -> 1267569736864
	1267569736528 -> 1267568958160 [dir=none]
	1267568958160 [label="self
 (1, 384, 42, 42)" fillcolor=orange]
	1267569736528 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569736192 -> 1267569736528
	1267569736192 -> 1267569886528 [dir=none]
	1267569886528 [label="input
 (1, 384, 42, 42)" fillcolor=orange]
	1267569736192 -> 1267568958400 [dir=none]
	1267568958400 [label="result1
 (384)" fillcolor=orange]
	1267569736192 -> 1267568954800 [dir=none]
	1267568954800 [label="result2
 (384)" fillcolor=orange]
	1267569736192 -> 1267568967280 [dir=none]
	1267568967280 [label="result3
 (0)" fillcolor=orange]
	1267569736192 -> 1267420374144 [dir=none]
	1267420374144 [label="running_mean
 (384)" fillcolor=orange]
	1267569736192 -> 1267420376784 [dir=none]
	1267420376784 [label="running_var
 (384)" fillcolor=orange]
	1267569736192 -> 1267420373504 [dir=none]
	1267420373504 [label="weight
 (384)" fillcolor=orange]
	1267569736192 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569736336 -> 1267569736192
	1267569736336 -> 1267569886048 [dir=none]
	1267569886048 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1267569736336 -> 1267420373744 [dir=none]
	1267420373744 [label="weight
 (384, 512, 1, 1)" fillcolor=orange]
	1267569736336 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569735520 -> 1267569736336
	1267569735520 -> 1267568955280 [dir=none]
	1267568955280 [label="self
 (1, 512, 42, 42)" fillcolor=orange]
	1267569735520 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569735664 -> 1267569735520
	1267569735664 [label="AddBackward0
------------
alpha: 1"]
	1267569735232 -> 1267569735664
	1267569735232 -> 1267569886608 [dir=none]
	1267569886608 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1267569735232 -> 1267568953120 [dir=none]
	1267568953120 [label="result1
 (512)" fillcolor=orange]
	1267569735232 -> 1267568961760 [dir=none]
	1267568961760 [label="result2
 (512)" fillcolor=orange]
	1267569735232 -> 1267568951520 [dir=none]
	1267568951520 [label="result3
 (0)" fillcolor=orange]
	1267569735232 -> 1267420368544 [dir=none]
	1267420368544 [label="running_mean
 (512)" fillcolor=orange]
	1267569735232 -> 1267420367184 [dir=none]
	1267420367184 [label="running_var
 (512)" fillcolor=orange]
	1267569735232 -> 1267420374624 [dir=none]
	1267420374624 [label="weight
 (512)" fillcolor=orange]
	1267569735232 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569734944 -> 1267569735232
	1267569734944 -> 1267569886448 [dir=none]
	1267569886448 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569734944 -> 1267420366704 [dir=none]
	1267420366704 [label="weight
 (512, 128, 1, 1)" fillcolor=orange]
	1267569734944 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569734608 -> 1267569734944
	1267569734608 -> 1267568952480 [dir=none]
	1267568952480 [label="self
 (1, 128, 42, 42)" fillcolor=orange]
	1267569734608 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569734272 -> 1267569734608
	1267569734272 -> 1267569886368 [dir=none]
	1267569886368 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569734272 -> 1267420126064 [dir=none]
	1267420126064 [label="result1
 (128)" fillcolor=orange]
	1267569734272 -> 1267420129504 [dir=none]
	1267420129504 [label="result2
 (128)" fillcolor=orange]
	1267569734272 -> 1267420119424 [dir=none]
	1267420119424 [label="result3
 (0)" fillcolor=orange]
	1267569734272 -> 1267420365664 [dir=none]
	1267420365664 [label="running_mean
 (128)" fillcolor=orange]
	1267569734272 -> 1267420365984 [dir=none]
	1267420365984 [label="running_var
 (128)" fillcolor=orange]
	1267569734272 -> 1267420372864 [dir=none]
	1267420372864 [label="weight
 (128)" fillcolor=orange]
	1267569734272 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569734416 -> 1267569734272
	1267569734416 -> 1267569886848 [dir=none]
	1267569886848 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569734416 -> 1267420374784 [dir=none]
	1267420374784 [label="weight
 (128, 32, 3, 3)" fillcolor=orange]
	1267569734416 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              4
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569733600 -> 1267569734416
	1267569733600 -> 1267420273440 [dir=none]
	1267420273440 [label="self
 (1, 128, 42, 42)" fillcolor=orange]
	1267569733600 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569733744 -> 1267569733600
	1267569733744 -> 1267569886928 [dir=none]
	1267569886928 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569733744 -> 1267420271920 [dir=none]
	1267420271920 [label="result1
 (128)" fillcolor=orange]
	1267569733744 -> 1267420271840 [dir=none]
	1267420271840 [label="result2
 (128)" fillcolor=orange]
	1267569733744 -> 1267420277200 [dir=none]
	1267420277200 [label="result3
 (0)" fillcolor=orange]
	1267569733744 -> 1267420372944 [dir=none]
	1267420372944 [label="running_mean
 (128)" fillcolor=orange]
	1267569733744 -> 1267420365184 [dir=none]
	1267420365184 [label="running_var
 (128)" fillcolor=orange]
	1267569733744 -> 1267420372784 [dir=none]
	1267420372784 [label="weight
 (128)" fillcolor=orange]
	1267569733744 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569733360 -> 1267569733744
	1267569733360 -> 1267569886768 [dir=none]
	1267569886768 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569733360 -> 1267420371664 [dir=none]
	1267420371664 [label="weight
 (128, 32, 3, 3)" fillcolor=orange]
	1267569733360 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              4
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569733072 -> 1267569733360
	1267569733072 -> 1267420133264 [dir=none]
	1267420133264 [label="self
 (1, 128, 42, 42)" fillcolor=orange]
	1267569733072 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569733216 -> 1267569733072
	1267569733216 -> 1267569887088 [dir=none]
	1267569887088 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569733216 -> 1267420130784 [dir=none]
	1267420130784 [label="result1
 (128)" fillcolor=orange]
	1267569733216 -> 1267420121184 [dir=none]
	1267420121184 [label="result2
 (128)" fillcolor=orange]
	1267569733216 -> 1267420125664 [dir=none]
	1267420125664 [label="result3
 (0)" fillcolor=orange]
	1267569733216 -> 1267420380704 [dir=none]
	1267420380704 [label="running_mean
 (128)" fillcolor=orange]
	1267569733216 -> 1267420365344 [dir=none]
	1267420365344 [label="running_var
 (128)" fillcolor=orange]
	1267569733216 -> 1267420377104 [dir=none]
	1267420377104 [label="weight
 (128)" fillcolor=orange]
	1267569733216 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569732352 -> 1267569733216
	1267569732352 -> 1267569886688 [dir=none]
	1267569886688 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1267569732352 -> 1267420373344 [dir=none]
	1267420373344 [label="weight
 (128, 512, 1, 1)" fillcolor=orange]
	1267569732352 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569735712 -> 1267569732352
	1267569735712 -> 1267420122304 [dir=none]
	1267420122304 [label="self
 (1, 512, 42, 42)" fillcolor=orange]
	1267569735712 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569732112 -> 1267569735712
	1267569732112 [label="AddBackward0
------------
alpha: 1"]
	1267569731728 -> 1267569732112
	1267569731728 -> 1267569887168 [dir=none]
	1267569887168 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1267569731728 -> 1268582182608 [dir=none]
	1268582182608 [label="result1
 (512)" fillcolor=orange]
	1267569731728 -> 1268582175088 [dir=none]
	1268582175088 [label="result2
 (512)" fillcolor=orange]
	1267569731728 -> 1268582186848 [dir=none]
	1268582186848 [label="result3
 (0)" fillcolor=orange]
	1267569731728 -> 1267420368944 [dir=none]
	1267420368944 [label="running_mean
 (512)" fillcolor=orange]
	1267569731728 -> 1267420376944 [dir=none]
	1267420376944 [label="running_var
 (512)" fillcolor=orange]
	1267569731728 -> 1267420377264 [dir=none]
	1267420377264 [label="weight
 (512)" fillcolor=orange]
	1267569731728 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569731920 -> 1267569731728
	1267569731920 -> 1267569887008 [dir=none]
	1267569887008 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569731920 -> 1267420370224 [dir=none]
	1267420370224 [label="weight
 (512, 128, 1, 1)" fillcolor=orange]
	1267569731920 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569731104 -> 1267569731920
	1267569731104 -> 1267420270560 [dir=none]
	1267420270560 [label="self
 (1, 128, 42, 42)" fillcolor=orange]
	1267569731104 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569731248 -> 1267569731104
	1267569731248 -> 1267569887408 [dir=none]
	1267569887408 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569731248 -> 1267420279520 [dir=none]
	1267420279520 [label="result1
 (128)" fillcolor=orange]
	1267569731248 -> 1267420270240 [dir=none]
	1267420270240 [label="result2
 (128)" fillcolor=orange]
	1267569731248 -> 1268582183168 [dir=none]
	1268582183168 [label="result3
 (0)" fillcolor=orange]
	1267569731248 -> 1267420242112 [dir=none]
	1267420242112 [label="running_mean
 (128)" fillcolor=orange]
	1267569731248 -> 1267420379904 [dir=none]
	1267420379904 [label="running_var
 (128)" fillcolor=orange]
	1267569731248 -> 1267420369264 [dir=none]
	1267420369264 [label="weight
 (128)" fillcolor=orange]
	1267569731248 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569730864 -> 1267569731248
	1267569730864 -> 1267569887488 [dir=none]
	1267569887488 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569730864 -> 1267420375744 [dir=none]
	1267420375744 [label="weight
 (128, 32, 3, 3)" fillcolor=orange]
	1267569730864 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              4
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569730576 -> 1267569730864
	1267569730576 -> 1267420061328 [dir=none]
	1267420061328 [label="self
 (1, 128, 42, 42)" fillcolor=orange]
	1267569730576 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569730720 -> 1267569730576
	1267569730720 -> 1267569887328 [dir=none]
	1267569887328 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569730720 -> 1267420059648 [dir=none]
	1267420059648 [label="result1
 (128)" fillcolor=orange]
	1267569730720 -> 1267420068448 [dir=none]
	1267420068448 [label="result2
 (128)" fillcolor=orange]
	1267569730720 -> 1267420064208 [dir=none]
	1267420064208 [label="result3
 (0)" fillcolor=orange]
	1267569730720 -> 1267420238352 [dir=none]
	1267420238352 [label="running_mean
 (128)" fillcolor=orange]
	1267569730720 -> 1267420244352 [dir=none]
	1267420244352 [label="running_var
 (128)" fillcolor=orange]
	1267569730720 -> 1267420237472 [dir=none]
	1267420237472 [label="weight
 (128)" fillcolor=orange]
	1267569730720 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569729856 -> 1267569730720
	1267569729856 -> 1267569887248 [dir=none]
	1267569887248 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569729856 -> 1267420246752 [dir=none]
	1267420246752 [label="weight
 (128, 32, 3, 3)" fillcolor=orange]
	1267569729856 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              4
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569730048 -> 1267569729856
	1267569730048 -> 1268582182448 [dir=none]
	1268582182448 [label="self
 (1, 128, 42, 42)" fillcolor=orange]
	1267569730048 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569729664 -> 1267569730048
	1267569729664 -> 1267569887808 [dir=none]
	1267569887808 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569729664 -> 1268582184768 [dir=none]
	1268582184768 [label="result1
 (128)" fillcolor=orange]
	1267569729664 -> 1268582184928 [dir=none]
	1268582184928 [label="result2
 (128)" fillcolor=orange]
	1267569729664 -> 1267420058528 [dir=none]
	1267420058528 [label="result3
 (0)" fillcolor=orange]
	1267569729664 -> 1267420240432 [dir=none]
	1267420240432 [label="running_mean
 (128)" fillcolor=orange]
	1267569729664 -> 1267420238032 [dir=none]
	1267420238032 [label="running_var
 (128)" fillcolor=orange]
	1267569729664 -> 1267420235392 [dir=none]
	1267420235392 [label="weight
 (128)" fillcolor=orange]
	1267569729664 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569729328 -> 1267569729664
	1267569729328 -> 1267569887728 [dir=none]
	1267569887728 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1267569729328 -> 1267420248752 [dir=none]
	1267420248752 [label="weight
 (128, 512, 1, 1)" fillcolor=orange]
	1267569729328 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569732160 -> 1267569729328
	1267569732160 -> 1267420067568 [dir=none]
	1267420067568 [label="self
 (1, 512, 42, 42)" fillcolor=orange]
	1267569732160 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569728608 -> 1267569732160
	1267569728608 [label="AddBackward0
------------
alpha: 1"]
	1267569728704 -> 1267569728608
	1267569728704 -> 1267569887648 [dir=none]
	1267569887648 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1267569728704 -> 1267420055088 [dir=none]
	1267420055088 [label="result1
 (512)" fillcolor=orange]
	1267569728704 -> 1267420054928 [dir=none]
	1267420054928 [label="result2
 (512)" fillcolor=orange]
	1267569728704 -> 1267292969440 [dir=none]
	1267292969440 [label="result3
 (0)" fillcolor=orange]
	1267569728704 -> 1267420238192 [dir=none]
	1267420238192 [label="running_mean
 (512)" fillcolor=orange]
	1267569728704 -> 1267420245472 [dir=none]
	1267420245472 [label="running_var
 (512)" fillcolor=orange]
	1267569728704 -> 1267420235152 [dir=none]
	1267420235152 [label="weight
 (512)" fillcolor=orange]
	1267569728704 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569728368 -> 1267569728704
	1267569728368 -> 1267569887568 [dir=none]
	1267569887568 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569728368 -> 1267420245312 [dir=none]
	1267420245312 [label="weight
 (512, 128, 1, 1)" fillcolor=orange]
	1267569728368 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569728080 -> 1267569728368
	1267569728080 -> 1267292969280 [dir=none]
	1267292969280 [label="self
 (1, 128, 42, 42)" fillcolor=orange]
	1267569728080 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569728224 -> 1267569728080
	1267569728224 -> 1267569887968 [dir=none]
	1267569887968 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569728224 -> 1267292970560 [dir=none]
	1267292970560 [label="result1
 (128)" fillcolor=orange]
	1267569728224 -> 1267292970240 [dir=none]
	1267292970240 [label="result2
 (128)" fillcolor=orange]
	1267569728224 -> 1267292970320 [dir=none]
	1267292970320 [label="result3
 (0)" fillcolor=orange]
	1267569728224 -> 1267420248272 [dir=none]
	1267420248272 [label="running_mean
 (128)" fillcolor=orange]
	1267569728224 -> 1267420235792 [dir=none]
	1267420235792 [label="running_var
 (128)" fillcolor=orange]
	1267569728224 -> 1267420245072 [dir=none]
	1267420245072 [label="weight
 (128)" fillcolor=orange]
	1267569728224 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569727360 -> 1267569728224
	1267569727360 -> 1267569888048 [dir=none]
	1267569888048 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569727360 -> 1267420234992 [dir=none]
	1267420234992 [label="weight
 (128, 32, 3, 3)" fillcolor=orange]
	1267569727360 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              4
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569727552 -> 1267569727360
	1267569727552 -> 1267292973360 [dir=none]
	1267292973360 [label="self
 (1, 128, 42, 42)" fillcolor=orange]
	1267569727552 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569727168 -> 1267569727552
	1267569727168 -> 1267569887888 [dir=none]
	1267569887888 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569727168 -> 1267292972000 [dir=none]
	1267292972000 [label="result1
 (128)" fillcolor=orange]
	1267569727168 -> 1267292966960 [dir=none]
	1267292966960 [label="result2
 (128)" fillcolor=orange]
	1267569727168 -> 1267292971040 [dir=none]
	1267292971040 [label="result3
 (0)" fillcolor=orange]
	1267569727168 -> 1268582171568 [dir=none]
	1268582171568 [label="running_mean
 (128)" fillcolor=orange]
	1267569727168 -> 1267420237312 [dir=none]
	1267420237312 [label="running_var
 (128)" fillcolor=orange]
	1267569727168 -> 1267420242992 [dir=none]
	1267420242992 [label="weight
 (128)" fillcolor=orange]
	1267569727168 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569726832 -> 1267569727168
	1267569726832 -> 1267569888368 [dir=none]
	1267569888368 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569726832 -> 1267420241632 [dir=none]
	1267420241632 [label="weight
 (128, 32, 3, 3)" fillcolor=orange]
	1267569726832 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              4
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569726496 -> 1267569726832
	1267569726496 -> 1267292972720 [dir=none]
	1267292972720 [label="self
 (1, 128, 42, 42)" fillcolor=orange]
	1267569726496 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569726160 -> 1267569726496
	1267569726160 -> 1267569888128 [dir=none]
	1267569888128 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569726160 -> 1267420301328 [dir=none]
	1267420301328 [label="result1
 (128)" fillcolor=orange]
	1267569726160 -> 1267420304208 [dir=none]
	1267420304208 [label="result2
 (128)" fillcolor=orange]
	1267569726160 -> 1267420311888 [dir=none]
	1267420311888 [label="result3
 (0)" fillcolor=orange]
	1267569726160 -> 1268582183568 [dir=none]
	1268582183568 [label="running_mean
 (128)" fillcolor=orange]
	1267569726160 -> 1267420246272 [dir=none]
	1267420246272 [label="running_var
 (128)" fillcolor=orange]
	1267569726160 -> 1267420242592 [dir=none]
	1267420242592 [label="weight
 (128)" fillcolor=orange]
	1267569726160 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569726304 -> 1267569726160
	1267569726304 -> 1267569888288 [dir=none]
	1267569888288 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1267569726304 -> 1267420242272 [dir=none]
	1267420242272 [label="weight
 (128, 512, 1, 1)" fillcolor=orange]
	1267569726304 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569728656 -> 1267569726304
	1267569728656 -> 1267420304928 [dir=none]
	1267420304928 [label="self
 (1, 512, 42, 42)" fillcolor=orange]
	1267569728656 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569725584 -> 1267569728656
	1267569725584 [label="AddBackward0
------------
alpha: 1"]
	1267569725680 -> 1267569725584
	1267569725680 -> 1267569888528 [dir=none]
	1267569888528 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1267569725680 -> 1267420307568 [dir=none]
	1267420307568 [label="result1
 (512)" fillcolor=orange]
	1267569725680 -> 1267420301168 [dir=none]
	1267420301168 [label="result2
 (512)" fillcolor=orange]
	1267569725680 -> 1267420305248 [dir=none]
	1267420305248 [label="result3
 (0)" fillcolor=orange]
	1267569725680 -> 1268582182368 [dir=none]
	1268582182368 [label="running_mean
 (512)" fillcolor=orange]
	1267569725680 -> 1268582181568 [dir=none]
	1268582181568 [label="running_var
 (512)" fillcolor=orange]
	1267569725680 -> 1268582173808 [dir=none]
	1268582173808 [label="weight
 (512)" fillcolor=orange]
	1267569725680 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569724864 -> 1267569725680
	1267569724864 -> 1267569888448 [dir=none]
	1267569888448 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569724864 -> 1268582179968 [dir=none]
	1268582179968 [label="weight
 (512, 128, 1, 1)" fillcolor=orange]
	1267569724864 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569725056 -> 1267569724864
	1267569725056 -> 1267420307488 [dir=none]
	1267420307488 [label="self
 (1, 128, 42, 42)" fillcolor=orange]
	1267569725056 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569724672 -> 1267569725056
	1267569724672 -> 1267569888768 [dir=none]
	1267569888768 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569724672 -> 1267420303968 [dir=none]
	1267420303968 [label="result1
 (128)" fillcolor=orange]
	1267569724672 -> 1267429769136 [dir=none]
	1267429769136 [label="result2
 (128)" fillcolor=orange]
	1267569724672 -> 1267429757696 [dir=none]
	1267429757696 [label="result3
 (0)" fillcolor=orange]
	1267569724672 -> 1268582181648 [dir=none]
	1268582181648 [label="running_mean
 (128)" fillcolor=orange]
	1267569724672 -> 1268582174848 [dir=none]
	1268582174848 [label="running_var
 (128)" fillcolor=orange]
	1267569724672 -> 1268582181488 [dir=none]
	1268582181488 [label="weight
 (128)" fillcolor=orange]
	1267569724672 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569724336 -> 1267569724672
	1267569724336 -> 1267569888848 [dir=none]
	1267569888848 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569724336 -> 1268582181408 [dir=none]
	1268582181408 [label="weight
 (128, 32, 3, 3)" fillcolor=orange]
	1267569724336 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              4
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569724000 -> 1267569724336
	1267569724000 -> 1267429757776 [dir=none]
	1267429757776 [label="self
 (1, 128, 42, 42)" fillcolor=orange]
	1267569724000 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569723664 -> 1267569724000
	1267569723664 -> 1267569888688 [dir=none]
	1267569888688 [label="input
 (1, 128, 42, 42)" fillcolor=orange]
	1267569723664 -> 1267429758096 [dir=none]
	1267429758096 [label="result1
 (128)" fillcolor=orange]
	1267569723664 -> 1267429757856 [dir=none]
	1267429757856 [label="result2
 (128)" fillcolor=orange]
	1267569723664 -> 1267429758016 [dir=none]
	1267429758016 [label="result3
 (0)" fillcolor=orange]
	1267569723664 -> 1268582182128 [dir=none]
	1268582182128 [label="running_mean
 (128)" fillcolor=orange]
	1267569723664 -> 1268582182048 [dir=none]
	1268582182048 [label="running_var
 (128)" fillcolor=orange]
	1267569723664 -> 1268582174928 [dir=none]
	1268582174928 [label="weight
 (128)" fillcolor=orange]
	1267569723664 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569723808 -> 1267569723664
	1267569723808 -> 1267569889088 [dir=none]
	1267569889088 [label="input
 (1, 128, 84, 84)" fillcolor=orange]
	1267569723808 -> 1268582181968 [dir=none]
	1268582181968 [label="weight
 (128, 32, 3, 3)" fillcolor=orange]
	1267569723808 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              4
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	1267569722992 -> 1267569723808
	1267569722992 -> 1267429758496 [dir=none]
	1267429758496 [label="self
 (1, 128, 84, 84)" fillcolor=orange]
	1267569722992 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569723136 -> 1267569722992
	1267569723136 -> 1267569889008 [dir=none]
	1267569889008 [label="input
 (1, 128, 84, 84)" fillcolor=orange]
	1267569723136 -> 1267429758416 [dir=none]
	1267429758416 [label="result1
 (128)" fillcolor=orange]
	1267569723136 -> 1267429757936 [dir=none]
	1267429757936 [label="result2
 (128)" fillcolor=orange]
	1267569723136 -> 1267429758336 [dir=none]
	1267429758336 [label="result3
 (0)" fillcolor=orange]
	1267569723136 -> 1268582182528 [dir=none]
	1268582182528 [label="running_mean
 (128)" fillcolor=orange]
	1267569723136 -> 1268582177328 [dir=none]
	1268582177328 [label="running_var
 (128)" fillcolor=orange]
	1267569723136 -> 1268582175248 [dir=none]
	1268582175248 [label="weight
 (128)" fillcolor=orange]
	1267569723136 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569722752 -> 1267569723136
	1267569722752 -> 1267569888608 [dir=none]
	1267569888608 [label="input
 (1, 256, 84, 84)" fillcolor=orange]
	1267569722752 -> 1268582182288 [dir=none]
	1268582182288 [label="weight
 (128, 256, 1, 1)" fillcolor=orange]
	1267569722752 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569722464 -> 1267569722752
	1267569722464 -> 1267429758256 [dir=none]
	1267429758256 [label="self
 (1, 256, 84, 84)" fillcolor=orange]
	1267569722464 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569722608 -> 1267569722464
	1267569722608 [label="AddBackward0
------------
alpha: 1"]
	1267569722176 -> 1267569722608
	1267569722176 -> 1267569888928 [dir=none]
	1267569888928 [label="input
 (1, 256, 84, 84)" fillcolor=orange]
	1267569722176 -> 1267429758736 [dir=none]
	1267429758736 [label="result1
 (256)" fillcolor=orange]
	1267569722176 -> 1267429758656 [dir=none]
	1267429758656 [label="result2
 (256)" fillcolor=orange]
	1267569722176 -> 1267429759056 [dir=none]
	1267429759056 [label="result3
 (0)" fillcolor=orange]
	1267569722176 -> 1267569890928 [dir=none]
	1267569890928 [label="running_mean
 (256)" fillcolor=orange]
	1267569722176 -> 1268582176128 [dir=none]
	1268582176128 [label="running_var
 (256)" fillcolor=orange]
	1267569722176 -> 1268582183088 [dir=none]
	1268582183088 [label="weight
 (256)" fillcolor=orange]
	1267569722176 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569721888 -> 1267569722176
	1267569721888 -> 1267569889408 [dir=none]
	1267569889408 [label="input
 (1, 256, 84, 84)" fillcolor=orange]
	1267569721888 -> 1268582183008 [dir=none]
	1268582183008 [label="weight
 (256, 256, 1, 1)" fillcolor=orange]
	1267569721888 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569721552 -> 1267569721888
	1267569721552 -> 1267429758576 [dir=none]
	1267429758576 [label="self
 (1, 256, 84, 84)" fillcolor=orange]
	1267569721552 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569704528 -> 1267569721552
	1267569704528 -> 1267569889488 [dir=none]
	1267569889488 [label="input
 (1, 256, 84, 84)" fillcolor=orange]
	1267569704528 -> 1267429758976 [dir=none]
	1267429758976 [label="result1
 (256)" fillcolor=orange]
	1267569704528 -> 1267429758816 [dir=none]
	1267429758816 [label="result2
 (256)" fillcolor=orange]
	1267569704528 -> 1267429759216 [dir=none]
	1267429759216 [label="result3
 (0)" fillcolor=orange]
	1267569704528 -> 1267569890608 [dir=none]
	1267569890608 [label="running_mean
 (256)" fillcolor=orange]
	1267569704528 -> 1268568557104 [dir=none]
	1268568557104 [label="running_var
 (256)" fillcolor=orange]
	1267569704528 -> 1268582176208 [dir=none]
	1268582176208 [label="weight
 (256)" fillcolor=orange]
	1267569704528 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569703760 -> 1267569704528
	1267569703760 -> 1267569889248 [dir=none]
	1267569889248 [label="input
 (1, 128, 84, 84)" fillcolor=orange]
	1267569703760 -> 1268582183248 [dir=none]
	1268582183248 [label="weight
 (256, 128, 3, 3)" fillcolor=orange]
	1267569703760 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569703136 -> 1267569703760
	1267569703136 -> 1267429758896 [dir=none]
	1267429758896 [label="self
 (1, 128, 84, 84)" fillcolor=orange]
	1267569703136 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569702464 -> 1267569703136
	1267569702464 -> 1267569889728 [dir=none]
	1267569889728 [label="input
 (1, 128, 84, 84)" fillcolor=orange]
	1267569702464 -> 1267429759136 [dir=none]
	1267429759136 [label="result1
 (128)" fillcolor=orange]
	1267569702464 -> 1267429759296 [dir=none]
	1267429759296 [label="result2
 (128)" fillcolor=orange]
	1267569702464 -> 1267429759536 [dir=none]
	1267429759536 [label="result3
 (0)" fillcolor=orange]
	1267569702464 -> 1268582177568 [dir=none]
	1268582177568 [label="running_mean
 (128)" fillcolor=orange]
	1267569702464 -> 1268582177488 [dir=none]
	1268582177488 [label="running_var
 (128)" fillcolor=orange]
	1267569702464 -> 1268582184448 [dir=none]
	1268582184448 [label="weight
 (128)" fillcolor=orange]
	1267569702464 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569702704 -> 1267569702464
	1267569702704 -> 1267569889808 [dir=none]
	1267569889808 [label="input
 (1, 64, 167, 167)" fillcolor=orange]
	1267569702704 -> 1268582171248 [dir=none]
	1268582171248 [label="weight
 (128, 64, 3, 3)" fillcolor=orange]
	1267569702704 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	1267569702080 -> 1267569702704
	1267569702080 -> 1267429759456 [dir=none]
	1267429759456 [label="self
 (1, 64, 167, 167)" fillcolor=orange]
	1267569702080 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569701408 -> 1267569702080
	1267569701408 -> 1267569889648 [dir=none]
	1267569889648 [label="input
 (1, 64, 167, 167)" fillcolor=orange]
	1267569701408 -> 1267429759376 [dir=none]
	1267429759376 [label="result1
 (64)" fillcolor=orange]
	1267569701408 -> 1267429759616 [dir=none]
	1267429759616 [label="result2
 (64)" fillcolor=orange]
	1267569701408 -> 1267429759936 [dir=none]
	1267429759936 [label="result3
 (0)" fillcolor=orange]
	1267569701408 -> 1267569890768 [dir=none]
	1267569890768 [label="running_mean
 (64)" fillcolor=orange]
	1267569701408 -> 1268582171488 [dir=none]
	1268582171488 [label="running_var
 (64)" fillcolor=orange]
	1267569701408 -> 1268582177648 [dir=none]
	1268582177648 [label="weight
 (64)" fillcolor=orange]
	1267569701408 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569700640 -> 1267569701408
	1267569700640 -> 1267569889568 [dir=none]
	1267569889568 [label="input
 (1, 32, 167, 167)" fillcolor=orange]
	1267569700640 -> 1268582184688 [dir=none]
	1268582184688 [label="weight
 (64, 32, 3, 3)" fillcolor=orange]
	1267569700640 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569700016 -> 1267569700640
	1267569700016 -> 1267429759776 [dir=none]
	1267429759776 [label="self
 (1, 32, 167, 167)" fillcolor=orange]
	1267569700016 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569699344 -> 1267569700016
	1267569699344 -> 1267569890048 [dir=none]
	1267569890048 [label="input
 (1, 32, 167, 167)" fillcolor=orange]
	1267569699344 -> 1267429759696 [dir=none]
	1267429759696 [label="result1
 (32)" fillcolor=orange]
	1267569699344 -> 1267429759856 [dir=none]
	1267429759856 [label="result2
 (32)" fillcolor=orange]
	1267569699344 -> 1267429760256 [dir=none]
	1267429760256 [label="result3
 (0)" fillcolor=orange]
	1267569699344 -> 1267569890528 [dir=none]
	1267569890528 [label="running_mean
 (32)" fillcolor=orange]
	1267569699344 -> 1267420302368 [dir=none]
	1267420302368 [label="running_var
 (32)" fillcolor=orange]
	1267569699344 -> 1268582171648 [dir=none]
	1268582171648 [label="weight
 (32)" fillcolor=orange]
	1267569699344 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569699584 -> 1267569699344
	1267569699584 -> 1267569890128 [dir=none]
	1267569890128 [label="input
 (1, 16, 167, 167)" fillcolor=orange]
	1267569699584 -> 1268582177888 [dir=none]
	1268582177888 [label="weight
 (32, 16, 3, 3)" fillcolor=orange]
	1267569699584 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569698960 -> 1267569699584
	1267569698960 -> 1267429760096 [dir=none]
	1267429760096 [label="self
 (1, 16, 167, 167)" fillcolor=orange]
	1267569698960 [label="SiluBackward0
--------------------
self: [saved tensor]"]
	1267569698288 -> 1267569698960
	1267569698288 -> 1267569889968 [dir=none]
	1267569889968 [label="input
 (1, 16, 167, 167)" fillcolor=orange]
	1267569698288 -> 1267429760016 [dir=none]
	1267429760016 [label="result1
 (16)" fillcolor=orange]
	1267569698288 -> 1267429760176 [dir=none]
	1267429760176 [label="result2
 (16)" fillcolor=orange]
	1267569698288 -> 1267429760416 [dir=none]
	1267429760416 [label="result3
 (0)" fillcolor=orange]
	1267569698288 -> 1267569890688 [dir=none]
	1267569890688 [label="running_mean
 (16)" fillcolor=orange]
	1267569698288 -> 1267420275600 [dir=none]
	1267420275600 [label="running_var
 (16)" fillcolor=orange]
	1267569698288 -> 1267420269040 [dir=none]
	1267420269040 [label="weight
 (16)" fillcolor=orange]
	1267569698288 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569697520 -> 1267569698288
	1267569697520 -> 1267569890208 [dir=none]
	1267569890208 [label="input
 (1, 3, 333, 333)" fillcolor=orange]
	1267569697520 -> 1268582177968 [dir=none]
	1268582177968 [label="weight
 (16, 3, 3, 3)" fillcolor=orange]
	1267569697520 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	1267569696896 -> 1267569697520
	1268582177968 [label="stem.conv1.conv.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	1268582177968 -> 1267569696896
	1267569696896 [label=AccumulateGrad]
	1267569698336 -> 1267569698288
	1267420269040 [label="stem.conv1.bn.weight
 (16)" fillcolor=lightblue]
	1267420269040 -> 1267569698336
	1267569698336 [label=AccumulateGrad]
	1267569698096 -> 1267569698288
	1268582178048 [label="stem.conv1.bn.bias
 (16)" fillcolor=lightblue]
	1268582178048 -> 1267569698096
	1267569698096 [label=AccumulateGrad]
	1267569698912 -> 1267569699584
	1268582177888 [label="stem.conv2.conv.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	1268582177888 -> 1267569698912
	1267569698912 [label=AccumulateGrad]
	1267569699392 -> 1267569699344
	1268582171648 [label="stem.conv2.bn.weight
 (32)" fillcolor=lightblue]
	1268582171648 -> 1267569699392
	1267569699392 [label=AccumulateGrad]
	1267569700160 -> 1267569699344
	1268582177808 [label="stem.conv2.bn.bias
 (32)" fillcolor=lightblue]
	1268582177808 -> 1267569700160
	1267569700160 [label=AccumulateGrad]
	1267569699968 -> 1267569700640
	1268582184688 [label="stem.conv3.conv.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	1268582184688 -> 1267569699968
	1267569699968 [label=AccumulateGrad]
	1267569701456 -> 1267569701408
	1268582177648 [label="stem.conv3.bn.weight
 (64)" fillcolor=lightblue]
	1268582177648 -> 1267569701456
	1267569701456 [label=AccumulateGrad]
	1267569701216 -> 1267569701408
	1268582184608 [label="stem.conv3.bn.bias
 (64)" fillcolor=lightblue]
	1268582184608 -> 1267569701216
	1267569701216 [label=AccumulateGrad]
	1267569702032 -> 1267569702704
	1268582171248 [label="stem.conv4.conv.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	1268582171248 -> 1267569702032
	1267569702032 [label=AccumulateGrad]
	1267569702512 -> 1267569702464
	1268582184448 [label="stem.conv4.bn.weight
 (128)" fillcolor=lightblue]
	1268582184448 -> 1267569702512
	1267569702512 [label=AccumulateGrad]
	1267569703280 -> 1267569702464
	1268582171168 [label="stem.conv4.bn.bias
 (128)" fillcolor=lightblue]
	1268582171168 -> 1267569703280
	1267569703280 [label=AccumulateGrad]
	1267569703088 -> 1267569703760
	1268582183248 [label="stages.0.0.conv1_kxk.conv.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	1268582183248 -> 1267569703088
	1267569703088 [label=AccumulateGrad]
	1267569704576 -> 1267569704528
	1268582176208 [label="stages.0.0.conv1_kxk.bn.weight
 (256)" fillcolor=lightblue]
	1268582176208 -> 1267569704576
	1267569704576 [label=AccumulateGrad]
	1267569704336 -> 1267569704528
	1268582176448 [label="stages.0.0.conv1_kxk.bn.bias
 (256)" fillcolor=lightblue]
	1268582176448 -> 1267569704336
	1267569704336 [label=AccumulateGrad]
	1267569721504 -> 1267569721888
	1268582183008 [label="stages.0.0.conv2_1x1.conv.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	1268582183008 -> 1267569721504
	1267569721504 [label=AccumulateGrad]
	1267569721792 -> 1267569722176
	1268582183088 [label="stages.0.0.conv2_1x1.bn.weight
 (256)" fillcolor=lightblue]
	1268582183088 -> 1267569721792
	1267569721792 [label=AccumulateGrad]
	1267569721744 -> 1267569722176
	1268582175968 [label="stages.0.0.conv2_1x1.bn.bias
 (256)" fillcolor=lightblue]
	1268582175968 -> 1267569721744
	1267569721744 [label=AccumulateGrad]
	1267569722128 -> 1267569722608
	1267569722128 -> 1267569889168 [dir=none]
	1267569889168 [label="input
 (1, 256, 84, 84)" fillcolor=orange]
	1267569722128 -> 1267429760336 [dir=none]
	1267429760336 [label="result1
 (256)" fillcolor=orange]
	1267569722128 -> 1267429760496 [dir=none]
	1267429760496 [label="result2
 (256)" fillcolor=orange]
	1267569722128 -> 1267429760736 [dir=none]
	1267429760736 [label="result3
 (0)" fillcolor=orange]
	1267569722128 -> 1267569890848 [dir=none]
	1267569890848 [label="running_mean
 (256)" fillcolor=orange]
	1267569722128 -> 1268568608096 [dir=none]
	1268568608096 [label="running_var
 (256)" fillcolor=orange]
	1267569722128 -> 1268568608176 [dir=none]
	1268568608176 [label="weight
 (256)" fillcolor=orange]
	1267569722128 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569721984 -> 1267569722128
	1267569721984 -> 1267569889248 [dir=none]
	1267569889248 [label="input
 (1, 128, 84, 84)" fillcolor=orange]
	1267569721984 -> 1268462307744 [dir=none]
	1268462307744 [label="weight
 (256, 128, 1, 1)" fillcolor=orange]
	1267569721984 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	1267569703136 -> 1267569721984
	1267569701840 -> 1267569721984
	1268462307744 [label="stages.0.0.shortcut.conv.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	1268462307744 -> 1267569701840
	1267569701840 [label=AccumulateGrad]
	1267569721936 -> 1267569722128
	1268568608176 [label="stages.0.0.shortcut.bn.weight
 (256)" fillcolor=lightblue]
	1268568608176 -> 1267569721936
	1267569721936 [label=AccumulateGrad]
	1267569703952 -> 1267569722128
	1268582176288 [label="stages.0.0.shortcut.bn.bias
 (256)" fillcolor=lightblue]
	1268582176288 -> 1267569703952
	1267569703952 [label=AccumulateGrad]
	1267569722416 -> 1267569722752
	1268582182288 [label="stages.1.0.conv1_1x1.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	1268582182288 -> 1267569722416
	1267569722416 [label=AccumulateGrad]
	1267569723184 -> 1267569723136
	1268582175248 [label="stages.1.0.conv1_1x1.bn.weight
 (128)" fillcolor=lightblue]
	1268582175248 -> 1267569723184
	1267569723184 [label=AccumulateGrad]
	1267569723040 -> 1267569723136
	1268582182208 [label="stages.1.0.conv1_1x1.bn.bias
 (128)" fillcolor=lightblue]
	1268582182208 -> 1267569723040
	1267569723040 [label=AccumulateGrad]
	1267569723424 -> 1267569723808
	1268582181968 [label="stages.1.0.conv2_kxk.conv.weight
 (128, 32, 3, 3)" fillcolor=lightblue]
	1268582181968 -> 1267569723424
	1267569723424 [label=AccumulateGrad]
	1267569723712 -> 1267569723664
	1268582174928 [label="stages.1.0.conv2_kxk.bn.weight
 (128)" fillcolor=lightblue]
	1268582174928 -> 1267569723712
	1267569723712 [label=AccumulateGrad]
	1267569724048 -> 1267569723664
	1268582181888 [label="stages.1.0.conv2_kxk.bn.bias
 (128)" fillcolor=lightblue]
	1268582181888 -> 1267569724048
	1267569724048 [label=AccumulateGrad]
	1267569724480 -> 1267569724336
	1268582181408 [label="stages.1.0.conv2b_kxk.conv.weight
 (128, 32, 3, 3)" fillcolor=lightblue]
	1268582181408 -> 1267569724480
	1267569724480 [label=AccumulateGrad]
	1267569724240 -> 1267569724672
	1268582181488 [label="stages.1.0.conv2b_kxk.bn.weight
 (128)" fillcolor=lightblue]
	1268582181488 -> 1267569724240
	1267569724240 [label=AccumulateGrad]
	1267569725104 -> 1267569724672
	1268582175488 [label="stages.1.0.conv2b_kxk.bn.bias
 (128)" fillcolor=lightblue]
	1268582175488 -> 1267569725104
	1267569725104 [label=AccumulateGrad]
	1267569725008 -> 1267569724864
	1268582179968 [label="stages.1.0.conv3_1x1.conv.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1268582179968 -> 1267569725008
	1267569725008 [label=AccumulateGrad]
	1267569725248 -> 1267569725680
	1268582173808 [label="stages.1.0.conv3_1x1.bn.weight
 (512)" fillcolor=lightblue]
	1268582173808 -> 1267569725248
	1267569725248 [label=AccumulateGrad]
	1267569725728 -> 1267569725680
	1268582179888 [label="stages.1.0.conv3_1x1.bn.bias
 (512)" fillcolor=lightblue]
	1268582179888 -> 1267569725728
	1267569725728 [label=AccumulateGrad]
	1267569725632 -> 1267569725584
	1267569725632 -> 1267569888208 [dir=none]
	1267569888208 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1267569725632 -> 1267429760816 [dir=none]
	1267429760816 [label="result1
 (512)" fillcolor=orange]
	1267569725632 -> 1267429769056 [dir=none]
	1267429769056 [label="result2
 (512)" fillcolor=orange]
	1267569725632 -> 1267429761136 [dir=none]
	1267429761136 [label="result3
 (0)" fillcolor=orange]
	1267569725632 -> 1268582182848 [dir=none]
	1268582182848 [label="running_mean
 (512)" fillcolor=orange]
	1267569725632 -> 1268582175808 [dir=none]
	1268582175808 [label="running_var
 (512)" fillcolor=orange]
	1267569725632 -> 1268582182768 [dir=none]
	1268582182768 [label="weight
 (512)" fillcolor=orange]
	1267569725632 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569724432 -> 1267569725632
	1267569724432 -> 1267569888608 [dir=none]
	1267569888608 [label="input
 (1, 256, 84, 84)" fillcolor=orange]
	1267569724432 -> 1268582182688 [dir=none]
	1268582182688 [label="weight
 (512, 256, 1, 1)" fillcolor=orange]
	1267569724432 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	1267569722464 -> 1267569724432
	1267569723856 -> 1267569724432
	1268582182688 [label="stages.1.0.shortcut.conv.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	1268582182688 -> 1267569723856
	1267569723856 [label=AccumulateGrad]
	1267569724960 -> 1267569725632
	1268582182768 [label="stages.1.0.shortcut.bn.weight
 (512)" fillcolor=lightblue]
	1268582182768 -> 1267569724960
	1267569724960 [label=AccumulateGrad]
	1267569724912 -> 1267569725632
	1268582175648 [label="stages.1.0.shortcut.bn.bias
 (512)" fillcolor=lightblue]
	1268582175648 -> 1267569724912
	1267569724912 [label=AccumulateGrad]
	1267569725488 -> 1267569726304
	1267420242272 [label="stages.1.1.conv1_1x1.conv.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1267420242272 -> 1267569725488
	1267569725488 [label=AccumulateGrad]
	1267569726208 -> 1267569726160
	1267420242592 [label="stages.1.1.conv1_1x1.bn.weight
 (128)" fillcolor=lightblue]
	1267420242592 -> 1267569726208
	1267569726208 [label=AccumulateGrad]
	1267569726544 -> 1267569726160
	1267420248032 [label="stages.1.1.conv1_1x1.bn.bias
 (128)" fillcolor=lightblue]
	1267420248032 -> 1267569726544
	1267569726544 [label=AccumulateGrad]
	1267569726976 -> 1267569726832
	1267420241632 [label="stages.1.1.conv2_kxk.conv.weight
 (128, 32, 3, 3)" fillcolor=lightblue]
	1267420241632 -> 1267569726976
	1267569726976 [label=AccumulateGrad]
	1267569726736 -> 1267569727168
	1267420242992 [label="stages.1.1.conv2_kxk.bn.weight
 (128)" fillcolor=lightblue]
	1267420242992 -> 1267569726736
	1267569726736 [label=AccumulateGrad]
	1267569727600 -> 1267569727168
	1267420244192 [label="stages.1.1.conv2_kxk.bn.bias
 (128)" fillcolor=lightblue]
	1267420244192 -> 1267569727600
	1267569727600 [label=AccumulateGrad]
	1267569727504 -> 1267569727360
	1267420234992 [label="stages.1.1.conv2b_kxk.conv.weight
 (128, 32, 3, 3)" fillcolor=lightblue]
	1267420234992 -> 1267569727504
	1267569727504 [label=AccumulateGrad]
	1267569727744 -> 1267569728224
	1267420245072 [label="stages.1.1.conv2b_kxk.bn.weight
 (128)" fillcolor=lightblue]
	1267420245072 -> 1267569727744
	1267569727744 [label=AccumulateGrad]
	1267569728128 -> 1267569728224
	1267420246912 [label="stages.1.1.conv2b_kxk.bn.bias
 (128)" fillcolor=lightblue]
	1267420246912 -> 1267569728128
	1267569728128 [label=AccumulateGrad]
	1267569728032 -> 1267569728368
	1267420245312 [label="stages.1.1.conv3_1x1.conv.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1267420245312 -> 1267569728032
	1267569728032 [label=AccumulateGrad]
	1267569728800 -> 1267569728704
	1267420235152 [label="stages.1.1.conv3_1x1.bn.weight
 (512)" fillcolor=lightblue]
	1267420235152 -> 1267569728800
	1267569728800 [label=AccumulateGrad]
	1267569728752 -> 1267569728704
	1267420236672 [label="stages.1.1.conv3_1x1.bn.bias
 (512)" fillcolor=lightblue]
	1267420236672 -> 1267569728752
	1267569728752 [label=AccumulateGrad]
	1267569728656 -> 1267569728608
	1267569728992 -> 1267569729328
	1267420248752 [label="stages.1.2.conv1_1x1.conv.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1267420248752 -> 1267569728992
	1267569728992 [label=AccumulateGrad]
	1267569729232 -> 1267569729664
	1267420235392 [label="stages.1.2.conv1_1x1.bn.weight
 (128)" fillcolor=lightblue]
	1267420235392 -> 1267569729232
	1267569729232 [label=AccumulateGrad]
	1267569730096 -> 1267569729664
	1267420242432 [label="stages.1.2.conv1_1x1.bn.bias
 (128)" fillcolor=lightblue]
	1267420242432 -> 1267569730096
	1267569730096 [label=AccumulateGrad]
	1267569730000 -> 1267569729856
	1267420246752 [label="stages.1.2.conv2_kxk.conv.weight
 (128, 32, 3, 3)" fillcolor=lightblue]
	1267420246752 -> 1267569730000
	1267569730000 [label=AccumulateGrad]
	1267569730240 -> 1267569730720
	1267420237472 [label="stages.1.2.conv2_kxk.bn.weight
 (128)" fillcolor=lightblue]
	1267420237472 -> 1267569730240
	1267569730240 [label=AccumulateGrad]
	1267569730624 -> 1267569730720
	1267420243792 [label="stages.1.2.conv2_kxk.bn.bias
 (128)" fillcolor=lightblue]
	1267420243792 -> 1267569730624
	1267569730624 [label=AccumulateGrad]
	1267569730528 -> 1267569730864
	1267420375744 [label="stages.1.2.conv2b_kxk.conv.weight
 (128, 32, 3, 3)" fillcolor=lightblue]
	1267420375744 -> 1267569730528
	1267569730528 [label=AccumulateGrad]
	1267569731296 -> 1267569731248
	1267420369264 [label="stages.1.2.conv2b_kxk.bn.weight
 (128)" fillcolor=lightblue]
	1267420369264 -> 1267569731296
	1267569731296 [label=AccumulateGrad]
	1267569731152 -> 1267569731248
	1267420367744 [label="stages.1.2.conv2b_kxk.bn.bias
 (128)" fillcolor=lightblue]
	1267420367744 -> 1267569731152
	1267569731152 [label=AccumulateGrad]
	1267569731536 -> 1267569731920
	1267420370224 [label="stages.1.2.conv3_1x1.conv.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1267420370224 -> 1267569731536
	1267569731536 [label=AccumulateGrad]
	1267569731824 -> 1267569731728
	1267420377264 [label="stages.1.2.conv3_1x1.bn.weight
 (512)" fillcolor=lightblue]
	1267420377264 -> 1267569731824
	1267569731824 [label=AccumulateGrad]
	1267569731776 -> 1267569731728
	1267420369824 [label="stages.1.2.conv3_1x1.bn.bias
 (512)" fillcolor=lightblue]
	1267420369824 -> 1267569731776
	1267569731776 [label=AccumulateGrad]
	1267569732160 -> 1267569732112
	1267569732544 -> 1267569732352
	1267420373344 [label="stages.1.3.conv1_1x1.conv.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1267420373344 -> 1267569732544
	1267569732544 [label=AccumulateGrad]
	1267569732736 -> 1267569733216
	1267420377104 [label="stages.1.3.conv1_1x1.bn.weight
 (128)" fillcolor=lightblue]
	1267420377104 -> 1267569732736
	1267569732736 [label=AccumulateGrad]
	1267569733120 -> 1267569733216
	1267420373024 [label="stages.1.3.conv1_1x1.bn.bias
 (128)" fillcolor=lightblue]
	1267420373024 -> 1267569733120
	1267569733120 [label=AccumulateGrad]
	1267569733024 -> 1267569733360
	1267420371664 [label="stages.1.3.conv2_kxk.conv.weight
 (128, 32, 3, 3)" fillcolor=lightblue]
	1267420371664 -> 1267569733024
	1267569733024 [label=AccumulateGrad]
	1267569733792 -> 1267569733744
	1267420372784 [label="stages.1.3.conv2_kxk.bn.weight
 (128)" fillcolor=lightblue]
	1267420372784 -> 1267569733792
	1267569733792 [label=AccumulateGrad]
	1267569733648 -> 1267569733744
	1267420373424 [label="stages.1.3.conv2_kxk.bn.bias
 (128)" fillcolor=lightblue]
	1267420373424 -> 1267569733648
	1267569733648 [label=AccumulateGrad]
	1267569734032 -> 1267569734416
	1267420374784 [label="stages.1.3.conv2b_kxk.conv.weight
 (128, 32, 3, 3)" fillcolor=lightblue]
	1267420374784 -> 1267569734032
	1267569734032 [label=AccumulateGrad]
	1267569734320 -> 1267569734272
	1267420372864 [label="stages.1.3.conv2b_kxk.bn.weight
 (128)" fillcolor=lightblue]
	1267420372864 -> 1267569734320
	1267569734320 [label=AccumulateGrad]
	1267569734656 -> 1267569734272
	1267420373104 [label="stages.1.3.conv2b_kxk.bn.bias
 (128)" fillcolor=lightblue]
	1267420373104 -> 1267569734656
	1267569734656 [label=AccumulateGrad]
	1267569735088 -> 1267569734944
	1267420366704 [label="stages.1.3.conv3_1x1.conv.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1267420366704 -> 1267569735088
	1267569735088 [label=AccumulateGrad]
	1267569734848 -> 1267569735232
	1267420374624 [label="stages.1.3.conv3_1x1.bn.weight
 (512)" fillcolor=lightblue]
	1267420374624 -> 1267569734848
	1267569734848 [label=AccumulateGrad]
	1267569735280 -> 1267569735232
	1267420370144 [label="stages.1.3.conv3_1x1.bn.bias
 (512)" fillcolor=lightblue]
	1267420370144 -> 1267569735280
	1267569735280 [label=AccumulateGrad]
	1267569735712 -> 1267569735664
	1267569735472 -> 1267569736336
	1267420373744 [label="stages.2.0.conv1_1x1.conv.weight
 (384, 512, 1, 1)" fillcolor=lightblue]
	1267420373744 -> 1267569735472
	1267569735472 [label=AccumulateGrad]
	1267569736240 -> 1267569736192
	1267420373504 [label="stages.2.0.conv1_1x1.bn.weight
 (384)" fillcolor=lightblue]
	1267420373504 -> 1267569736240
	1267569736240 [label=AccumulateGrad]
	1267569736096 -> 1267569736192
	1267420375344 [label="stages.2.0.conv1_1x1.bn.bias
 (384)" fillcolor=lightblue]
	1267420375344 -> 1267569736096
	1267569736096 [label=AccumulateGrad]
	1267569736480 -> 1267569736864
	1267420366864 [label="stages.2.0.conv2_kxk.conv.weight
 (384, 32, 3, 3)" fillcolor=lightblue]
	1267420366864 -> 1267569736480
	1267569736480 [label=AccumulateGrad]
	1267569736768 -> 1267569736720
	1267420376544 [label="stages.2.0.conv2_kxk.bn.weight
 (384)" fillcolor=lightblue]
	1267420376544 -> 1267569736768
	1267569736768 [label=AccumulateGrad]
	1267569737104 -> 1267569736720
	1267420376624 [label="stages.2.0.conv2_kxk.bn.bias
 (384)" fillcolor=lightblue]
	1267420376624 -> 1267569737104
	1267569737104 [label=AccumulateGrad]
	1267569737536 -> 1267569737392
	1267420367504 [label="stages.2.0.conv2b_kxk.conv.weight
 (384, 32, 3, 3)" fillcolor=lightblue]
	1267420367504 -> 1267569737536
	1267569737536 [label=AccumulateGrad]
	1267569721648 -> 1267569721600
	1267420371904 [label="stages.2.0.conv2b_kxk.bn.weight
 (384)" fillcolor=lightblue]
	1267420371904 -> 1267569721648
	1267569721648 [label=AccumulateGrad]
	1267569721408 -> 1267569721600
	1267420367824 [label="stages.2.0.conv2b_kxk.bn.bias
 (384)" fillcolor=lightblue]
	1267420367824 -> 1267569721408
	1267569721408 [label=AccumulateGrad]
	1267569722080 -> 1267569722848
	1267420368624 [label="stages.2.0.conv3_1x1.conv.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1267420368624 -> 1267569722080
	1267569722080 [label=AccumulateGrad]
	1267569722656 -> 1267569723472
	1267420372144 [label="stages.2.0.conv3_1x1.bn.weight
 (1536)" fillcolor=lightblue]
	1267420372144 -> 1267569722656
	1267569722656 [label=AccumulateGrad]
	1267569723520 -> 1267569723472
	1267420367984 [label="stages.2.0.conv3_1x1.bn.bias
 (1536)" fillcolor=lightblue]
	1267420367984 -> 1267569723520
	1267569723520 [label=AccumulateGrad]
	1267569723328 -> 1267569723280
	1267569723328 -> 1267569885408 [dir=none]
	1267569885408 [label="input
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569723328 -> 1267429760576 [dir=none]
	1267429760576 [label="result1
 (1536)" fillcolor=orange]
	1267569723328 -> 1267429761056 [dir=none]
	1267429761056 [label="result2
 (1536)" fillcolor=orange]
	1267569723328 -> 1267429758176 [dir=none]
	1267429758176 [label="result3
 (0)" fillcolor=orange]
	1267569723328 -> 1268582184368 [dir=none]
	1268582184368 [label="running_mean
 (1536)" fillcolor=orange]
	1267569723328 -> 1267420379504 [dir=none]
	1267420379504 [label="running_var
 (1536)" fillcolor=orange]
	1267569723328 -> 1267420374544 [dir=none]
	1267420374544 [label="weight
 (1536)" fillcolor=orange]
	1267569723328 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569737488 -> 1267569723328
	1267569737488 -> 1267569886048 [dir=none]
	1267569886048 [label="input
 (1, 512, 42, 42)" fillcolor=orange]
	1267569737488 -> 1267420374224 [dir=none]
	1267420374224 [label="weight
 (1536, 512, 1, 1)" fillcolor=orange]
	1267569737488 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	1267569735520 -> 1267569737488
	1267569736912 -> 1267569737488
	1267420374224 [label="stages.2.0.shortcut.conv.weight
 (1536, 512, 1, 1)" fillcolor=lightblue]
	1267420374224 -> 1267569736912
	1267569736912 [label=AccumulateGrad]
	1267569722032 -> 1267569723328
	1267420374544 [label="stages.2.0.shortcut.bn.weight
 (1536)" fillcolor=lightblue]
	1267420374544 -> 1267569722032
	1267569722032 [label=AccumulateGrad]
	1267569722896 -> 1267569723328
	1267420379824 [label="stages.2.0.shortcut.bn.bias
 (1536)" fillcolor=lightblue]
	1267420379824 -> 1267569722896
	1267569722896 [label=AccumulateGrad]
	1267569724096 -> 1267569724720
	1267420380624 [label="stages.2.1.conv1_1x1.conv.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1267420380624 -> 1267569724096
	1267569724096 [label=AccumulateGrad]
	1267569724528 -> 1267569725392
	1267420371584 [label="stages.2.1.conv1_1x1.bn.weight
 (384)" fillcolor=lightblue]
	1267420371584 -> 1267569724528
	1267569724528 [label=AccumulateGrad]
	1267569725200 -> 1267569725392
	1267420374864 [label="stages.2.1.conv1_1x1.bn.bias
 (384)" fillcolor=lightblue]
	1267420374864 -> 1267569725200
	1267569725200 [label=AccumulateGrad]
	1267569726016 -> 1267569725776
	1267420370864 [label="stages.2.1.conv2_kxk.conv.weight
 (384, 32, 3, 3)" fillcolor=lightblue]
	1267420370864 -> 1267569726016
	1267569726016 [label=AccumulateGrad]
	1267569726592 -> 1267569726448
	1267420380384 [label="stages.2.1.conv2_kxk.bn.weight
 (384)" fillcolor=lightblue]
	1267420380384 -> 1267569726592
	1267569726592 [label=AccumulateGrad]
	1267569727264 -> 1267569726448
	1267420369744 [label="stages.2.1.conv2_kxk.bn.bias
 (384)" fillcolor=lightblue]
	1267420369744 -> 1267569727264
	1267569727264 [label=AccumulateGrad]
	1267569727072 -> 1267569727840
	1267420370544 [label="stages.2.1.conv2b_kxk.conv.weight
 (384, 32, 3, 3)" fillcolor=lightblue]
	1267420370544 -> 1267569727072
	1267569727072 [label=AccumulateGrad]
	1267569727648 -> 1267569728512
	1267420370464 [label="stages.2.1.conv2b_kxk.bn.weight
 (384)" fillcolor=lightblue]
	1267420370464 -> 1267569727648
	1267569727648 [label=AccumulateGrad]
	1267569728320 -> 1267569728512
	1267420380544 [label="stages.2.1.conv2b_kxk.bn.bias
 (384)" fillcolor=lightblue]
	1267420380544 -> 1267569728320
	1267569728320 [label=AccumulateGrad]
	1267569729136 -> 1267569728896
	1267420366784 [label="stages.2.1.conv3_1x1.conv.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1267420366784 -> 1267569729136
	1267569729136 [label=AccumulateGrad]
	1267569729712 -> 1267569729520
	1267420367264 [label="stages.2.1.conv3_1x1.bn.weight
 (1536)" fillcolor=lightblue]
	1267420367264 -> 1267569729712
	1267569729712 [label=AccumulateGrad]
	1267569729568 -> 1267569729520
	1267420376864 [label="stages.2.1.conv3_1x1.bn.bias
 (1536)" fillcolor=lightblue]
	1267420376864 -> 1267569729568
	1267569729568 [label=AccumulateGrad]
	1267569730384 -> 1267569730336
	1267569730144 -> 1267569730768
	1267420367104 [label="stages.2.2.conv1_1x1.conv.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1267420367104 -> 1267569730144
	1267569730144 [label=AccumulateGrad]
	1267569731584 -> 1267569731440
	1267420366944 [label="stages.2.2.conv1_1x1.bn.weight
 (384)" fillcolor=lightblue]
	1267420366944 -> 1267569731584
	1267569731584 [label=AccumulateGrad]
	1267569732256 -> 1267569731440
	1267420368144 [label="stages.2.2.conv1_1x1.bn.bias
 (384)" fillcolor=lightblue]
	1267420368144 -> 1267569732256
	1267569732256 [label=AccumulateGrad]
	1267569732064 -> 1267569732832
	1267420366144 [label="stages.2.2.conv2_kxk.conv.weight
 (384, 32, 3, 3)" fillcolor=lightblue]
	1267420366144 -> 1267569732064
	1267569732064 [label=AccumulateGrad]
	1267569732640 -> 1267569733504
	1267420366464 [label="stages.2.2.conv2_kxk.bn.weight
 (384)" fillcolor=lightblue]
	1267420366464 -> 1267569732640
	1267569732640 [label=AccumulateGrad]
	1267569733312 -> 1267569733504
	1267420379264 [label="stages.2.2.conv2_kxk.bn.bias
 (384)" fillcolor=lightblue]
	1267420379264 -> 1267569733312
	1267569733312 [label=AccumulateGrad]
	1267569734128 -> 1267569733888
	1267420374944 [label="stages.2.2.conv2b_kxk.conv.weight
 (384, 32, 3, 3)" fillcolor=lightblue]
	1267420374944 -> 1267569734128
	1267569734128 [label=AccumulateGrad]
	1267569734704 -> 1267569734560
	1267420367904 [label="stages.2.2.conv2b_kxk.bn.weight
 (384)" fillcolor=lightblue]
	1267420367904 -> 1267569734704
	1267569734704 [label=AccumulateGrad]
	1267569735376 -> 1267569734560
	1267420375104 [label="stages.2.2.conv2b_kxk.bn.bias
 (384)" fillcolor=lightblue]
	1267420375104 -> 1267569735376
	1267569735376 [label=AccumulateGrad]
	1267569735184 -> 1267569735952
	1267420380784 [label="stages.2.2.conv3_1x1.conv.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1267420380784 -> 1267569735184
	1267569735184 [label=AccumulateGrad]
	1267569735760 -> 1267569736576
	1267420364864 [label="stages.2.2.conv3_1x1.bn.weight
 (1536)" fillcolor=lightblue]
	1267420364864 -> 1267569735760
	1267569735760 [label=AccumulateGrad]
	1267569736624 -> 1267569736576
	1267420379584 [label="stages.2.2.conv3_1x1.bn.bias
 (1536)" fillcolor=lightblue]
	1267420379584 -> 1267569736624
	1267569736624 [label=AccumulateGrad]
	1267569736432 -> 1267569736384
	1267569737200 -> 1267569819712
	1267420365744 [label="stages.2.3.conv1_1x1.conv.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1267420365744 -> 1267569737200
	1267569737200 [label=AccumulateGrad]
	1267569820096 -> 1267569820192
	1267420368064 [label="stages.2.3.conv1_1x1.bn.weight
 (384)" fillcolor=lightblue]
	1267420368064 -> 1267569820096
	1267569820096 [label=AccumulateGrad]
	1267569737632 -> 1267569820192
	1267420377664 [label="stages.2.3.conv1_1x1.bn.bias
 (384)" fillcolor=lightblue]
	1267420377664 -> 1267569737632
	1267569737632 [label=AccumulateGrad]
	1267569820000 -> 1267569820336
	1267420378064 [label="stages.2.3.conv2_kxk.conv.weight
 (384, 32, 3, 3)" fillcolor=lightblue]
	1267420378064 -> 1267569820000
	1267569820000 [label=AccumulateGrad]
	1267569820768 -> 1267569820720
	1267420378224 [label="stages.2.3.conv2_kxk.bn.weight
 (384)" fillcolor=lightblue]
	1267420378224 -> 1267569820768
	1267569820768 [label=AccumulateGrad]
	1267569820624 -> 1267569820720
	1267420377824 [label="stages.2.3.conv2_kxk.bn.bias
 (384)" fillcolor=lightblue]
	1267420377824 -> 1267569820624
	1267569820624 [label=AccumulateGrad]
	1267569821008 -> 1267569821392
	1267420379424 [label="stages.2.3.conv2b_kxk.conv.weight
 (384, 32, 3, 3)" fillcolor=lightblue]
	1267420379424 -> 1267569821008
	1267569821008 [label=AccumulateGrad]
	1267569821296 -> 1267569821248
	1267420378544 [label="stages.2.3.conv2b_kxk.bn.weight
 (384)" fillcolor=lightblue]
	1267420378544 -> 1267569821296
	1267569821296 [label=AccumulateGrad]
	1267569821632 -> 1267569821248
	1267420369184 [label="stages.2.3.conv2b_kxk.bn.bias
 (384)" fillcolor=lightblue]
	1267420369184 -> 1267569821632
	1267569821632 [label=AccumulateGrad]
	1267569822064 -> 1267569821920
	1267420378944 [label="stages.2.3.conv3_1x1.conv.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1267420378944 -> 1267569822064
	1267569822064 [label=AccumulateGrad]
	1267569821824 -> 1267569822208
	1267420365584 [label="stages.2.3.conv3_1x1.bn.weight
 (1536)" fillcolor=lightblue]
	1267420365584 -> 1267569821824
	1267569821824 [label=AccumulateGrad]
	1267569822256 -> 1267569822208
	1267420379184 [label="stages.2.3.conv3_1x1.bn.bias
 (1536)" fillcolor=lightblue]
	1267420379184 -> 1267569822256
	1267569822256 [label=AccumulateGrad]
	1267569822688 -> 1267569822640
	1267569822544 -> 1267569822832
	1267420369504 [label="stages.2.4.conv1_1x1.conv.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1267420369504 -> 1267569822544
	1267569822544 [label=AccumulateGrad]
	1267569823264 -> 1267569823216
	1267420377344 [label="stages.2.4.conv1_1x1.bn.weight
 (384)" fillcolor=lightblue]
	1267420377344 -> 1267569823264
	1267569823264 [label=AccumulateGrad]
	1267569823120 -> 1267569823216
	1267420368864 [label="stages.2.4.conv1_1x1.bn.bias
 (384)" fillcolor=lightblue]
	1267420368864 -> 1267569823120
	1267569823120 [label=AccumulateGrad]
	1267569823504 -> 1267569823888
	1267420374384 [label="stages.2.4.conv2_kxk.conv.weight
 (384, 32, 3, 3)" fillcolor=lightblue]
	1267420374384 -> 1267569823504
	1267569823504 [label=AccumulateGrad]
	1267569823792 -> 1267569823744
	1267420375264 [label="stages.2.4.conv2_kxk.bn.weight
 (384)" fillcolor=lightblue]
	1267420375264 -> 1267569823792
	1267569823792 [label=AccumulateGrad]
	1267569824128 -> 1267569823744
	1267420370704 [label="stages.2.4.conv2_kxk.bn.bias
 (384)" fillcolor=lightblue]
	1267420370704 -> 1267569824128
	1267569824128 [label=AccumulateGrad]
	1267569824560 -> 1267569824416
	1267420065808 [label="stages.2.4.conv2b_kxk.conv.weight
 (384, 32, 3, 3)" fillcolor=lightblue]
	1267420065808 -> 1267569824560
	1267569824560 [label=AccumulateGrad]
	1267569824320 -> 1267569824752
	1267420054848 [label="stages.2.4.conv2b_kxk.bn.weight
 (384)" fillcolor=lightblue]
	1267420054848 -> 1267569824320
	1267569824320 [label=AccumulateGrad]
	1267569825184 -> 1267569824752
	1267420067648 [label="stages.2.4.conv2b_kxk.bn.bias
 (384)" fillcolor=lightblue]
	1267420067648 -> 1267569825184
	1267569825184 [label=AccumulateGrad]
	1267569825088 -> 1267569824944
	1267420068528 [label="stages.2.4.conv3_1x1.conv.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1267420068528 -> 1267569825088
	1267569825088 [label=AccumulateGrad]
	1267569825328 -> 1267569825760
	1267420056768 [label="stages.2.4.conv3_1x1.bn.weight
 (1536)" fillcolor=lightblue]
	1267420056768 -> 1267569825328
	1267569825328 [label=AccumulateGrad]
	1267569825808 -> 1267569825760
	1267420068048 [label="stages.2.4.conv3_1x1.bn.bias
 (1536)" fillcolor=lightblue]
	1267420068048 -> 1267569825808
	1267569825808 [label=AccumulateGrad]
	1267569825712 -> 1267569825664
	1267569825568 -> 1267569826384
	1267420067888 [label="stages.2.5.conv1_1x1.conv.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1267420067888 -> 1267569825568
	1267569825568 [label=AccumulateGrad]
	1267569826288 -> 1267569826240
	1267420067968 [label="stages.2.5.conv1_1x1.bn.weight
 (384)" fillcolor=lightblue]
	1267420067968 -> 1267569826288
	1267569826288 [label=AccumulateGrad]
	1267569826624 -> 1267569826240
	1267420055328 [label="stages.2.5.conv1_1x1.bn.bias
 (384)" fillcolor=lightblue]
	1267420055328 -> 1267569826624
	1267569826624 [label=AccumulateGrad]
	1267569827056 -> 1267569826912
	1267420054688 [label="stages.2.5.conv2_kxk.conv.weight
 (384, 32, 3, 3)" fillcolor=lightblue]
	1267420054688 -> 1267569827056
	1267569827056 [label=AccumulateGrad]
	1267569826816 -> 1267569827248
	1267420061008 [label="stages.2.5.conv2_kxk.bn.weight
 (384)" fillcolor=lightblue]
	1267420061008 -> 1267569826816
	1267569826816 [label=AccumulateGrad]
	1267569827680 -> 1267569827248
	1267420059488 [label="stages.2.5.conv2_kxk.bn.bias
 (384)" fillcolor=lightblue]
	1267420059488 -> 1267569827680
	1267569827680 [label=AccumulateGrad]
	1267569827584 -> 1267569827440
	1267420054128 [label="stages.2.5.conv2b_kxk.conv.weight
 (384, 32, 3, 3)" fillcolor=lightblue]
	1267420054128 -> 1267569827584
	1267569827584 [label=AccumulateGrad]
	1267569827824 -> 1267569828304
	1267420059008 [label="stages.2.5.conv2b_kxk.bn.weight
 (384)" fillcolor=lightblue]
	1267420059008 -> 1267569827824
	1267569827824 [label=AccumulateGrad]
	1267569828208 -> 1267569828304
	1267420053968 [label="stages.2.5.conv2b_kxk.bn.bias
 (384)" fillcolor=lightblue]
	1267420053968 -> 1267569828208
	1267569828208 [label=AccumulateGrad]
	1267569828112 -> 1267569828448
	1267420056528 [label="stages.2.5.conv3_1x1.conv.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1267420056528 -> 1267569828112
	1267569828112 [label=AccumulateGrad]
	1267569828880 -> 1267569828784
	1267420057168 [label="stages.2.5.conv3_1x1.bn.weight
 (1536)" fillcolor=lightblue]
	1267420057168 -> 1267569828880
	1267569828880 [label=AccumulateGrad]
	1267569828832 -> 1267569828784
	1267420055248 [label="stages.2.5.conv3_1x1.bn.bias
 (1536)" fillcolor=lightblue]
	1267420055248 -> 1267569828832
	1267569828832 [label=AccumulateGrad]
	1267569828736 -> 1267569828688
	1267569829504 -> 1267569829360
	1267420059888 [label="stages.3.0.conv1_1x1.conv.weight
 (1536, 1536, 1, 1)" fillcolor=lightblue]
	1267420059888 -> 1267569829504
	1267569829504 [label=AccumulateGrad]
	1267569829744 -> 1267569829696
	1267420059168 [label="stages.3.0.conv1_1x1.bn.weight
 (1536)" fillcolor=lightblue]
	1267420059168 -> 1267569829744
	1267569829744 [label=AccumulateGrad]
	1267569830128 -> 1267569829696
	1267420060528 [label="stages.3.0.conv1_1x1.bn.bias
 (1536)" fillcolor=lightblue]
	1267420060528 -> 1267569830128
	1267569830128 [label=AccumulateGrad]
	1267569830032 -> 1267569830368
	1267420061808 [label="stages.3.0.conv2_kxk.conv.weight
 (1536, 1, 3, 3)" fillcolor=lightblue]
	1267420061808 -> 1267569830032
	1267569830032 [label=AccumulateGrad]
	1267569830800 -> 1267569830752
	1267420063888 [label="stages.3.0.conv2_kxk.bn.weight
 (1536)" fillcolor=lightblue]
	1267420063888 -> 1267569830800
	1267569830800 [label=AccumulateGrad]
	1267569830656 -> 1267569830752
	1267420062608 [label="stages.3.0.conv2_kxk.bn.bias
 (1536)" fillcolor=lightblue]
	1267420062608 -> 1267569830656
	1267569830656 [label=AccumulateGrad]
	1267569830560 -> 1267569831424
	1267420064928 [label="stages.3.0.conv2b_kxk.conv.weight
 (1536, 1, 3, 3)" fillcolor=lightblue]
	1267420064928 -> 1267569830560
	1267569830560 [label=AccumulateGrad]
	1267569831328 -> 1267569831280
	1267420066208 [label="stages.3.0.conv2b_kxk.bn.weight
 (1536)" fillcolor=lightblue]
	1267420066208 -> 1267569831328
	1267569831328 [label=AccumulateGrad]
	1267569831184 -> 1267569831280
	1267420058128 [label="stages.3.0.conv2b_kxk.bn.bias
 (1536)" fillcolor=lightblue]
	1267420058128 -> 1267569831184
	1267569831184 [label=AccumulateGrad]
	1267569831568 -> 1267569831952
	1267420057968 [label="stages.3.0.conv3_1x1.conv.weight
 (1536, 1536, 1, 1)" fillcolor=lightblue]
	1267420057968 -> 1267569831568
	1267569831568 [label=AccumulateGrad]
	1267569831904 -> 1267569831808
	1267420066528 [label="stages.3.0.conv3_1x1.bn.weight
 (1536)" fillcolor=lightblue]
	1267420066528 -> 1267569831904
	1267569831904 [label=AccumulateGrad]
	1267569831856 -> 1267569831808
	1267420057008 [label="stages.3.0.conv3_1x1.bn.bias
 (1536)" fillcolor=lightblue]
	1267420057008 -> 1267569831856
	1267569831856 [label=AccumulateGrad]
	1267569832240 -> 1267569832192
	1267569832240 -> 1267568937136 [dir=none]
	1267568937136 [label="input
 (1, 1536, 11, 11)" fillcolor=orange]
	1267569832240 -> 1267429761456 [dir=none]
	1267429761456 [label="result1
 (1536)" fillcolor=orange]
	1267569832240 -> 1267429760976 [dir=none]
	1267429760976 [label="result2
 (1536)" fillcolor=orange]
	1267569832240 -> 1267429760656 [dir=none]
	1267429760656 [label="result3
 (0)" fillcolor=orange]
	1267569832240 -> 1267420069808 [dir=none]
	1267420069808 [label="running_mean
 (1536)" fillcolor=orange]
	1267569832240 -> 1267420057488 [dir=none]
	1267420057488 [label="running_var
 (1536)" fillcolor=orange]
	1267569832240 -> 1267420056208 [dir=none]
	1267420056208 [label="weight
 (1536)" fillcolor=orange]
	1267569832240 [label="CudnnBatchNormBackward0
----------------------------
epsilon     :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
result3     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	1267569830992 -> 1267569832240
	1267569830992 -> 1267568935776 [dir=none]
	1267568935776 [label="input
 (1, 1536, 21, 21)" fillcolor=orange]
	1267569830992 -> 1267420061488 [dir=none]
	1267420061488 [label="weight
 (1536, 1536, 1, 1)" fillcolor=orange]
	1267569830992 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	1267569829552 -> 1267569830992
	1267569829936 -> 1267569830992
	1267420061488 [label="stages.3.0.shortcut.conv.weight
 (1536, 1536, 1, 1)" fillcolor=lightblue]
	1267420061488 -> 1267569829936
	1267569829936 [label=AccumulateGrad]
	1267569832048 -> 1267569832240
	1267420056208 [label="stages.3.0.shortcut.bn.weight
 (1536)" fillcolor=lightblue]
	1267420056208 -> 1267569832048
	1267569832048 [label=AccumulateGrad]
	1267569832000 -> 1267569832240
	1267420060208 [label="stages.3.0.shortcut.bn.bias
 (1536)" fillcolor=lightblue]
	1267420060208 -> 1267569832000
	1267569832000 [label=AccumulateGrad]
	1267569832624 -> 1267569832432
	1267420120784 [label="stages.3.1.conv1_1x1.conv.weight
 (1536, 1536, 1, 1)" fillcolor=lightblue]
	1267420120784 -> 1267569832624
	1267569832624 [label=AccumulateGrad]
	1267569832864 -> 1267569832816
	1267420121424 [label="stages.3.1.conv1_1x1.bn.weight
 (1536)" fillcolor=lightblue]
	1267420121424 -> 1267569832864
	1267569832864 [label=AccumulateGrad]
	1267569833248 -> 1267569832816
	1267420128784 [label="stages.3.1.conv1_1x1.bn.bias
 (1536)" fillcolor=lightblue]
	1267420128784 -> 1267569833248
	1267569833248 [label=AccumulateGrad]
	1267569833152 -> 1267569833488
	1267420119584 [label="stages.3.1.conv2_kxk.conv.weight
 (1536, 1, 3, 3)" fillcolor=lightblue]
	1267420119584 -> 1267569833152
	1267569833152 [label=AccumulateGrad]
	1267569833440 -> 1267569833920
	1267420119904 [label="stages.3.1.conv2_kxk.bn.weight
 (1536)" fillcolor=lightblue]
	1267420119904 -> 1267569833440
	1267569833440 [label=AccumulateGrad]
	1267569833824 -> 1267569833920
	1267420120384 [label="stages.3.1.conv2_kxk.bn.bias
 (1536)" fillcolor=lightblue]
	1267420120384 -> 1267569833824
	1267569833824 [label=AccumulateGrad]
	1267569833728 -> 1267569834064
	1267420121824 [label="stages.3.1.conv2b_kxk.conv.weight
 (1536, 1, 3, 3)" fillcolor=lightblue]
	1267420121824 -> 1267569833728
	1267569833728 [label=AccumulateGrad]
	1267569834496 -> 1267569834448
	1267420121664 [label="stages.3.1.conv2b_kxk.bn.weight
 (1536)" fillcolor=lightblue]
	1267420121664 -> 1267569834496
	1267569834496 [label=AccumulateGrad]
	1267569834352 -> 1267569834448
	1267420121344 [label="stages.3.1.conv2b_kxk.bn.bias
 (1536)" fillcolor=lightblue]
	1267420121344 -> 1267569834352
	1267569834352 [label=AccumulateGrad]
	1267569834736 -> 1267569835120
	1267420123824 [label="stages.3.1.conv3_1x1.conv.weight
 (1536, 1536, 1, 1)" fillcolor=lightblue]
	1267420123824 -> 1267569834736
	1267569834736 [label=AccumulateGrad]
	1267569835072 -> 1267569834976
	1267420123504 [label="stages.3.1.conv3_1x1.bn.weight
 (1536)" fillcolor=lightblue]
	1267420123504 -> 1267569835072
	1267569835072 [label=AccumulateGrad]
	1267569835024 -> 1267569834976
	1267420123184 [label="stages.3.1.conv3_1x1.bn.bias
 (1536)" fillcolor=lightblue]
	1267420123184 -> 1267569835024
	1267569835024 [label=AccumulateGrad]
	1267569834928 -> 1267569835360
	1267569835792 -> 1267569835984
	1267420124144 [label="stages.3.2.conv1_1x1.conv.weight
 (1536, 1536, 1, 1)" fillcolor=lightblue]
	1267420124144 -> 1267569835792
	1267569835792 [label=AccumulateGrad]
	1267569835600 -> 1267569835936
	1267420124624 [label="stages.3.2.conv1_1x1.bn.weight
 (1536)" fillcolor=lightblue]
	1267420124624 -> 1267569835600
	1267569835600 [label=AccumulateGrad]
	1267569819808 -> 1267569835936
	1267420124304 [label="stages.3.2.conv1_1x1.bn.bias
 (1536)" fillcolor=lightblue]
	1267420124304 -> 1267569819808
	1267569819808 [label=AccumulateGrad]
	1267569820432 -> 1267569821104
	1267420124464 [label="stages.3.2.conv2_kxk.conv.weight
 (1536, 1, 3, 3)" fillcolor=lightblue]
	1267420124464 -> 1267569820432
	1267569820432 [label=AccumulateGrad]
	1267569821056 -> 1267569820912
	1267420124784 [label="stages.3.2.conv2_kxk.bn.weight
 (1536)" fillcolor=lightblue]
	1267420124784 -> 1267569821056
	1267569821056 [label=AccumulateGrad]
	1267569821728 -> 1267569820912
	1267420125424 [label="stages.3.2.conv2_kxk.bn.bias
 (1536)" fillcolor=lightblue]
	1267420125424 -> 1267569821728
	1267569821728 [label=AccumulateGrad]
	1267569821536 -> 1267569822304
	1267420127024 [label="stages.3.2.conv2b_kxk.conv.weight
 (1536, 1, 3, 3)" fillcolor=lightblue]
	1267420127024 -> 1267569821536
	1267569821536 [label=AccumulateGrad]
	1267569822160 -> 1267569822112
	1267420126864 [label="stages.3.2.conv2b_kxk.bn.weight
 (1536)" fillcolor=lightblue]
	1267420126864 -> 1267569822160
	1267569822160 [label=AccumulateGrad]
	1267569822928 -> 1267569822112
	1267420127504 [label="stages.3.2.conv2b_kxk.bn.bias
 (1536)" fillcolor=lightblue]
	1267420127504 -> 1267569822928
	1267569822928 [label=AccumulateGrad]
	1267569822736 -> 1267569823408
	1267420128384 [label="stages.3.2.conv3_1x1.conv.weight
 (1536, 1536, 1, 1)" fillcolor=lightblue]
	1267420128384 -> 1267569822736
	1267569822736 [label=AccumulateGrad]
	1267569823360 -> 1267569824176
	1267420127664 [label="stages.3.2.conv3_1x1.bn.weight
 (1536)" fillcolor=lightblue]
	1267420127664 -> 1267569823360
	1267569823360 [label=AccumulateGrad]
	1267569824224 -> 1267569824176
	1267420129024 [label="stages.3.2.conv3_1x1.bn.bias
 (1536)" fillcolor=lightblue]
	1267420129024 -> 1267569824224
	1267569824224 [label=AccumulateGrad]
	1267569824032 -> 1267569823984
	1267569824800 -> 1267569825424
	1267420127824 [label="stages.3.3.conv1_1x1.conv.weight
 (1536, 1536, 1, 1)" fillcolor=lightblue]
	1267420127824 -> 1267569824800
	1267569824800 [label=AccumulateGrad]
	1267569825280 -> 1267569825232
	1267420128224 [label="stages.3.3.conv1_1x1.bn.weight
 (1536)" fillcolor=lightblue]
	1267420128224 -> 1267569825280
	1267569825280 [label=AccumulateGrad]
	1267569826048 -> 1267569825232
	1267420129344 [label="stages.3.3.conv1_1x1.bn.bias
 (1536)" fillcolor=lightblue]
	1267420129344 -> 1267569826048
	1267569826048 [label=AccumulateGrad]
	1267569825856 -> 1267569826528
	1267420131904 [label="stages.3.3.conv2_kxk.conv.weight
 (1536, 1, 3, 3)" fillcolor=lightblue]
	1267420131904 -> 1267569825856
	1267569825856 [label=AccumulateGrad]
	1267569826480 -> 1267569827344
	1267420131104 [label="stages.3.3.conv2_kxk.bn.weight
 (1536)" fillcolor=lightblue]
	1267420131104 -> 1267569826480
	1267569826480 [label=AccumulateGrad]
	1267569827152 -> 1267569827344
	1267420131264 [label="stages.3.3.conv2_kxk.bn.bias
 (1536)" fillcolor=lightblue]
	1267420131264 -> 1267569827152
	1267569827152 [label=AccumulateGrad]
	1267569827968 -> 1267569827728
	1267420132384 [label="stages.3.3.conv2b_kxk.conv.weight
 (1536, 1, 3, 3)" fillcolor=lightblue]
	1267420132384 -> 1267569827968
	1267569827968 [label=AccumulateGrad]
	1267569828592 -> 1267569828544
	1267420132864 [label="stages.3.3.conv2b_kxk.bn.weight
 (1536)" fillcolor=lightblue]
	1267420132864 -> 1267569828592
	1267569828592 [label=AccumulateGrad]
	1267569828352 -> 1267569828544
	1267420132224 [label="stages.3.3.conv2b_kxk.bn.bias
 (1536)" fillcolor=lightblue]
	1267420132224 -> 1267569828352
	1267569828352 [label=AccumulateGrad]
	1267569829168 -> 1267569829840
	1267420132704 [label="stages.3.3.conv3_1x1.conv.weight
 (1536, 1536, 1, 1)" fillcolor=lightblue]
	1267420132704 -> 1267569829168
	1267569829168 [label=AccumulateGrad]
	1267569829792 -> 1267569829600
	1267420132544 [label="stages.3.3.conv3_1x1.bn.weight
 (1536)" fillcolor=lightblue]
	1267420132544 -> 1267569829792
	1267569829792 [label=AccumulateGrad]
	1267569829648 -> 1267569829600
	1267420133744 [label="stages.3.3.conv3_1x1.bn.bias
 (1536)" fillcolor=lightblue]
	1267420133744 -> 1267569829648
	1267569829648 [label=AccumulateGrad]
	1267569830464 -> 1267569830416
	1267569831040 -> 1267569831712
	1267420134064 [label="final_conv.conv.weight
 (2048, 1536, 1, 1)" fillcolor=lightblue]
	1267420134064 -> 1267569831040
	1267569831040 [label=AccumulateGrad]
	1267569831664 -> 1267569831520
	1267420134384 [label="final_conv.bn.weight
 (2048)" fillcolor=lightblue]
	1267420134384 -> 1267569831664
	1267569831664 [label=AccumulateGrad]
	1267569832720 -> 1267569831520
	1267420119104 [label="final_conv.bn.bias
 (2048)" fillcolor=lightblue]
	1267420119104 -> 1267569832720
	1267569832720 [label=AccumulateGrad]
	1267569832960 -> 1267569833536
	1267569832960 [label=TBackward0]
	1267569831472 -> 1267569832960
	1268568557904 [label="head.fc.weight
 (4, 2048)" fillcolor=lightblue]
	1268568557904 -> 1267569831472
	1267569831472 [label=AccumulateGrad]
	1267569833536 -> 1267568940256
}
