digraph {
	graph [size="288.15,288.15"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1904566218848 [label="
 (1, 4)" fillcolor=darkolivegreen1]
	1904570971760 -> 1904566216608 [dir=none]
	1904566216608 [label="mat1
 (1, 768)" fillcolor=orange]
	1904570971760 -> 1904439726608 [dir=none]
	1904439726608 [label="mat2
 (768, 4)" fillcolor=orange]
	1904570971760 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (1, 768)
mat1_sym_strides:    (443136, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (768, 4)
mat2_sym_strides:       (1, 768)"]
	1904570970320 -> 1904570971760
	1904566118304 [label="head.bias
 (4)" fillcolor=lightblue]
	1904566118304 -> 1904570970320
	1904570970320 [label=AccumulateGrad]
	1904570971136 -> 1904570971760
	1904570971136 [label="SelectBackward0
-----------------------------
dim           :             1
index         :             0
self_sym_sizes: (1, 577, 768)"]
	1904570970992 -> 1904570971136
	1904570970992 [label="SliceBackward0
-----------------------------
dim           :             0
end           :    4294967295
self_sym_sizes: (1, 577, 768)
start         :             0
step          :             1"]
	1904570970560 -> 1904570970992
	1904570970560 -> 1904566117664 [dir=none]
	1904566117664 [label="bias
 (768)" fillcolor=orange]
	1904570970560 -> 1904566216928 [dir=none]
	1904566216928 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570970560 -> 1904439728768 [dir=none]
	1904439728768 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570970560 -> 1904570945104 [dir=none]
	1904570945104 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570970560 -> 1904566124144 [dir=none]
	1904566124144 [label="weight
 (768)" fillcolor=orange]
	1904570970560 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570969744 -> 1904570970560
	1904570969744 [label="AddBackward0
------------
alpha: 1"]
	1904570969120 -> 1904570969744
	1904570969120 [label="AddBackward0
------------
alpha: 1"]
	1904570968448 -> 1904570969120
	1904570968448 [label="AddBackward0
------------
alpha: 1"]
	1904570968688 -> 1904570968448
	1904570968688 [label="AddBackward0
------------
alpha: 1"]
	1904570968016 -> 1904570968688
	1904570968016 [label="AddBackward0
------------
alpha: 1"]
	1904570967248 -> 1904570968016
	1904570967248 [label="AddBackward0
------------
alpha: 1"]
	1904570966576 -> 1904570967248
	1904570966576 [label="AddBackward0
------------
alpha: 1"]
	1904570966816 -> 1904570966576
	1904570966816 [label="AddBackward0
------------
alpha: 1"]
	1904570966144 -> 1904570966816
	1904570966144 [label="AddBackward0
------------
alpha: 1"]
	1904570965376 -> 1904570966144
	1904570965376 [label="AddBackward0
------------
alpha: 1"]
	1904570964704 -> 1904570965376
	1904570964704 [label="AddBackward0
------------
alpha: 1"]
	1904570964944 -> 1904570964704
	1904570964944 [label="AddBackward0
------------
alpha: 1"]
	1904570964272 -> 1904570964944
	1904570964272 [label="AddBackward0
------------
alpha: 1"]
	1904570963504 -> 1904570964272
	1904570963504 [label="AddBackward0
------------
alpha: 1"]
	1904570962832 -> 1904570963504
	1904570962832 [label="AddBackward0
------------
alpha: 1"]
	1904570963072 -> 1904570962832
	1904570963072 [label="AddBackward0
------------
alpha: 1"]
	1904570962400 -> 1904570963072
	1904570962400 [label="AddBackward0
------------
alpha: 1"]
	1904570961632 -> 1904570962400
	1904570961632 [label="AddBackward0
------------
alpha: 1"]
	1904570960960 -> 1904570961632
	1904570960960 [label="AddBackward0
------------
alpha: 1"]
	1904570961200 -> 1904570960960
	1904570961200 [label="AddBackward0
------------
alpha: 1"]
	1904570960528 -> 1904570961200
	1904570960528 [label="AddBackward0
------------
alpha: 1"]
	1904570959760 -> 1904570960528
	1904570959760 [label="AddBackward0
------------
alpha: 1"]
	1904570959088 -> 1904570959760
	1904570959088 [label="AddBackward0
------------
alpha: 1"]
	1904570959328 -> 1904570959088
	1904570959328 [label="AddBackward0
------------
alpha: 1"]
	1904570958656 -> 1904570959328
	1904570958656 [label="AddBackward0
------------
alpha: 1"]
	1904570958032 -> 1904570958656
	1904570958032 [label="CatBackward0
------------
dim: 1"]
	1904570972288 -> 1904570958032
	1904570972288 [label="ExpandBackward0
---------------------------
self_sym_sizes: (1, 1, 768)"]
	1904570971952 -> 1904570972288
	1903581360464 [label="cls_token
 (1, 1, 768)" fillcolor=lightblue]
	1903581360464 -> 1904570971952
	1904570971952 [label=AccumulateGrad]
	1904570967488 -> 1904570958032
	1904570967488 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	1904570972000 -> 1904570967488
	1904570972000 [label="ReshapeAliasBackward0
--------------------------------
self_sym_sizes: (1, 768, 24, 24)"]
	1904570972096 -> 1904570972000
	1904570972096 -> 1904565984592 [dir=none]
	1904565984592 [label="input
 (1, 3, 384, 384)" fillcolor=orange]
	1904570972096 -> 1903581360304 [dir=none]
	1903581360304 [label="weight
 (768, 3, 16, 16)" fillcolor=orange]
	1904570972096 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (768,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :       (16, 16)
transposed        :          False
weight            : [saved tensor]"]
	1904570971664 -> 1904570972096
	1903581360304 [label="patch_embed.proj.weight
 (768, 3, 16, 16)" fillcolor=lightblue]
	1903581360304 -> 1904570971664
	1904570971664 [label=AccumulateGrad]
	1904570972144 -> 1904570972096
	1903581360384 [label="patch_embed.proj.bias
 (768)" fillcolor=lightblue]
	1903581360384 -> 1904570972144
	1904570972144 [label=AccumulateGrad]
	1904570957888 -> 1904570958656
	1904566231712 [label="pos_embed
 (1, 577, 768)" fillcolor=lightblue]
	1904566231712 -> 1904570957888
	1904570957888 [label=AccumulateGrad]
	1904570958512 -> 1904570959328
	1904570958512 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570972048 -> 1904570958512
	1904570972048 -> 1904439730528 [dir=none]
	1904439730528 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570972048 -> 1904570945664 [dir=none]
	1904570945664 [label="mat2
 (768, 768)" fillcolor=orange]
	1904570972048 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (768, 768)
mat2_sym_strides:       (1, 768)"]
	1904570971904 -> 1904570972048
	1903581359824 [label="blocks.0.attn.proj.bias
 (768)" fillcolor=lightblue]
	1903581359824 -> 1904570971904
	1904570971904 [label=AccumulateGrad]
	1904570958080 -> 1904570972048
	1904570958080 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570971280 -> 1904570958080
	1904570971280 [label="ReshapeAliasBackward0
--------------------------------
self_sym_sizes: (1, 577, 12, 64)"]
	1904570971472 -> 1904570971280
	1904570971472 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	1904570971040 -> 1904570971472
	1904570971040 -> 1904565884928 [dir=none]
	1904565884928 [label="key
 (1, 12, 577, 64)" fillcolor=orange]
	1904570971040 -> 1904565989552 [dir=none]
	1904565989552 [label="query
 (1, 12, 577, 64)" fillcolor=orange]
	1904570971040 -> 1904570945184 [dir=none]
	1904570945184 [label="result0
 (1, 12, 577, 64)" fillcolor=orange]
	1904570971040 -> 1904570945344 [dir=none]
	1904570945344 [label="result1
 (1, 12, 608)" fillcolor=orange]
	1904570971040 -> 1904565887648 [dir=none]
	1904565887648 [label="value
 (1, 12, 577, 64)" fillcolor=orange]
	1904570971040 [label="ScaledDotProductEfficientAttentionBackward0
-------------------------------------------
is_causal:          False
key      : [saved tensor]
query    : [saved tensor]
result0  : [saved tensor]
result1  : [saved tensor]
value    : [saved tensor]"]
	1904570970704 -> 1904570971040
	1904570970704 [label="UnbindBackward0
---------------
dim: 0"]
	1904570970800 -> 1904570970704
	1904570970800 [label="PermuteBackward0
---------------------
dims: (2, 0, 3, 1, 4)"]
	1904570970896 -> 1904570970800
	1904570970896 [label="ReshapeAliasBackward0
------------------------------
self_sym_sizes: (1, 577, 2304)"]
	1904570970416 -> 1904570970896
	1904570970416 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 2304)"]
	1904570970080 -> 1904570970416
	1904570970080 -> 1904570945584 [dir=none]
	1904570945584 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570970080 -> 1904570944864 [dir=none]
	1904570944864 [label="mat2
 (768, 2304)" fillcolor=orange]
	1904570970080 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 2304)
mat2_sym_strides:       (1, 768)"]
	1904570969840 -> 1904570970080
	1903581360224 [label="blocks.0.attn.qkv.bias
 (2304)" fillcolor=lightblue]
	1903581360224 -> 1904570969840
	1904570969840 [label=AccumulateGrad]
	1904570970224 -> 1904570970080
	1904570970224 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570969456 -> 1904570970224
	1904570969456 -> 1903581360064 [dir=none]
	1903581360064 [label="bias
 (768)" fillcolor=orange]
	1904570969456 -> 1904565981232 [dir=none]
	1904565981232 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570969456 -> 1904570944544 [dir=none]
	1904570944544 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570969456 -> 1904570945264 [dir=none]
	1904570945264 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570969456 -> 1903581359424 [dir=none]
	1903581359424 [label="weight
 (768)" fillcolor=orange]
	1904570969456 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570958656 -> 1904570969456
	1904570969168 -> 1904570969456
	1903581359424 [label="blocks.0.norm1.weight
 (768)" fillcolor=lightblue]
	1903581359424 -> 1904570969168
	1904570969168 [label=AccumulateGrad]
	1904570969600 -> 1904570969456
	1903581360064 [label="blocks.0.norm1.bias
 (768)" fillcolor=lightblue]
	1903581360064 -> 1904570969600
	1904570969600 [label=AccumulateGrad]
	1904570970176 -> 1904570970080
	1904570970176 [label=TBackward0]
	1904570969216 -> 1904570970176
	1904439727008 [label="blocks.0.attn.qkv.weight
 (2304, 768)" fillcolor=lightblue]
	1904439727008 -> 1904570969216
	1904570969216 [label=AccumulateGrad]
	1904570970704 -> 1904570971040
	1904570970704 -> 1904570971040
	1904570958704 -> 1904570972048
	1904570958704 [label=TBackward0]
	1904570971520 -> 1904570958704
	1903581360144 [label="blocks.0.attn.proj.weight
 (768, 768)" fillcolor=lightblue]
	1903581360144 -> 1904570971520
	1904570971520 [label=AccumulateGrad]
	1904570959280 -> 1904570959088
	1904570959280 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570971712 -> 1904570959280
	1904570971712 -> 1904570944944 [dir=none]
	1904570944944 [label="mat1
 (577, 3072)" fillcolor=orange]
	1904570971712 -> 1904570945504 [dir=none]
	1904570945504 [label="mat2
 (3072, 768)" fillcolor=orange]
	1904570971712 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :    (577, 3072)
mat1_sym_strides:      (3072, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (3072, 768)
mat2_sym_strides:      (1, 3072)"]
	1904570970752 -> 1904570971712
	1904566262080 [label="blocks.0.mlp.fc2.bias
 (768)" fillcolor=lightblue]
	1904566262080 -> 1904570970752
	1904570970752 [label=AccumulateGrad]
	1904570971424 -> 1904570971712
	1904570971424 [label="ViewBackward0
------------------------------
self_sym_sizes: (1, 577, 3072)"]
	1904570971328 -> 1904570971424
	1904570971328 -> 1904566030864 [dir=none]
	1904566030864 [label="self
 (1, 577, 3072)" fillcolor=orange]
	1904570971328 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	1904570969408 -> 1904570971328
	1904570969408 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 3072)"]
	1904570968832 -> 1904570969408
	1904570968832 -> 1904566159536 [dir=none]
	1904566159536 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570968832 -> 1904570944784 [dir=none]
	1904570944784 [label="mat2
 (768, 3072)" fillcolor=orange]
	1904570968832 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 3072)
mat2_sym_strides:       (1, 768)"]
	1904570969504 -> 1904570968832
	1904566261440 [label="blocks.0.mlp.fc1.bias
 (3072)" fillcolor=lightblue]
	1904566261440 -> 1904570969504
	1904570969504 [label=AccumulateGrad]
	1904570968784 -> 1904570968832
	1904570968784 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570968928 -> 1904570968784
	1904570968928 -> 1903581359984 [dir=none]
	1903581359984 [label="bias
 (768)" fillcolor=orange]
	1904570968928 -> 1904565982192 [dir=none]
	1904565982192 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570968928 -> 1904570944384 [dir=none]
	1904570944384 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570968928 -> 1904570944704 [dir=none]
	1904570944704 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570968928 -> 1904566231312 [dir=none]
	1904566231312 [label="weight
 (768)" fillcolor=orange]
	1904570968928 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570959328 -> 1904570968928
	1904570968592 -> 1904570968928
	1904566231312 [label="blocks.0.norm2.weight
 (768)" fillcolor=lightblue]
	1904566231312 -> 1904570968592
	1904570968592 [label=AccumulateGrad]
	1904570968544 -> 1904570968928
	1903581359984 [label="blocks.0.norm2.bias
 (768)" fillcolor=lightblue]
	1903581359984 -> 1904570968544
	1904570968544 [label=AccumulateGrad]
	1904570971376 -> 1904570968832
	1904570971376 [label=TBackward0]
	1904570968160 -> 1904570971376
	1904566261760 [label="blocks.0.mlp.fc1.weight
 (3072, 768)" fillcolor=lightblue]
	1904566261760 -> 1904570968160
	1904570968160 [label=AccumulateGrad]
	1904570958464 -> 1904570971712
	1904570958464 [label=TBackward0]
	1904570969552 -> 1904570958464
	1904566261600 [label="blocks.0.mlp.fc2.weight
 (768, 3072)" fillcolor=lightblue]
	1904566261600 -> 1904570969552
	1904570969552 [label=AccumulateGrad]
	1904570959952 -> 1904570959760
	1904570959952 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570971088 -> 1904570959952
	1904570971088 -> 1904570945024 [dir=none]
	1904570945024 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570971088 -> 1904570944464 [dir=none]
	1904570944464 [label="mat2
 (768, 768)" fillcolor=orange]
	1904570971088 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (768, 768)
mat2_sym_strides:       (1, 768)"]
	1904570969024 -> 1904570971088
	1904566267920 [label="blocks.1.attn.proj.bias
 (768)" fillcolor=lightblue]
	1904566267920 -> 1904570969024
	1904570969024 [label=AccumulateGrad]
	1904570970032 -> 1904570971088
	1904570970032 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570970848 -> 1904570970032
	1904570970848 [label="ReshapeAliasBackward0
--------------------------------
self_sym_sizes: (1, 577, 12, 64)"]
	1904570968304 -> 1904570970848
	1904570968304 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	1904570968400 -> 1904570968304
	1904570968400 -> 1904566218768 [dir=none]
	1904566218768 [label="key
 (1, 12, 577, 64)" fillcolor=orange]
	1904570968400 -> 1904566210448 [dir=none]
	1904566210448 [label="query
 (1, 12, 577, 64)" fillcolor=orange]
	1904570968400 -> 1904570944624 [dir=none]
	1904570944624 [label="result0
 (1, 12, 577, 64)" fillcolor=orange]
	1904570968400 -> 1904570944304 [dir=none]
	1904570944304 [label="result1
 (1, 12, 608)" fillcolor=orange]
	1904570968400 -> 1904566212768 [dir=none]
	1904566212768 [label="value
 (1, 12, 577, 64)" fillcolor=orange]
	1904570968400 [label="ScaledDotProductEfficientAttentionBackward0
-------------------------------------------
is_causal:          False
key      : [saved tensor]
query    : [saved tensor]
result0  : [saved tensor]
result1  : [saved tensor]
value    : [saved tensor]"]
	1904570967968 -> 1904570968400
	1904570967968 [label="UnbindBackward0
---------------
dim: 0"]
	1904570967584 -> 1904570967968
	1904570967584 [label="PermuteBackward0
---------------------
dims: (2, 0, 3, 1, 4)"]
	1904570967680 -> 1904570967584
	1904570967680 [label="ReshapeAliasBackward0
------------------------------
self_sym_sizes: (1, 577, 2304)"]
	1904570967776 -> 1904570967680
	1904570967776 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 2304)"]
	1904570967344 -> 1904570967776
	1904570967344 -> 1904570943984 [dir=none]
	1904570943984 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570967344 -> 1904570943744 [dir=none]
	1904570943744 [label="mat2
 (768, 2304)" fillcolor=orange]
	1904570967344 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 2304)
mat2_sym_strides:       (1, 768)"]
	1904570966960 -> 1904570967344
	1904566261280 [label="blocks.1.attn.qkv.bias
 (2304)" fillcolor=lightblue]
	1904566261280 -> 1904570966960
	1904570966960 [label=AccumulateGrad]
	1904570966912 -> 1904570967344
	1904570966912 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570967056 -> 1904570966912
	1904570967056 -> 1904566261840 [dir=none]
	1904566261840 [label="bias
 (768)" fillcolor=orange]
	1904570967056 -> 1904566214048 [dir=none]
	1904566214048 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570967056 -> 1904570943904 [dir=none]
	1904570943904 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570967056 -> 1904570944064 [dir=none]
	1904570944064 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570967056 -> 1904566263440 [dir=none]
	1904566263440 [label="weight
 (768)" fillcolor=orange]
	1904570967056 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570959088 -> 1904570967056
	1904570966720 -> 1904570967056
	1904566263440 [label="blocks.1.norm1.weight
 (768)" fillcolor=lightblue]
	1904566263440 -> 1904570966720
	1904570966720 [label=AccumulateGrad]
	1904570966672 -> 1904570967056
	1904566261840 [label="blocks.1.norm1.bias
 (768)" fillcolor=lightblue]
	1904566261840 -> 1904570966672
	1904570966672 [label=AccumulateGrad]
	1904570968208 -> 1904570967344
	1904570968208 [label=TBackward0]
	1904570966288 -> 1904570968208
	1904566260800 [label="blocks.1.attn.qkv.weight
 (2304, 768)" fillcolor=lightblue]
	1904566260800 -> 1904570966288
	1904570966288 [label=AccumulateGrad]
	1904570967968 -> 1904570968400
	1904570967968 -> 1904570968400
	1904570959136 -> 1904570971088
	1904570959136 [label=TBackward0]
	1904570968352 -> 1904570959136
	1904566267440 [label="blocks.1.attn.proj.weight
 (768, 768)" fillcolor=lightblue]
	1904566267440 -> 1904570968352
	1904570968352 [label=AccumulateGrad]
	1904570959712 -> 1904570960528
	1904570959712 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570968880 -> 1904570959712
	1904570968880 -> 1904570944144 [dir=none]
	1904570944144 [label="mat1
 (577, 3072)" fillcolor=orange]
	1904570968880 -> 1904570944224 [dir=none]
	1904570944224 [label="mat2
 (3072, 768)" fillcolor=orange]
	1904570968880 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :    (577, 3072)
mat1_sym_strides:      (3072, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (3072, 768)
mat2_sym_strides:      (1, 3072)"]
	1904570967536 -> 1904570968880
	1904566167936 [label="blocks.1.mlp.fc2.bias
 (768)" fillcolor=lightblue]
	1904566167936 -> 1904570967536
	1904570967536 [label=AccumulateGrad]
	1904570968976 -> 1904570968880
	1904570968976 [label="ViewBackward0
------------------------------
self_sym_sizes: (1, 577, 3072)"]
	1904570968256 -> 1904570968976
	1904570968256 -> 1904566210128 [dir=none]
	1904566210128 [label="self
 (1, 577, 3072)" fillcolor=orange]
	1904570968256 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	1904570967008 -> 1904570968256
	1904570967008 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 3072)"]
	1904570966384 -> 1904570967008
	1904570966384 -> 1904570943664 [dir=none]
	1904570943664 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570966384 -> 1904570943424 [dir=none]
	1904570943424 [label="mat2
 (768, 3072)" fillcolor=orange]
	1904570966384 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 3072)
mat2_sym_strides:       (1, 768)"]
	1904570967104 -> 1904570966384
	1904566162576 [label="blocks.1.mlp.fc1.bias
 (3072)" fillcolor=lightblue]
	1904566162576 -> 1904570967104
	1904570967104 [label=AccumulateGrad]
	1904570966336 -> 1904570966384
	1904570966336 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570966480 -> 1904570966336
	1904570966480 -> 1904566265120 [dir=none]
	1904566265120 [label="bias
 (768)" fillcolor=orange]
	1904570966480 -> 1904566214208 [dir=none]
	1904566214208 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570966480 -> 1904570943504 [dir=none]
	1904570943504 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570966480 -> 1904570943824 [dir=none]
	1904570943824 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570966480 -> 1904566258800 [dir=none]
	1904566258800 [label="weight
 (768)" fillcolor=orange]
	1904570966480 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570959760 -> 1904570966480
	1904570965664 -> 1904570966480
	1904566258800 [label="blocks.1.norm2.weight
 (768)" fillcolor=lightblue]
	1904566258800 -> 1904570965664
	1904570965664 [label=AccumulateGrad]
	1904570966096 -> 1904570966480
	1904566265120 [label="blocks.1.norm2.bias
 (768)" fillcolor=lightblue]
	1904566265120 -> 1904570966096
	1904570966096 [label=AccumulateGrad]
	1904570967728 -> 1904570966384
	1904570967728 [label=TBackward0]
	1904570965760 -> 1904570967728
	1904566166096 [label="blocks.1.mlp.fc1.weight
 (3072, 768)" fillcolor=lightblue]
	1904566166096 -> 1904570965760
	1904570965760 [label=AccumulateGrad]
	1904570959904 -> 1904570968880
	1904570959904 [label=TBackward0]
	1904570967152 -> 1904570959904
	1904566165376 [label="blocks.1.mlp.fc2.weight
 (768, 3072)" fillcolor=lightblue]
	1904566165376 -> 1904570967152
	1904570967152 [label=AccumulateGrad]
	1904570960384 -> 1904570961200
	1904570960384 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570967920 -> 1904570960384
	1904570967920 -> 1904570943584 [dir=none]
	1904570943584 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570967920 -> 1904570943024 [dir=none]
	1904570943024 [label="mat2
 (768, 768)" fillcolor=orange]
	1904570967920 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (768, 768)
mat2_sym_strides:       (1, 768)"]
	1904570966048 -> 1904570967920
	1904566161456 [label="blocks.2.attn.proj.bias
 (768)" fillcolor=lightblue]
	1904566161456 -> 1904570966048
	1904570966048 [label=AccumulateGrad]
	1904570967296 -> 1904570967920
	1904570967296 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570967632 -> 1904570967296
	1904570967632 [label="ReshapeAliasBackward0
--------------------------------
self_sym_sizes: (1, 577, 12, 64)"]
	1904570965904 -> 1904570967632
	1904570965904 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	1904570965472 -> 1904570965904
	1904570965472 -> 1904566209488 [dir=none]
	1904566209488 [label="key
 (1, 12, 577, 64)" fillcolor=orange]
	1904570965472 -> 1904566209648 [dir=none]
	1904566209648 [label="query
 (1, 12, 577, 64)" fillcolor=orange]
	1904570965472 -> 1904570943344 [dir=none]
	1904570943344 [label="result0
 (1, 12, 577, 64)" fillcolor=orange]
	1904570965472 -> 1904570943104 [dir=none]
	1904570943104 [label="result1
 (1, 12, 608)" fillcolor=orange]
	1904570965472 -> 1904566208768 [dir=none]
	1904566208768 [label="value
 (1, 12, 577, 64)" fillcolor=orange]
	1904570965472 [label="ScaledDotProductEfficientAttentionBackward0
-------------------------------------------
is_causal:          False
key      : [saved tensor]
query    : [saved tensor]
result0  : [saved tensor]
result1  : [saved tensor]
value    : [saved tensor]"]
	1904570965088 -> 1904570965472
	1904570965088 [label="UnbindBackward0
---------------
dim: 0"]
	1904570965184 -> 1904570965088
	1904570965184 [label="PermuteBackward0
---------------------
dims: (2, 0, 3, 1, 4)"]
	1904570965280 -> 1904570965184
	1904570965280 [label="ReshapeAliasBackward0
------------------------------
self_sym_sizes: (1, 577, 2304)"]
	1904570964848 -> 1904570965280
	1904570964848 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 2304)"]
	1904570964464 -> 1904570964848
	1904570964464 -> 1904570943264 [dir=none]
	1904570943264 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570964464 -> 1904570942864 [dir=none]
	1904570942864 [label="mat2
 (768, 2304)" fillcolor=orange]
	1904570964464 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 2304)
mat2_sym_strides:       (1, 768)"]
	1904570964560 -> 1904570964464
	1904566162176 [label="blocks.2.attn.qkv.bias
 (2304)" fillcolor=lightblue]
	1904566162176 -> 1904570964560
	1904570964560 [label=AccumulateGrad]
	1904570964512 -> 1904570964464
	1904570964512 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570964656 -> 1904570964512
	1904570964656 -> 1904566167536 [dir=none]
	1904566167536 [label="bias
 (768)" fillcolor=orange]
	1904570964656 -> 1904566209168 [dir=none]
	1904566209168 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570964656 -> 1904570942544 [dir=none]
	1904570942544 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570964656 -> 1904570943184 [dir=none]
	1904570943184 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570964656 -> 1904566173456 [dir=none]
	1904566173456 [label="weight
 (768)" fillcolor=orange]
	1904570964656 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570960528 -> 1904570964656
	1904570963840 -> 1904570964656
	1904566173456 [label="blocks.2.norm1.weight
 (768)" fillcolor=lightblue]
	1904566173456 -> 1904570963840
	1904570963840 [label=AccumulateGrad]
	1904570963792 -> 1904570964656
	1904566167536 [label="blocks.2.norm1.bias
 (768)" fillcolor=lightblue]
	1904566167536 -> 1904570963792
	1904570963792 [label=AccumulateGrad]
	1904570965808 -> 1904570964464
	1904570965808 [label=TBackward0]
	1904570963888 -> 1904570965808
	1904566167456 [label="blocks.2.attn.qkv.weight
 (2304, 768)" fillcolor=lightblue]
	1904566167456 -> 1904570963888
	1904570963888 [label=AccumulateGrad]
	1904570965088 -> 1904570965472
	1904570965088 -> 1904570965472
	1904570960576 -> 1904570967920
	1904570960576 [label=TBackward0]
	1904570965424 -> 1904570960576
	1904566170496 [label="blocks.2.attn.proj.weight
 (768, 768)" fillcolor=lightblue]
	1904566170496 -> 1904570965424
	1904570965424 [label=AccumulateGrad]
	1904570961152 -> 1904570960960
	1904570961152 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570966432 -> 1904570961152
	1904570966432 -> 1904570942784 [dir=none]
	1904570942784 [label="mat1
 (577, 3072)" fillcolor=orange]
	1904570966432 -> 1904570942704 [dir=none]
	1904570942704 [label="mat2
 (3072, 768)" fillcolor=orange]
	1904570966432 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :    (577, 3072)
mat1_sym_strides:      (3072, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (3072, 768)
mat2_sym_strides:      (1, 3072)"]
	1904570965136 -> 1904570966432
	1904566163136 [label="blocks.2.mlp.fc2.bias
 (768)" fillcolor=lightblue]
	1904566163136 -> 1904570965136
	1904570965136 [label=AccumulateGrad]
	1904570966528 -> 1904570966432
	1904570966528 [label="ViewBackward0
------------------------------
self_sym_sizes: (1, 577, 3072)"]
	1904570965856 -> 1904570966528
	1904570965856 -> 1904566211168 [dir=none]
	1904566211168 [label="self
 (1, 577, 3072)" fillcolor=orange]
	1904570965856 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	1904570964608 -> 1904570965856
	1904570964608 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 3072)"]
	1904570963984 -> 1904570964608
	1904570963984 -> 1904570942944 [dir=none]
	1904570942944 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570963984 -> 1904570942144 [dir=none]
	1904570942144 [label="mat2
 (768, 3072)" fillcolor=orange]
	1904570963984 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 3072)
mat2_sym_strides:       (1, 768)"]
	1904570964176 -> 1904570963984
	1904566158096 [label="blocks.2.mlp.fc1.bias
 (3072)" fillcolor=lightblue]
	1904566158096 -> 1904570964176
	1904570964176 [label=AccumulateGrad]
	1904570963936 -> 1904570963984
	1904570963936 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570963552 -> 1904570963936
	1904570963552 -> 1904566171616 [dir=none]
	1904566171616 [label="bias
 (768)" fillcolor=orange]
	1904570963552 -> 1904566209328 [dir=none]
	1904566209328 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570963552 -> 1904570942384 [dir=none]
	1904570942384 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570963552 -> 1904570942624 [dir=none]
	1904570942624 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570963552 -> 1904566171216 [dir=none]
	1904566171216 [label="weight
 (768)" fillcolor=orange]
	1904570963552 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570961200 -> 1904570963552
	1904570963264 -> 1904570963552
	1904566171216 [label="blocks.2.norm2.weight
 (768)" fillcolor=lightblue]
	1904566171216 -> 1904570963264
	1904570963264 [label=AccumulateGrad]
	1904570963216 -> 1904570963552
	1904566171616 [label="blocks.2.norm2.bias
 (768)" fillcolor=lightblue]
	1904566171616 -> 1904570963216
	1904570963216 [label=AccumulateGrad]
	1904570964800 -> 1904570963984
	1904570964800 [label=TBackward0]
	1904570963312 -> 1904570964800
	1904566164256 [label="blocks.2.mlp.fc1.weight
 (3072, 768)" fillcolor=lightblue]
	1904566164256 -> 1904570963312
	1904570963312 [label=AccumulateGrad]
	1904570960336 -> 1904570966432
	1904570960336 [label=TBackward0]
	1904570964224 -> 1904570960336
	1904566164576 [label="blocks.2.mlp.fc2.weight
 (768, 3072)" fillcolor=lightblue]
	1904566164576 -> 1904570964224
	1904570964224 [label=AccumulateGrad]
	1904570961824 -> 1904570961632
	1904570961824 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570965040 -> 1904570961824
	1904570965040 -> 1904570942224 [dir=none]
	1904570942224 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570965040 -> 1904570942304 [dir=none]
	1904570942304 [label="mat2
 (768, 768)" fillcolor=orange]
	1904570965040 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (768, 768)
mat2_sym_strides:       (1, 768)"]
	1904570963168 -> 1904570965040
	1904566160096 [label="blocks.3.attn.proj.bias
 (768)" fillcolor=lightblue]
	1904566160096 -> 1904570963168
	1904570963168 [label=AccumulateGrad]
	1904570964416 -> 1904570965040
	1904570964416 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570965232 -> 1904570964416
	1904570965232 [label="ReshapeAliasBackward0
--------------------------------
self_sym_sizes: (1, 577, 12, 64)"]
	1904570962928 -> 1904570965232
	1904570962928 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	1904570962544 -> 1904570962928
	1904570962544 -> 1904566209408 [dir=none]
	1904566209408 [label="key
 (1, 12, 577, 64)" fillcolor=orange]
	1904570962544 -> 1904566210368 [dir=none]
	1904566210368 [label="query
 (1, 12, 577, 64)" fillcolor=orange]
	1904570962544 -> 1904570942464 [dir=none]
	1904570942464 [label="result0
 (1, 12, 577, 64)" fillcolor=orange]
	1904570962544 -> 1904570941984 [dir=none]
	1904570941984 [label="result1
 (1, 12, 608)" fillcolor=orange]
	1904570962544 -> 1904566207408 [dir=none]
	1904566207408 [label="value
 (1, 12, 577, 64)" fillcolor=orange]
	1904570962544 [label="ScaledDotProductEfficientAttentionBackward0
-------------------------------------------
is_causal:          False
key      : [saved tensor]
query    : [saved tensor]
result0  : [saved tensor]
result1  : [saved tensor]
value    : [saved tensor]"]
	1904570962640 -> 1904570962544
	1904570962640 [label="UnbindBackward0
---------------
dim: 0"]
	1904570962736 -> 1904570962640
	1904570962736 [label="PermuteBackward0
---------------------
dims: (2, 0, 3, 1, 4)"]
	1904570962304 -> 1904570962736
	1904570962304 [label="ReshapeAliasBackward0
------------------------------
self_sym_sizes: (1, 577, 2304)"]
	1904570961920 -> 1904570962304
	1904570961920 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 2304)"]
	1904570962016 -> 1904570961920
	1904570962016 -> 1904570942064 [dir=none]
	1904570942064 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570962016 -> 1904570941744 [dir=none]
	1904570941744 [label="mat2
 (768, 2304)" fillcolor=orange]
	1904570962016 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 2304)
mat2_sym_strides:       (1, 768)"]
	1904570962112 -> 1904570962016
	1904566170176 [label="blocks.3.attn.qkv.bias
 (2304)" fillcolor=lightblue]
	1904566170176 -> 1904570962112
	1904570962112 [label=AccumulateGrad]
	1904570962064 -> 1904570962016
	1904570962064 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570961680 -> 1904570962064
	1904570961680 -> 1904566164896 [dir=none]
	1904566164896 [label="bias
 (768)" fillcolor=orange]
	1904570961680 -> 1904566208688 [dir=none]
	1904566208688 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570961680 -> 1904570941504 [dir=none]
	1904570941504 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570961680 -> 1904570941904 [dir=none]
	1904570941904 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570961680 -> 1904566162496 [dir=none]
	1904566162496 [label="weight
 (768)" fillcolor=orange]
	1904570961680 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570960960 -> 1904570961680
	1904570961392 -> 1904570961680
	1904566162496 [label="blocks.3.norm1.weight
 (768)" fillcolor=lightblue]
	1904566162496 -> 1904570961392
	1904570961392 [label=AccumulateGrad]
	1904570961344 -> 1904570961680
	1904566164896 [label="blocks.3.norm1.bias
 (768)" fillcolor=lightblue]
	1904566164896 -> 1904570961344
	1904570961344 [label=AccumulateGrad]
	1904570963360 -> 1904570962016
	1904570963360 [label=TBackward0]
	1904570961440 -> 1904570963360
	1904566169616 [label="blocks.3.attn.qkv.weight
 (2304, 768)" fillcolor=lightblue]
	1904566169616 -> 1904570961440
	1904570961440 [label=AccumulateGrad]
	1904570962640 -> 1904570962544
	1904570962640 -> 1904570962544
	1904570961008 -> 1904570965040
	1904570961008 [label=TBackward0]
	1904570962976 -> 1904570961008
	1904566163456 [label="blocks.3.attn.proj.weight
 (768, 768)" fillcolor=lightblue]
	1904566163456 -> 1904570962976
	1904570962976 [label=AccumulateGrad]
	1904570961584 -> 1904570962400
	1904570961584 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570964032 -> 1904570961584
	1904570964032 -> 1904570941664 [dir=none]
	1904570941664 [label="mat1
 (577, 3072)" fillcolor=orange]
	1904570964032 -> 1904570941584 [dir=none]
	1904570941584 [label="mat2
 (3072, 768)" fillcolor=orange]
	1904570964032 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :    (577, 3072)
mat1_sym_strides:      (3072, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (3072, 768)
mat2_sym_strides:      (1, 3072)"]
	1904570962688 -> 1904570964032
	1904566169056 [label="blocks.3.mlp.fc2.bias
 (768)" fillcolor=lightblue]
	1904566169056 -> 1904570962688
	1904570962688 [label=AccumulateGrad]
	1904570963600 -> 1904570964032
	1904570963600 [label="ViewBackward0
------------------------------
self_sym_sizes: (1, 577, 3072)"]
	1904570963408 -> 1904570963600
	1904570963408 -> 1904566208048 [dir=none]
	1904566208048 [label="self
 (1, 577, 3072)" fillcolor=orange]
	1904570963408 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	1904570962160 -> 1904570963408
	1904570962160 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 3072)"]
	1904570961536 -> 1904570962160
	1904570961536 -> 1904570941824 [dir=none]
	1904570941824 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570961536 -> 1904570955344 [dir=none]
	1904570955344 [label="mat2
 (768, 3072)" fillcolor=orange]
	1904570961536 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 3072)
mat2_sym_strides:       (1, 768)"]
	1904570961728 -> 1904570961536
	1904566165216 [label="blocks.3.mlp.fc1.bias
 (3072)" fillcolor=lightblue]
	1904566165216 -> 1904570961728
	1904570961728 [label=AccumulateGrad]
	1904570961488 -> 1904570961536
	1904570961488 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570961104 -> 1904570961488
	1904570961104 -> 1904566160416 [dir=none]
	1904566160416 [label="bias
 (768)" fillcolor=orange]
	1904570961104 -> 1904566209728 [dir=none]
	1904566209728 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570961104 -> 1904570580432 [dir=none]
	1904570580432 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570961104 -> 1904570580752 [dir=none]
	1904570580752 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570961104 -> 1904566166416 [dir=none]
	1904566166416 [label="weight
 (768)" fillcolor=orange]
	1904570961104 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570961632 -> 1904570961104
	1904570960816 -> 1904570961104
	1904566166416 [label="blocks.3.norm2.weight
 (768)" fillcolor=lightblue]
	1904566166416 -> 1904570960816
	1904570960816 [label=AccumulateGrad]
	1904570960768 -> 1904570961104
	1904566160416 [label="blocks.3.norm2.bias
 (768)" fillcolor=lightblue]
	1904566160416 -> 1904570960768
	1904570960768 [label=AccumulateGrad]
	1904570962352 -> 1904570961536
	1904570962352 [label=TBackward0]
	1904570960864 -> 1904570962352
	1904566159776 [label="blocks.3.mlp.fc1.weight
 (3072, 768)" fillcolor=lightblue]
	1904566159776 -> 1904570960864
	1904570960864 [label=AccumulateGrad]
	1904570961776 -> 1904570964032
	1904570961776 [label=TBackward0]
	1904570961296 -> 1904570961776
	1904566161136 [label="blocks.3.mlp.fc2.weight
 (768, 3072)" fillcolor=lightblue]
	1904566161136 -> 1904570961296
	1904570961296 [label=AccumulateGrad]
	1904570962256 -> 1904570963072
	1904570962256 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570962592 -> 1904570962256
	1904570962592 -> 1904570580912 [dir=none]
	1904570580912 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570962592 -> 1904570580512 [dir=none]
	1904570580512 [label="mat2
 (768, 768)" fillcolor=orange]
	1904570962592 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (768, 768)
mat2_sym_strides:       (1, 768)"]
	1904570960720 -> 1904570962592
	1904566166736 [label="blocks.4.attn.proj.bias
 (768)" fillcolor=lightblue]
	1904566166736 -> 1904570960720
	1904570960720 [label=AccumulateGrad]
	1904570961968 -> 1904570962592
	1904570961968 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570962784 -> 1904570961968
	1904570962784 [label="ReshapeAliasBackward0
--------------------------------
self_sym_sizes: (1, 577, 12, 64)"]
	1904570960480 -> 1904570962784
	1904570960480 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	1904570960096 -> 1904570960480
	1904570960096 -> 1904566207168 [dir=none]
	1904566207168 [label="key
 (1, 12, 577, 64)" fillcolor=orange]
	1904570960096 -> 1904566207008 [dir=none]
	1904566207008 [label="query
 (1, 12, 577, 64)" fillcolor=orange]
	1904570960096 -> 1904570580832 [dir=none]
	1904570580832 [label="result0
 (1, 12, 577, 64)" fillcolor=orange]
	1904570960096 -> 1904570580672 [dir=none]
	1904570580672 [label="result1
 (1, 12, 608)" fillcolor=orange]
	1904570960096 -> 1904566206848 [dir=none]
	1904566206848 [label="value
 (1, 12, 577, 64)" fillcolor=orange]
	1904570960096 [label="ScaledDotProductEfficientAttentionBackward0
-------------------------------------------
is_causal:          False
key      : [saved tensor]
query    : [saved tensor]
result0  : [saved tensor]
result1  : [saved tensor]
value    : [saved tensor]"]
	1904570960192 -> 1904570960096
	1904570960192 [label="UnbindBackward0
---------------
dim: 0"]
	1904570960288 -> 1904570960192
	1904570960288 [label="PermuteBackward0
---------------------
dims: (2, 0, 3, 1, 4)"]
	1904570959856 -> 1904570960288
	1904570959856 [label="ReshapeAliasBackward0
------------------------------
self_sym_sizes: (1, 577, 2304)"]
	1904570959472 -> 1904570959856
	1904570959472 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 2304)"]
	1904570959568 -> 1904570959472
	1904570959568 -> 1904570580592 [dir=none]
	1904570580592 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570959568 -> 1904570580192 [dir=none]
	1904570580192 [label="mat2
 (768, 2304)" fillcolor=orange]
	1904570959568 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 2304)
mat2_sym_strides:       (1, 768)"]
	1904570959664 -> 1904570959568
	1904566166816 [label="blocks.4.attn.qkv.bias
 (2304)" fillcolor=lightblue]
	1904566166816 -> 1904570959664
	1904570959664 [label=AccumulateGrad]
	1904570959616 -> 1904570959568
	1904570959616 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570959232 -> 1904570959616
	1904570959232 -> 1904566160176 [dir=none]
	1904566160176 [label="bias
 (768)" fillcolor=orange]
	1904570959232 -> 1904566207728 [dir=none]
	1904566207728 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570959232 -> 1904570580112 [dir=none]
	1904570580112 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570959232 -> 1904570580352 [dir=none]
	1904570580352 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570959232 -> 1904566163616 [dir=none]
	1904566163616 [label="weight
 (768)" fillcolor=orange]
	1904570959232 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570962400 -> 1904570959232
	1904570958944 -> 1904570959232
	1904566163616 [label="blocks.4.norm1.weight
 (768)" fillcolor=lightblue]
	1904566163616 -> 1904570958944
	1904570958944 [label=AccumulateGrad]
	1904570958896 -> 1904570959232
	1904566160176 [label="blocks.4.norm1.bias
 (768)" fillcolor=lightblue]
	1904566160176 -> 1904570958896
	1904570958896 [label=AccumulateGrad]
	1904570960912 -> 1904570959568
	1904570960912 [label=TBackward0]
	1904570958992 -> 1904570960912
	1904566173536 [label="blocks.4.attn.qkv.weight
 (2304, 768)" fillcolor=lightblue]
	1904566173536 -> 1904570958992
	1904570958992 [label=AccumulateGrad]
	1904570960192 -> 1904570960096
	1904570960192 -> 1904570960096
	1904570962448 -> 1904570962592
	1904570962448 [label=TBackward0]
	1904570960048 -> 1904570962448
	1904566165296 [label="blocks.4.attn.proj.weight
 (768, 768)" fillcolor=lightblue]
	1904566165296 -> 1904570960048
	1904570960048 [label=AccumulateGrad]
	1904570963024 -> 1904570962832
	1904570963024 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570961056 -> 1904570963024
	1904570961056 -> 1904570579952 [dir=none]
	1904570579952 [label="mat1
 (577, 3072)" fillcolor=orange]
	1904570961056 -> 1904570580272 [dir=none]
	1904570580272 [label="mat2
 (3072, 768)" fillcolor=orange]
	1904570961056 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :    (577, 3072)
mat1_sym_strides:      (3072, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (3072, 768)
mat2_sym_strides:      (1, 3072)"]
	1904570960240 -> 1904570961056
	1904566162336 [label="blocks.4.mlp.fc2.bias
 (768)" fillcolor=lightblue]
	1904566162336 -> 1904570960240
	1904570960240 [label=AccumulateGrad]
	1904570960672 -> 1904570961056
	1904570960672 [label="ViewBackward0
------------------------------
self_sym_sizes: (1, 577, 3072)"]
	1904570960432 -> 1904570960672
	1904570960432 -> 1904566207808 [dir=none]
	1904566207808 [label="self
 (1, 577, 3072)" fillcolor=orange]
	1904570960432 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	1904570959184 -> 1904570960432
	1904570959184 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 3072)"]
	1904570958560 -> 1904570959184
	1904570958560 -> 1904570580032 [dir=none]
	1904570580032 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570958560 -> 1904570579712 [dir=none]
	1904570579712 [label="mat2
 (768, 3072)" fillcolor=orange]
	1904570958560 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 3072)
mat2_sym_strides:       (1, 768)"]
	1904570958800 -> 1904570958560
	1904566159056 [label="blocks.4.mlp.fc1.bias
 (3072)" fillcolor=lightblue]
	1904566159056 -> 1904570958800
	1904570958800 [label=AccumulateGrad]
	1904570959040 -> 1904570958560
	1904570959040 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570958176 -> 1904570959040
	1904570958176 -> 1904566168256 [dir=none]
	1904566168256 [label="bias
 (768)" fillcolor=orange]
	1904570958176 -> 1904566207088 [dir=none]
	1904566207088 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570958176 -> 1904570579472 [dir=none]
	1904570579472 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570958176 -> 1904570579792 [dir=none]
	1904570579792 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570958176 -> 1904566157696 [dir=none]
	1904566157696 [label="weight
 (768)" fillcolor=orange]
	1904570958176 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570963072 -> 1904570958176
	1904570958368 -> 1904570958176
	1904566157696 [label="blocks.4.norm2.weight
 (768)" fillcolor=lightblue]
	1904566157696 -> 1904570958368
	1904570958368 [label=AccumulateGrad]
	1904570958320 -> 1904570958176
	1904566168256 [label="blocks.4.norm2.bias
 (768)" fillcolor=lightblue]
	1904566168256 -> 1904570958320
	1904570958320 [label=AccumulateGrad]
	1904570959424 -> 1904570958560
	1904570959424 [label=TBackward0]
	1904570958416 -> 1904570959424
	1904566169536 [label="blocks.4.mlp.fc1.weight
 (3072, 768)" fillcolor=lightblue]
	1904566169536 -> 1904570958416
	1904570958416 [label=AccumulateGrad]
	1904570962208 -> 1904570961056
	1904570962208 [label=TBackward0]
	1904570958848 -> 1904570962208
	1904566161616 [label="blocks.4.mlp.fc2.weight
 (768, 3072)" fillcolor=lightblue]
	1904566161616 -> 1904570958848
	1904570958848 [label=AccumulateGrad]
	1904570963696 -> 1904570963504
	1904570963696 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570960144 -> 1904570963696
	1904570960144 -> 1904570579392 [dir=none]
	1904570579392 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570960144 -> 1904570579632 [dir=none]
	1904570579632 [label="mat2
 (768, 768)" fillcolor=orange]
	1904570960144 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (768, 768)
mat2_sym_strides:       (1, 768)"]
	1904570958272 -> 1904570960144
	1904566160336 [label="blocks.5.attn.proj.bias
 (768)" fillcolor=lightblue]
	1904566160336 -> 1904570958272
	1904570958272 [label=AccumulateGrad]
	1904570959520 -> 1904570960144
	1904570959520 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570959808 -> 1904570959520
	1904570959808 [label="ReshapeAliasBackward0
--------------------------------
self_sym_sizes: (1, 577, 12, 64)"]
	1904570958224 -> 1904570959808
	1904570958224 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	1904570875280 -> 1904570958224
	1904570875280 -> 1904566208128 [dir=none]
	1904566208128 [label="key
 (1, 12, 577, 64)" fillcolor=orange]
	1904570875280 -> 1904566208288 [dir=none]
	1904566208288 [label="query
 (1, 12, 577, 64)" fillcolor=orange]
	1904570875280 -> 1904570579872 [dir=none]
	1904570579872 [label="result0
 (1, 12, 577, 64)" fillcolor=orange]
	1904570875280 -> 1904570579552 [dir=none]
	1904570579552 [label="result1
 (1, 12, 608)" fillcolor=orange]
	1904570875280 -> 1904566222528 [dir=none]
	1904566222528 [label="value
 (1, 12, 577, 64)" fillcolor=orange]
	1904570875280 [label="ScaledDotProductEfficientAttentionBackward0
-------------------------------------------
is_causal:          False
key      : [saved tensor]
query    : [saved tensor]
result0  : [saved tensor]
result1  : [saved tensor]
value    : [saved tensor]"]
	1904570875472 -> 1904570875280
	1904570875472 [label="UnbindBackward0
---------------
dim: 0"]
	1904570874656 -> 1904570875472
	1904570874656 [label="PermuteBackward0
---------------------
dims: (2, 0, 3, 1, 4)"]
	1904570874848 -> 1904570874656
	1904570874848 [label="ReshapeAliasBackward0
------------------------------
self_sym_sizes: (1, 577, 2304)"]
	1904570874032 -> 1904570874848
	1904570874032 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 2304)"]
	1904570874224 -> 1904570874032
	1904570874224 -> 1904570579072 [dir=none]
	1904570579072 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570874224 -> 1904570578832 [dir=none]
	1904570578832 [label="mat2
 (768, 2304)" fillcolor=orange]
	1904570874224 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 2304)
mat2_sym_strides:       (1, 768)"]
	1904570873408 -> 1904570874224
	1904566158816 [label="blocks.5.attn.qkv.bias
 (2304)" fillcolor=lightblue]
	1904566158816 -> 1904570873408
	1904570873408 [label=AccumulateGrad]
	1904570873360 -> 1904570874224
	1904570873360 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570873600 -> 1904570873360
	1904570873600 -> 1904566165136 [dir=none]
	1904566165136 [label="bias
 (768)" fillcolor=orange]
	1904570873600 -> 1904566222448 [dir=none]
	1904566222448 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570873600 -> 1904570578992 [dir=none]
	1904570578992 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570873600 -> 1904570579152 [dir=none]
	1904570579152 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570873600 -> 1904566159376 [dir=none]
	1904566159376 [label="weight
 (768)" fillcolor=orange]
	1904570873600 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570962832 -> 1904570873600
	1904570872976 -> 1904570873600
	1904566159376 [label="blocks.5.norm1.weight
 (768)" fillcolor=lightblue]
	1904566159376 -> 1904570872976
	1904570872976 [label=AccumulateGrad]
	1904570872928 -> 1904570873600
	1904566165136 [label="blocks.5.norm1.bias
 (768)" fillcolor=lightblue]
	1904566165136 -> 1904570872928
	1904570872928 [label=AccumulateGrad]
	1904570875856 -> 1904570874224
	1904570875856 [label=TBackward0]
	1904570872112 -> 1904570875856
	1904566158656 [label="blocks.5.attn.qkv.weight
 (2304, 768)" fillcolor=lightblue]
	1904566158656 -> 1904570872112
	1904570872112 [label=AccumulateGrad]
	1904570875472 -> 1904570875280
	1904570875472 -> 1904570875280
	1904570962880 -> 1904570960144
	1904570962880 [label=TBackward0]
	1904570957936 -> 1904570962880
	1904566158736 [label="blocks.5.attn.proj.weight
 (768, 768)" fillcolor=lightblue]
	1904566158736 -> 1904570957936
	1904570957936 [label=AccumulateGrad]
	1904570963456 -> 1904570964272
	1904570963456 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570958608 -> 1904570963456
	1904570958608 -> 1904570579232 [dir=none]
	1904570579232 [label="mat1
 (577, 3072)" fillcolor=orange]
	1904570958608 -> 1904570579312 [dir=none]
	1904570579312 [label="mat2
 (3072, 768)" fillcolor=orange]
	1904570958608 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :    (577, 3072)
mat1_sym_strides:      (3072, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (3072, 768)
mat2_sym_strides:      (1, 3072)"]
	1904570957984 -> 1904570958608
	1904566165696 [label="blocks.5.mlp.fc2.bias
 (768)" fillcolor=lightblue]
	1904566165696 -> 1904570957984
	1904570957984 [label=AccumulateGrad]
	1904570963648 -> 1904570958608
	1904570963648 [label="ViewBackward0
------------------------------
self_sym_sizes: (1, 577, 3072)"]
	1904570875232 -> 1904570963648
	1904570875232 -> 1904566221968 [dir=none]
	1904566221968 [label="self
 (1, 577, 3072)" fillcolor=orange]
	1904570875232 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	1904570873552 -> 1904570875232
	1904570873552 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 3072)"]
	1904570872304 -> 1904570873552
	1904570872304 -> 1904570578752 [dir=none]
	1904570578752 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570872304 -> 1904570578512 [dir=none]
	1904570578512 [label="mat2
 (768, 3072)" fillcolor=orange]
	1904570872304 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 3072)
mat2_sym_strides:       (1, 768)"]
	1904570872736 -> 1904570872304
	1904566164976 [label="blocks.5.mlp.fc1.bias
 (3072)" fillcolor=lightblue]
	1904566164976 -> 1904570872736
	1904570872736 [label=AccumulateGrad]
	1904570872160 -> 1904570872304
	1904570872160 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570871488 -> 1904570872160
	1904570871488 -> 1904566173616 [dir=none]
	1904566173616 [label="bias
 (768)" fillcolor=orange]
	1904570871488 -> 1904566207968 [dir=none]
	1904566207968 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570871488 -> 1904570578592 [dir=none]
	1904570578592 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570871488 -> 1904570578912 [dir=none]
	1904570578912 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570871488 -> 1904566165856 [dir=none]
	1904566165856 [label="weight
 (768)" fillcolor=orange]
	1904570871488 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570963504 -> 1904570871488
	1904570870864 -> 1904570871488
	1904566165856 [label="blocks.5.norm2.weight
 (768)" fillcolor=lightblue]
	1904566165856 -> 1904570870864
	1904570870864 [label=AccumulateGrad]
	1904570871728 -> 1904570871488
	1904566173616 [label="blocks.5.norm2.bias
 (768)" fillcolor=lightblue]
	1904566173616 -> 1904570871728
	1904570871728 [label=AccumulateGrad]
	1904570873984 -> 1904570872304
	1904570873984 [label=TBackward0]
	1904570870912 -> 1904570873984
	1904566162976 [label="blocks.5.mlp.fc1.weight
 (3072, 768)" fillcolor=lightblue]
	1904566162976 -> 1904570870912
	1904570870912 [label=AccumulateGrad]
	1904570874608 -> 1904570958608
	1904570874608 [label=TBackward0]
	1904570872352 -> 1904570874608
	1904566165536 [label="blocks.5.mlp.fc2.weight
 (768, 3072)" fillcolor=lightblue]
	1904566165536 -> 1904570872352
	1904570872352 [label=AccumulateGrad]
	1904570964128 -> 1904570964944
	1904570964128 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570972336 -> 1904570964128
	1904570972336 -> 1904570578672 [dir=none]
	1904570578672 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570972336 -> 1904570578352 [dir=none]
	1904570578352 [label="mat2
 (768, 768)" fillcolor=orange]
	1904570972336 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (768, 768)
mat2_sym_strides:       (1, 768)"]
	1904570871104 -> 1904570972336
	1904566160656 [label="blocks.6.attn.proj.bias
 (768)" fillcolor=lightblue]
	1904566160656 -> 1904570871104
	1904570871104 [label=AccumulateGrad]
	1904570872784 -> 1904570972336
	1904570872784 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570874176 -> 1904570872784
	1904570874176 [label="ReshapeAliasBackward0
--------------------------------
self_sym_sizes: (1, 577, 12, 64)"]
	1904570870288 -> 1904570874176
	1904570870288 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	1904570870480 -> 1904570870288
	1904570870480 -> 1904566219408 [dir=none]
	1904566219408 [label="key
 (1, 12, 577, 64)" fillcolor=orange]
	1904570870480 -> 1904566219728 [dir=none]
	1904566219728 [label="query
 (1, 12, 577, 64)" fillcolor=orange]
	1904570870480 -> 1904570578432 [dir=none]
	1904570578432 [label="result0
 (1, 12, 577, 64)" fillcolor=orange]
	1904570870480 -> 1904570578272 [dir=none]
	1904570578272 [label="result1
 (1, 12, 608)" fillcolor=orange]
	1904570870480 -> 1904566220048 [dir=none]
	1904566220048 [label="value
 (1, 12, 577, 64)" fillcolor=orange]
	1904570870480 [label="ScaledDotProductEfficientAttentionBackward0
-------------------------------------------
is_causal:          False
key      : [saved tensor]
query    : [saved tensor]
result0  : [saved tensor]
result1  : [saved tensor]
value    : [saved tensor]"]
	1904570869664 -> 1904570870480
	1904570869664 [label="UnbindBackward0
---------------
dim: 0"]
	1904570869856 -> 1904570869664
	1904570869856 [label="PermuteBackward0
---------------------
dims: (2, 0, 3, 1, 4)"]
	1904570869040 -> 1904570869856
	1904570869040 [label="ReshapeAliasBackward0
------------------------------
self_sym_sizes: (1, 577, 2304)"]
	1904570869232 -> 1904570869040
	1904570869232 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 2304)"]
	1904570868416 -> 1904570869232
	1904570868416 -> 1904570578032 [dir=none]
	1904570578032 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570868416 -> 1904570577952 [dir=none]
	1904570577952 [label="mat2
 (768, 2304)" fillcolor=orange]
	1904570868416 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 2304)
mat2_sym_strides:       (1, 768)"]
	1904570868608 -> 1904570868416
	1904566161856 [label="blocks.6.attn.qkv.bias
 (2304)" fillcolor=lightblue]
	1904566161856 -> 1904570868608
	1904570868608 [label=AccumulateGrad]
	1904570868560 -> 1904570868416
	1904570868560 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570867792 -> 1904570868560
	1904570867792 -> 1904566159936 [dir=none]
	1904566159936 [label="bias
 (768)" fillcolor=orange]
	1904570867792 -> 1904566221328 [dir=none]
	1904566221328 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570867792 -> 1904570577472 [dir=none]
	1904570577472 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570867792 -> 1904570578192 [dir=none]
	1904570578192 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570867792 -> 1904566167616 [dir=none]
	1904566167616 [label="weight
 (768)" fillcolor=orange]
	1904570867792 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570964272 -> 1904570867792
	1904570867168 -> 1904570867792
	1904566167616 [label="blocks.6.norm1.weight
 (768)" fillcolor=lightblue]
	1904566167616 -> 1904570867168
	1904570867168 [label=AccumulateGrad]
	1904570867120 -> 1904570867792
	1904566159936 [label="blocks.6.norm1.bias
 (768)" fillcolor=lightblue]
	1904566159936 -> 1904570867120
	1904570867120 [label=AccumulateGrad]
	1904570871536 -> 1904570868416
	1904570871536 [label=TBackward0]
	1904570867312 -> 1904570871536
	1904566163936 [label="blocks.6.attn.qkv.weight
 (2304, 768)" fillcolor=lightblue]
	1904566163936 -> 1904570867312
	1904570867312 [label=AccumulateGrad]
	1904570869664 -> 1904570870480
	1904570869664 -> 1904570870480
	1904570875424 -> 1904570972336
	1904570875424 [label=TBackward0]
	1904570870432 -> 1904570875424
	1904566159456 [label="blocks.6.attn.proj.weight
 (768, 768)" fillcolor=lightblue]
	1904566159456 -> 1904570870432
	1904570870432 [label=AccumulateGrad]
	1904570964896 -> 1904570964704
	1904570964896 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570964320 -> 1904570964896
	1904570964320 -> 1904570577792 [dir=none]
	1904570577792 [label="mat1
 (577, 3072)" fillcolor=orange]
	1904570964320 -> 1904570578112 [dir=none]
	1904570578112 [label="mat2
 (3072, 768)" fillcolor=orange]
	1904570964320 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :    (577, 3072)
mat1_sym_strides:      (3072, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (3072, 768)
mat2_sym_strides:      (1, 3072)"]
	1904570869808 -> 1904570964320
	1904566160256 [label="blocks.6.mlp.fc2.bias
 (768)" fillcolor=lightblue]
	1904566160256 -> 1904570869808
	1904570869808 [label=AccumulateGrad]
	1904570870240 -> 1904570964320
	1904570870240 [label="ViewBackward0
------------------------------
self_sym_sizes: (1, 577, 3072)"]
	1904570871056 -> 1904570870240
	1904570871056 -> 1904566218048 [dir=none]
	1904566218048 [label="self
 (1, 577, 3072)" fillcolor=orange]
	1904570871056 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	1904570867744 -> 1904570871056
	1904570867744 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 3072)"]
	1904570866496 -> 1904570867744
	1904570866496 -> 1904570577872 [dir=none]
	1904570577872 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570866496 -> 1904570577632 [dir=none]
	1904570577632 [label="mat2
 (768, 3072)" fillcolor=orange]
	1904570866496 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 3072)
mat2_sym_strides:       (1, 768)"]
	1904570867936 -> 1904570866496
	1904566159136 [label="blocks.6.mlp.fc1.bias
 (3072)" fillcolor=lightblue]
	1904566159136 -> 1904570867936
	1904570867936 [label=AccumulateGrad]
	1904570867360 -> 1904570866496
	1904570867360 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570866688 -> 1904570867360
	1904570866688 -> 1904566162816 [dir=none]
	1904566162816 [label="bias
 (768)" fillcolor=orange]
	1904570866688 -> 1904566221648 [dir=none]
	1904566221648 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570866688 -> 1904570577232 [dir=none]
	1904570577232 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570866688 -> 1904570577552 [dir=none]
	1904570577552 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570866688 -> 1904566168656 [dir=none]
	1904566168656 [label="weight
 (768)" fillcolor=orange]
	1904570866688 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570964944 -> 1904570866688
	1904570866064 -> 1904570866688
	1904566168656 [label="blocks.6.norm2.weight
 (768)" fillcolor=lightblue]
	1904566168656 -> 1904570866064
	1904570866064 [label=AccumulateGrad]
	1904570865920 -> 1904570866688
	1904566162816 [label="blocks.6.norm2.bias
 (768)" fillcolor=lightblue]
	1904566162816 -> 1904570865920
	1904570865920 [label=AccumulateGrad]
	1904570869184 -> 1904570866496
	1904570869184 [label=TBackward0]
	1904570866112 -> 1904570869184
	1904566159616 [label="blocks.6.mlp.fc1.weight
 (3072, 768)" fillcolor=lightblue]
	1904566159616 -> 1904570866112
	1904570866112 [label=AccumulateGrad]
	1904570871680 -> 1904570964320
	1904570871680 [label=TBackward0]
	1904570867984 -> 1904570871680
	1904566161936 [label="blocks.6.mlp.fc2.weight
 (768, 3072)" fillcolor=lightblue]
	1904566161936 -> 1904570867984
	1904570867984 [label=AccumulateGrad]
	1904570965568 -> 1904570965376
	1904570965568 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570964080 -> 1904570965568
	1904570964080 -> 1904570577152 [dir=none]
	1904570577152 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570964080 -> 1904570577392 [dir=none]
	1904570577392 [label="mat2
 (768, 768)" fillcolor=orange]
	1904570964080 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (768, 768)
mat2_sym_strides:       (1, 768)"]
	1904570865872 -> 1904570964080
	1904566169696 [label="blocks.7.attn.proj.bias
 (768)" fillcolor=lightblue]
	1904566169696 -> 1904570865872
	1904570865872 [label=AccumulateGrad]
	1904570868368 -> 1904570964080
	1904570868368 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570868992 -> 1904570868368
	1904570868992 [label="ReshapeAliasBackward0
--------------------------------
self_sym_sizes: (1, 577, 12, 64)"]
	1904570865440 -> 1904570868992
	1904570865440 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	1904570864624 -> 1904570865440
	1904570864624 -> 1904566217728 [dir=none]
	1904566217728 [label="key
 (1, 12, 577, 64)" fillcolor=orange]
	1904570864624 -> 1904566217408 [dir=none]
	1904566217408 [label="query
 (1, 12, 577, 64)" fillcolor=orange]
	1904570864624 -> 1904570577712 [dir=none]
	1904570577712 [label="result0
 (1, 12, 577, 64)" fillcolor=orange]
	1904570864624 -> 1904570577312 [dir=none]
	1904570577312 [label="result1
 (1, 12, 608)" fillcolor=orange]
	1904570864624 -> 1904566215248 [dir=none]
	1904566215248 [label="value
 (1, 12, 577, 64)" fillcolor=orange]
	1904570864624 [label="ScaledDotProductEfficientAttentionBackward0
-------------------------------------------
is_causal:          False
key      : [saved tensor]
query    : [saved tensor]
result0  : [saved tensor]
result1  : [saved tensor]
value    : [saved tensor]"]
	1904570864816 -> 1904570864624
	1904570864816 [label="UnbindBackward0
---------------
dim: 0"]
	1904570864000 -> 1904570864816
	1904570864000 [label="PermuteBackward0
---------------------
dims: (2, 0, 3, 1, 4)"]
	1904570864192 -> 1904570864000
	1904570864192 [label="ReshapeAliasBackward0
------------------------------
self_sym_sizes: (1, 577, 2304)"]
	1904570863376 -> 1904570864192
	1904570863376 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 2304)"]
	1904570863568 -> 1904570863376
	1904570863568 -> 1904570576912 [dir=none]
	1904570576912 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570863568 -> 1904570576432 [dir=none]
	1904570576432 [label="mat2
 (768, 2304)" fillcolor=orange]
	1904570863568 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 2304)
mat2_sym_strides:       (1, 768)"]
	1904570862752 -> 1904570863568
	1904566168816 [label="blocks.7.attn.qkv.bias
 (2304)" fillcolor=lightblue]
	1904566168816 -> 1904570862752
	1904570862752 [label=AccumulateGrad]
	1904570863616 -> 1904570863568
	1904570863616 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570862944 -> 1904570863616
	1904570862944 -> 1904566173056 [dir=none]
	1904566173056 [label="bias
 (768)" fillcolor=orange]
	1904570862944 -> 1904566217088 [dir=none]
	1904566217088 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570862944 -> 1904570576512 [dir=none]
	1904570576512 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570862944 -> 1904570577072 [dir=none]
	1904570577072 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570862944 -> 1904566163376 [dir=none]
	1904566163376 [label="weight
 (768)" fillcolor=orange]
	1904570862944 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570964704 -> 1904570862944
	1904570862320 -> 1904570862944
	1904566163376 [label="blocks.7.norm1.weight
 (768)" fillcolor=lightblue]
	1904566163376 -> 1904570862320
	1904570862320 [label=AccumulateGrad]
	1904570862176 -> 1904570862944
	1904566173056 [label="blocks.7.norm1.bias
 (768)" fillcolor=lightblue]
	1904566173056 -> 1904570862176
	1904570862176 [label=AccumulateGrad]
	1904570865248 -> 1904570863568
	1904570865248 [label=TBackward0]
	1904570862368 -> 1904570865248
	1904566173136 [label="blocks.7.attn.qkv.weight
 (2304, 768)" fillcolor=lightblue]
	1904566173136 -> 1904570862368
	1904570862368 [label=AccumulateGrad]
	1904570864816 -> 1904570864624
	1904570864816 -> 1904570864624
	1904570869616 -> 1904570964080
	1904570869616 [label=TBackward0]
	1904570865488 -> 1904570869616
	1904566173376 [label="blocks.7.attn.proj.weight
 (768, 768)" fillcolor=lightblue]
	1904566173376 -> 1904570865488
	1904570865488 [label=AccumulateGrad]
	1904570965328 -> 1904570966144
	1904570965328 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570964752 -> 1904570965328
	1904570964752 -> 1904570576752 [dir=none]
	1904570576752 [label="mat1
 (577, 3072)" fillcolor=orange]
	1904570964752 -> 1904570576992 [dir=none]
	1904570576992 [label="mat2
 (3072, 768)" fillcolor=orange]
	1904570964752 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :    (577, 3072)
mat1_sym_strides:      (3072, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (3072, 768)
mat2_sym_strides:      (1, 3072)"]
	1904570864864 -> 1904570964752
	1904566164416 [label="blocks.7.mlp.fc2.bias
 (768)" fillcolor=lightblue]
	1904566164416 -> 1904570864864
	1904570864864 [label=AccumulateGrad]
	1904570866736 -> 1904570964752
	1904570866736 [label="ViewBackward0
------------------------------
self_sym_sizes: (1, 577, 3072)"]
	1904570865296 -> 1904570866736
	1904570865296 -> 1904566214288 [dir=none]
	1904566214288 [label="self
 (1, 577, 3072)" fillcolor=orange]
	1904570865296 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	1904570862800 -> 1904570865296
	1904570862800 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 3072)"]
	1904570861552 -> 1904570862800
	1904570861552 -> 1904570576832 [dir=none]
	1904570576832 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570861552 -> 1904570576272 [dir=none]
	1904570576272 [label="mat2
 (768, 3072)" fillcolor=orange]
	1904570861552 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 3072)
mat2_sym_strides:       (1, 768)"]
	1904570862992 -> 1904570861552
	1904566168496 [label="blocks.7.mlp.fc1.bias
 (3072)" fillcolor=lightblue]
	1904566168496 -> 1904570862992
	1904570862992 [label=AccumulateGrad]
	1904570861504 -> 1904570861552
	1904570861504 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570861744 -> 1904570861504
	1904570861744 -> 1904566166656 [dir=none]
	1904566166656 [label="bias
 (768)" fillcolor=orange]
	1904570861744 -> 1904566216768 [dir=none]
	1904566216768 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570861744 -> 1904570576192 [dir=none]
	1904570576192 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570861744 -> 1904570576672 [dir=none]
	1904570576672 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570861744 -> 1904566172976 [dir=none]
	1904566172976 [label="weight
 (768)" fillcolor=orange]
	1904570861744 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570965376 -> 1904570861744
	1904570861120 -> 1904570861744
	1904566172976 [label="blocks.7.norm2.weight
 (768)" fillcolor=lightblue]
	1904566172976 -> 1904570861120
	1904570861120 [label=AccumulateGrad]
	1904570861072 -> 1904570861744
	1904566166656 [label="blocks.7.norm2.bias
 (768)" fillcolor=lightblue]
	1904566166656 -> 1904570861072
	1904570861072 [label=AccumulateGrad]
	1904570864240 -> 1904570861552
	1904570864240 [label=TBackward0]
	1904570860256 -> 1904570864240
	1904566163856 [label="blocks.7.mlp.fc1.weight
 (3072, 768)" fillcolor=lightblue]
	1904566163856 -> 1904570860256
	1904570860256 [label=AccumulateGrad]
	1904570866544 -> 1904570964752
	1904570866544 [label=TBackward0]
	1904570862128 -> 1904570866544
	1904566167296 [label="blocks.7.mlp.fc2.weight
 (768, 3072)" fillcolor=lightblue]
	1904566167296 -> 1904570862128
	1904570862128 [label=AccumulateGrad]
	1904570966000 -> 1904570966816
	1904570966000 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570965520 -> 1904570966000
	1904570965520 -> 1904570576352 [dir=none]
	1904570576352 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570965520 -> 1904570575872 [dir=none]
	1904570575872 [label="mat2
 (768, 768)" fillcolor=orange]
	1904570965520 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (768, 768)
mat2_sym_strides:       (1, 768)"]
	1904570860928 -> 1904570965520
	1904566158896 [label="blocks.8.attn.proj.bias
 (768)" fillcolor=lightblue]
	1904566158896 -> 1904570860928
	1904570860928 [label=AccumulateGrad]
	1904570863424 -> 1904570965520
	1904570863424 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570864048 -> 1904570863424
	1904570864048 [label="ReshapeAliasBackward0
--------------------------------
self_sym_sizes: (1, 577, 12, 64)"]
	1904570860496 -> 1904570864048
	1904570860496 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	1904570859680 -> 1904570860496
	1904570859680 -> 1904566213008 [dir=none]
	1904566213008 [label="key
 (1, 12, 577, 64)" fillcolor=orange]
	1904570859680 -> 1904566213648 [dir=none]
	1904566213648 [label="query
 (1, 12, 577, 64)" fillcolor=orange]
	1904570859680 -> 1904570576592 [dir=none]
	1904570576592 [label="result0
 (1, 12, 577, 64)" fillcolor=orange]
	1904570859680 -> 1904570575952 [dir=none]
	1904570575952 [label="result1
 (1, 12, 608)" fillcolor=orange]
	1904570859680 -> 1904566211648 [dir=none]
	1904566211648 [label="value
 (1, 12, 577, 64)" fillcolor=orange]
	1904570859680 [label="ScaledDotProductEfficientAttentionBackward0
-------------------------------------------
is_causal:          False
key      : [saved tensor]
query    : [saved tensor]
result0  : [saved tensor]
result1  : [saved tensor]
value    : [saved tensor]"]
	1904570859872 -> 1904570859680
	1904570859872 [label="UnbindBackward0
---------------
dim: 0"]
	1904570866160 -> 1904570859872
	1904570866160 [label="PermuteBackward0
---------------------
dims: (2, 0, 3, 1, 4)"]
	1904570875616 -> 1904570866160
	1904570875616 [label="ReshapeAliasBackward0
------------------------------
self_sym_sizes: (1, 577, 2304)"]
	1904570875712 -> 1904570875616
	1904570875712 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 2304)"]
	1904570875808 -> 1904570875712
	1904570875808 -> 1904570576112 [dir=none]
	1904570576112 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570875808 -> 1904570575712 [dir=none]
	1904570575712 [label="mat2
 (768, 2304)" fillcolor=orange]
	1904570875808 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 2304)
mat2_sym_strides:       (1, 768)"]
	1904570875376 -> 1904570875808
	1904566170016 [label="blocks.8.attn.qkv.bias
 (2304)" fillcolor=lightblue]
	1904566170016 -> 1904570875376
	1904570875376 [label=AccumulateGrad]
	1904570875328 -> 1904570875808
	1904570875328 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570874992 -> 1904570875328
	1904570874992 -> 1904566165936 [dir=none]
	1904566165936 [label="bias
 (768)" fillcolor=orange]
	1904570874992 -> 1904566214608 [dir=none]
	1904566214608 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570874992 -> 1904570575232 [dir=none]
	1904570575232 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570874992 -> 1904570576032 [dir=none]
	1904570576032 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570874992 -> 1904566168096 [dir=none]
	1904566168096 [label="weight
 (768)" fillcolor=orange]
	1904570874992 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570966144 -> 1904570874992
	1904570875184 -> 1904570874992
	1904566168096 [label="blocks.8.norm1.weight
 (768)" fillcolor=lightblue]
	1904566168096 -> 1904570875184
	1904570875184 [label=AccumulateGrad]
	1904570875136 -> 1904570874992
	1904566165936 [label="blocks.8.norm1.bias
 (768)" fillcolor=lightblue]
	1904566165936 -> 1904570875136
	1904570875136 [label=AccumulateGrad]
	1904570860304 -> 1904570875808
	1904570860304 [label=TBackward0]
	1904570874704 -> 1904570860304
	1904566160976 [label="blocks.8.attn.qkv.weight
 (2304, 768)" fillcolor=lightblue]
	1904566160976 -> 1904570874704
	1904570874704 [label=AccumulateGrad]
	1904570859872 -> 1904570859680
	1904570859872 -> 1904570859680
	1904570864672 -> 1904570965520
	1904570864672 [label=TBackward0]
	1904570859632 -> 1904570864672
	1904566172896 [label="blocks.8.attn.proj.weight
 (768, 768)" fillcolor=lightblue]
	1904566172896 -> 1904570859632
	1904570859632 [label=AccumulateGrad]
	1904570966768 -> 1904570966576
	1904570966768 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570966192 -> 1904570966768
	1904570966192 -> 1904570575632 [dir=none]
	1904570575632 [label="mat1
 (577, 3072)" fillcolor=orange]
	1904570966192 -> 1904570575552 [dir=none]
	1904570575552 [label="mat2
 (3072, 768)" fillcolor=orange]
	1904570966192 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :    (577, 3072)
mat1_sym_strides:      (3072, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (3072, 768)
mat2_sym_strides:      (1, 3072)"]
	1904570872400 -> 1904570966192
	1904566163536 [label="blocks.8.mlp.fc2.bias
 (768)" fillcolor=lightblue]
	1904566163536 -> 1904570872400
	1904570872400 [label=AccumulateGrad]
	1904570860880 -> 1904570966192
	1904570860880 [label="ViewBackward0
------------------------------
self_sym_sizes: (1, 577, 3072)"]
	1904570860448 -> 1904570860880
	1904570860448 -> 1904566212368 [dir=none]
	1904566212368 [label="self
 (1, 577, 3072)" fillcolor=orange]
	1904570860448 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	1904570874944 -> 1904570860448
	1904570874944 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 3072)"]
	1904570874320 -> 1904570874944
	1904570874320 -> 1904570575792 [dir=none]
	1904570575792 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570874320 -> 1904570575392 [dir=none]
	1904570575392 [label="mat2
 (768, 3072)" fillcolor=orange]
	1904570874320 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 3072)
mat2_sym_strides:       (1, 768)"]
	1904570875040 -> 1904570874320
	1904566165776 [label="blocks.8.mlp.fc1.bias
 (3072)" fillcolor=lightblue]
	1904566165776 -> 1904570875040
	1904570875040 [label=AccumulateGrad]
	1904570874752 -> 1904570874320
	1904570874752 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570874416 -> 1904570874752
	1904570874416 -> 1904566157936 [dir=none]
	1904566157936 [label="bias
 (768)" fillcolor=orange]
	1904570874416 -> 1904566213968 [dir=none]
	1904566213968 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570874416 -> 1904570574992 [dir=none]
	1904570574992 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570874416 -> 1904570575312 [dir=none]
	1904570575312 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570874416 -> 1904566161696 [dir=none]
	1904566161696 [label="weight
 (768)" fillcolor=orange]
	1904570874416 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570966816 -> 1904570874416
	1904570874080 -> 1904570874416
	1904566161696 [label="blocks.8.norm2.weight
 (768)" fillcolor=lightblue]
	1904566161696 -> 1904570874080
	1904570874080 [label=AccumulateGrad]
	1904570874560 -> 1904570874416
	1904566157936 [label="blocks.8.norm2.bias
 (768)" fillcolor=lightblue]
	1904566157936 -> 1904570874560
	1904570874560 [label=AccumulateGrad]
	1904570875664 -> 1904570874320
	1904570875664 [label=TBackward0]
	1904570874128 -> 1904570875664
	1904566163776 [label="blocks.8.mlp.fc1.weight
 (3072, 768)" fillcolor=lightblue]
	1904566163776 -> 1904570874128
	1904570874128 [label=AccumulateGrad]
	1904570861696 -> 1904570966192
	1904570861696 [label=TBackward0]
	1904570875088 -> 1904570861696
	1904566168976 [label="blocks.8.mlp.fc2.weight
 (768, 3072)" fillcolor=lightblue]
	1904566168976 -> 1904570875088
	1904570875088 [label=AccumulateGrad]
	1904570967440 -> 1904570967248
	1904570967440 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570965952 -> 1904570967440
	1904570965952 -> 1904570574912 [dir=none]
	1904570574912 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570965952 -> 1904570575152 [dir=none]
	1904570575152 [label="mat2
 (768, 768)" fillcolor=orange]
	1904570965952 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (768, 768)
mat2_sym_strides:       (1, 768)"]
	1904570874512 -> 1904570965952
	1904566169856 [label="blocks.9.attn.proj.bias
 (768)" fillcolor=lightblue]
	1904566169856 -> 1904570874512
	1904570874512 [label=AccumulateGrad]
	1904570875760 -> 1904570965952
	1904570875760 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570875568 -> 1904570875760
	1904570875568 [label="ReshapeAliasBackward0
--------------------------------
self_sym_sizes: (1, 577, 12, 64)"]
	1904570873792 -> 1904570875568
	1904570873792 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	1904570873888 -> 1904570873792
	1904570873888 -> 1904566209248 [dir=none]
	1904566209248 [label="key
 (1, 12, 577, 64)" fillcolor=orange]
	1904570873888 -> 1904566208528 [dir=none]
	1904566208528 [label="query
 (1, 12, 577, 64)" fillcolor=orange]
	1904570873888 -> 1904570575472 [dir=none]
	1904570575472 [label="result0
 (1, 12, 577, 64)" fillcolor=orange]
	1904570873888 -> 1904570575072 [dir=none]
	1904570575072 [label="result1
 (1, 12, 608)" fillcolor=orange]
	1904570873888 -> 1904566210208 [dir=none]
	1904566210208 [label="value
 (1, 12, 577, 64)" fillcolor=orange]
	1904570873888 [label="ScaledDotProductEfficientAttentionBackward0
-------------------------------------------
is_causal:          False
key      : [saved tensor]
query    : [saved tensor]
result0  : [saved tensor]
result1  : [saved tensor]
value    : [saved tensor]"]
	1904570873456 -> 1904570873888
	1904570873456 [label="UnbindBackward0
---------------
dim: 0"]
	1904570873072 -> 1904570873456
	1904570873072 [label="PermuteBackward0
---------------------
dims: (2, 0, 3, 1, 4)"]
	1904570873168 -> 1904570873072
	1904570873168 [label="ReshapeAliasBackward0
------------------------------
self_sym_sizes: (1, 577, 2304)"]
	1904570873264 -> 1904570873168
	1904570873264 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 2304)"]
	1904570872832 -> 1904570873264
	1904570872832 -> 1904570574592 [dir=none]
	1904570574592 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570872832 -> 1904570574352 [dir=none]
	1904570574352 [label="mat2
 (768, 2304)" fillcolor=orange]
	1904570872832 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 2304)
mat2_sym_strides:       (1, 768)"]
	1904570872448 -> 1904570872832
	1904566171536 [label="blocks.9.attn.qkv.bias
 (2304)" fillcolor=lightblue]
	1904566171536 -> 1904570872448
	1904570872448 [label=AccumulateGrad]
	1904570872880 -> 1904570872832
	1904570872880 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570872544 -> 1904570872880
	1904570872544 -> 1904566168336 [dir=none]
	1904566168336 [label="bias
 (768)" fillcolor=orange]
	1904570872544 -> 1904566212048 [dir=none]
	1904566212048 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570872544 -> 1904570574512 [dir=none]
	1904570574512 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570872544 -> 1904570574672 [dir=none]
	1904570574672 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570872544 -> 1904566169776 [dir=none]
	1904566169776 [label="weight
 (768)" fillcolor=orange]
	1904570872544 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570966576 -> 1904570872544
	1904570872208 -> 1904570872544
	1904566169776 [label="blocks.9.norm1.weight
 (768)" fillcolor=lightblue]
	1904566169776 -> 1904570872208
	1904570872208 [label=AccumulateGrad]
	1904570872688 -> 1904570872544
	1904566168336 [label="blocks.9.norm1.bias
 (768)" fillcolor=lightblue]
	1904566168336 -> 1904570872688
	1904570872688 [label=AccumulateGrad]
	1904570873696 -> 1904570872832
	1904570873696 [label=TBackward0]
	1904570872256 -> 1904570873696
	1904566159296 [label="blocks.9.attn.qkv.weight
 (2304, 768)" fillcolor=lightblue]
	1904566159296 -> 1904570872256
	1904570872256 [label=AccumulateGrad]
	1904570873456 -> 1904570873888
	1904570873456 -> 1904570873888
	1904570859824 -> 1904570965952
	1904570859824 [label=TBackward0]
	1904570873840 -> 1904570859824
	1904566170336 [label="blocks.9.attn.proj.weight
 (768, 768)" fillcolor=lightblue]
	1904566170336 -> 1904570873840
	1904570873840 [label=AccumulateGrad]
	1904570967200 -> 1904570968016
	1904570967200 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570966624 -> 1904570967200
	1904570966624 -> 1904570574752 [dir=none]
	1904570574752 [label="mat1
 (577, 3072)" fillcolor=orange]
	1904570966624 -> 1904570574832 [dir=none]
	1904570574832 [label="mat2
 (3072, 768)" fillcolor=orange]
	1904570966624 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :    (577, 3072)
mat1_sym_strides:      (3072, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (3072, 768)
mat2_sym_strides:      (1, 3072)"]
	1904570873504 -> 1904570966624
	1904566110944 [label="blocks.9.mlp.fc2.bias
 (768)" fillcolor=lightblue]
	1904566110944 -> 1904570873504
	1904570873504 [label=AccumulateGrad]
	1904570874464 -> 1904570966624
	1904570874464 [label="ViewBackward0
------------------------------
self_sym_sizes: (1, 577, 3072)"]
	1904570873744 -> 1904570874464
	1904570873744 -> 1904566208208 [dir=none]
	1904566208208 [label="self
 (1, 577, 3072)" fillcolor=orange]
	1904570873744 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	1904570872496 -> 1904570873744
	1904570872496 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 3072)"]
	1904570871872 -> 1904570872496
	1904570871872 -> 1904570574272 [dir=none]
	1904570574272 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570871872 -> 1904570574032 [dir=none]
	1904570574032 [label="mat2
 (768, 3072)" fillcolor=orange]
	1904570871872 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 3072)
mat2_sym_strides:       (1, 768)"]
	1904570872592 -> 1904570871872
	1904566169216 [label="blocks.9.mlp.fc1.bias
 (3072)" fillcolor=lightblue]
	1904566169216 -> 1904570872592
	1904570872592 [label=AccumulateGrad]
	1904570871824 -> 1904570871872
	1904570871824 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570871968 -> 1904570871824
	1904570871968 -> 1904566164736 [dir=none]
	1904566164736 [label="bias
 (768)" fillcolor=orange]
	1904570871968 -> 1904566210848 [dir=none]
	1904566210848 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570871968 -> 1904570574112 [dir=none]
	1904570574112 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570871968 -> 1904570574432 [dir=none]
	1904570574432 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570871968 -> 1904566157856 [dir=none]
	1904566157856 [label="weight
 (768)" fillcolor=orange]
	1904570871968 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570967248 -> 1904570871968
	1904570871632 -> 1904570871968
	1904566157856 [label="blocks.9.norm2.weight
 (768)" fillcolor=lightblue]
	1904566157856 -> 1904570871632
	1904570871632 [label=AccumulateGrad]
	1904570871584 -> 1904570871968
	1904566164736 [label="blocks.9.norm2.bias
 (768)" fillcolor=lightblue]
	1904566164736 -> 1904570871584
	1904570871584 [label=AccumulateGrad]
	1904570873216 -> 1904570871872
	1904570873216 [label=TBackward0]
	1904570871200 -> 1904570873216
	1904566169376 [label="blocks.9.mlp.fc1.weight
 (3072, 768)" fillcolor=lightblue]
	1904566169376 -> 1904570871200
	1904570871200 [label=AccumulateGrad]
	1904570874368 -> 1904570966624
	1904570874368 [label=TBackward0]
	1904570872640 -> 1904570874368
	1904566117584 [label="blocks.9.mlp.fc2.weight
 (768, 3072)" fillcolor=lightblue]
	1904566117584 -> 1904570872640
	1904570872640 [label=AccumulateGrad]
	1904570967872 -> 1904570968688
	1904570967872 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570967392 -> 1904570967872
	1904570967392 -> 1904570574192 [dir=none]
	1904570574192 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570967392 -> 1904570573632 [dir=none]
	1904570573632 [label="mat2
 (768, 768)" fillcolor=orange]
	1904570967392 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (768, 768)
mat2_sym_strides:       (1, 768)"]
	1904570872064 -> 1904570967392
	1904566110304 [label="blocks.10.attn.proj.bias
 (768)" fillcolor=lightblue]
	1904566110304 -> 1904570872064
	1904570872064 [label=AccumulateGrad]
	1904570873312 -> 1904570967392
	1904570873312 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570873120 -> 1904570873312
	1904570873120 [label="ReshapeAliasBackward0
--------------------------------
self_sym_sizes: (1, 577, 12, 64)"]
	1904570871344 -> 1904570873120
	1904570871344 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	1904570871440 -> 1904570871344
	1904570871440 -> 1904566212208 [dir=none]
	1904566212208 [label="key
 (1, 12, 577, 64)" fillcolor=orange]
	1904570871440 -> 1904566212528 [dir=none]
	1904566212528 [label="query
 (1, 12, 577, 64)" fillcolor=orange]
	1904570871440 -> 1904570573952 [dir=none]
	1904570573952 [label="result0
 (1, 12, 577, 64)" fillcolor=orange]
	1904570871440 -> 1904570573712 [dir=none]
	1904570573712 [label="result1
 (1, 12, 608)" fillcolor=orange]
	1904570871440 -> 1904566211488 [dir=none]
	1904566211488 [label="value
 (1, 12, 577, 64)" fillcolor=orange]
	1904570871440 [label="ScaledDotProductEfficientAttentionBackward0
-------------------------------------------
is_causal:          False
key      : [saved tensor]
query    : [saved tensor]
result0  : [saved tensor]
result1  : [saved tensor]
value    : [saved tensor]"]
	1904570871008 -> 1904570871440
	1904570871008 [label="UnbindBackward0
---------------
dim: 0"]
	1904570870624 -> 1904570871008
	1904570870624 [label="PermuteBackward0
---------------------
dims: (2, 0, 3, 1, 4)"]
	1904570870720 -> 1904570870624
	1904570870720 [label="ReshapeAliasBackward0
------------------------------
self_sym_sizes: (1, 577, 2304)"]
	1904570870816 -> 1904570870720
	1904570870816 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 2304)"]
	1904570870384 -> 1904570870816
	1904570870384 -> 1904570573872 [dir=none]
	1904570573872 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570870384 -> 1904570573472 [dir=none]
	1904570573472 [label="mat2
 (768, 2304)" fillcolor=orange]
	1904570870384 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 2304)
mat2_sym_strides:       (1, 768)"]
	1904570870000 -> 1904570870384
	1904566115504 [label="blocks.10.attn.qkv.bias
 (2304)" fillcolor=lightblue]
	1904566115504 -> 1904570870000
	1904570870000 [label=AccumulateGrad]
	1904570869952 -> 1904570870384
	1904570869952 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570870096 -> 1904570869952
	1904570870096 -> 1904566108544 [dir=none]
	1904566108544 [label="bias
 (768)" fillcolor=orange]
	1904570870096 -> 1904566207568 [dir=none]
	1904566207568 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570870096 -> 1904570572992 [dir=none]
	1904570572992 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570870096 -> 1904570573792 [dir=none]
	1904570573792 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570870096 -> 1904566117824 [dir=none]
	1904566117824 [label="weight
 (768)" fillcolor=orange]
	1904570870096 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570968016 -> 1904570870096
	1904570869760 -> 1904570870096
	1904566117824 [label="blocks.10.norm1.weight
 (768)" fillcolor=lightblue]
	1904566117824 -> 1904570869760
	1904570869760 [label=AccumulateGrad]
	1904570869712 -> 1904570870096
	1904566108544 [label="blocks.10.norm1.bias
 (768)" fillcolor=lightblue]
	1904566108544 -> 1904570869712
	1904570869712 [label=AccumulateGrad]
	1904570871248 -> 1904570870384
	1904570871248 [label=TBackward0]
	1904570869328 -> 1904570871248
	1904566115184 [label="blocks.10.attn.qkv.weight
 (2304, 768)" fillcolor=lightblue]
	1904566115184 -> 1904570869328
	1904570869328 [label=AccumulateGrad]
	1904570871008 -> 1904570871440
	1904570871008 -> 1904570871440
	1904570873936 -> 1904570967392
	1904570873936 [label=TBackward0]
	1904570871392 -> 1904570873936
	1904566114864 [label="blocks.10.attn.proj.weight
 (768, 768)" fillcolor=lightblue]
	1904566114864 -> 1904570871392
	1904570871392 [label=AccumulateGrad]
	1904570968640 -> 1904570968448
	1904570968640 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570968064 -> 1904570968640
	1904570968064 -> 1904570573392 [dir=none]
	1904570573392 [label="mat1
 (577, 3072)" fillcolor=orange]
	1904570968064 -> 1904570573312 [dir=none]
	1904570573312 [label="mat2
 (3072, 768)" fillcolor=orange]
	1904570968064 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :    (577, 3072)
mat1_sym_strides:      (3072, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (3072, 768)
mat2_sym_strides:      (1, 3072)"]
	1904570870576 -> 1904570968064
	1904566111344 [label="blocks.10.mlp.fc2.bias
 (768)" fillcolor=lightblue]
	1904566111344 -> 1904570870576
	1904570870576 [label=AccumulateGrad]
	1904570872016 -> 1904570968064
	1904570872016 [label="ViewBackward0
------------------------------
self_sym_sizes: (1, 577, 3072)"]
	1904570871296 -> 1904570872016
	1904570871296 -> 1904566213488 [dir=none]
	1904566213488 [label="self
 (1, 577, 3072)" fillcolor=orange]
	1904570871296 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	1904570870048 -> 1904570871296
	1904570870048 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 3072)"]
	1904570869424 -> 1904570870048
	1904570869424 -> 1904570573552 [dir=none]
	1904570573552 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570869424 -> 1904570573152 [dir=none]
	1904570573152 [label="mat2
 (768, 3072)" fillcolor=orange]
	1904570869424 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 3072)
mat2_sym_strides:       (1, 768)"]
	1904570870144 -> 1904570869424
	1904566109984 [label="blocks.10.mlp.fc1.bias
 (3072)" fillcolor=lightblue]
	1904566109984 -> 1904570870144
	1904570870144 [label=AccumulateGrad]
	1904570869376 -> 1904570869424
	1904570869376 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570869520 -> 1904570869376
	1904570869520 -> 1904566112304 [dir=none]
	1904566112304 [label="bias
 (768)" fillcolor=orange]
	1904570869520 -> 1904566206928 [dir=none]
	1904566206928 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570869520 -> 1904570572912 [dir=none]
	1904570572912 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570869520 -> 1904570573072 [dir=none]
	1904570573072 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570869520 -> 1904566111664 [dir=none]
	1904566111664 [label="weight
 (768)" fillcolor=orange]
	1904570869520 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570968688 -> 1904570869520
	1904570868704 -> 1904570869520
	1904566111664 [label="blocks.10.norm2.weight
 (768)" fillcolor=lightblue]
	1904566111664 -> 1904570868704
	1904570868704 [label=AccumulateGrad]
	1904570869136 -> 1904570869520
	1904566112304 [label="blocks.10.norm2.bias
 (768)" fillcolor=lightblue]
	1904566112304 -> 1904570869136
	1904570869136 [label=AccumulateGrad]
	1904570870768 -> 1904570869424
	1904570870768 [label=TBackward0]
	1904570868752 -> 1904570870768
	1904566116144 [label="blocks.10.mlp.fc1.weight
 (3072, 768)" fillcolor=lightblue]
	1904566116144 -> 1904570868752
	1904570868752 [label=AccumulateGrad]
	1904570871920 -> 1904570968064
	1904570871920 [label=TBackward0]
	1904570870192 -> 1904570871920
	1904566113904 [label="blocks.10.mlp.fc2.weight
 (768, 3072)" fillcolor=lightblue]
	1904566113904 -> 1904570870192
	1904570870192 [label=AccumulateGrad]
	1904570969312 -> 1904570969120
	1904570969312 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570967824 -> 1904570969312
	1904570967824 -> 1904570572832 [dir=none]
	1904570572832 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570967824 -> 1904570572752 [dir=none]
	1904570572752 [label="mat2
 (768, 768)" fillcolor=orange]
	1904570967824 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (768, 768)
mat2_sym_strides:       (1, 768)"]
	1904570869088 -> 1904570967824
	1904566123344 [label="blocks.11.attn.proj.bias
 (768)" fillcolor=lightblue]
	1904566123344 -> 1904570869088
	1904570869088 [label=AccumulateGrad]
	1904570870336 -> 1904570967824
	1904570870336 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570870672 -> 1904570870336
	1904570870672 [label="ReshapeAliasBackward0
--------------------------------
self_sym_sizes: (1, 577, 12, 64)"]
	1904570868896 -> 1904570870672
	1904570868896 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	1904570868464 -> 1904570868896
	1904570868464 -> 1904566216288 [dir=none]
	1904566216288 [label="key
 (1, 12, 577, 64)" fillcolor=orange]
	1904570868464 -> 1904566214448 [dir=none]
	1904566214448 [label="query
 (1, 12, 577, 64)" fillcolor=orange]
	1904570868464 -> 1904570573232 [dir=none]
	1904570573232 [label="result0
 (1, 12, 577, 64)" fillcolor=orange]
	1904570868464 -> 1904570572512 [dir=none]
	1904570572512 [label="result1
 (1, 12, 608)" fillcolor=orange]
	1904570868464 -> 1904566215808 [dir=none]
	1904566215808 [label="value
 (1, 12, 577, 64)" fillcolor=orange]
	1904570868464 [label="ScaledDotProductEfficientAttentionBackward0
-------------------------------------------
is_causal:          False
key      : [saved tensor]
query    : [saved tensor]
result0  : [saved tensor]
result1  : [saved tensor]
value    : [saved tensor]"]
	1904570868080 -> 1904570868464
	1904570868080 [label="UnbindBackward0
---------------
dim: 0"]
	1904570868176 -> 1904570868080
	1904570868176 [label="PermuteBackward0
---------------------
dims: (2, 0, 3, 1, 4)"]
	1904570868272 -> 1904570868176
	1904570868272 [label="ReshapeAliasBackward0
------------------------------
self_sym_sizes: (1, 577, 2304)"]
	1904570867840 -> 1904570868272
	1904570867840 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 2304)"]
	1904570867456 -> 1904570867840
	1904570867456 -> 1904570572672 [dir=none]
	1904570572672 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570867456 -> 1904570572352 [dir=none]
	1904570572352 [label="mat2
 (768, 2304)" fillcolor=orange]
	1904570867456 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 2304)
mat2_sym_strides:       (1, 768)"]
	1904570867552 -> 1904570867456
	1904566122864 [label="blocks.11.attn.qkv.bias
 (2304)" fillcolor=lightblue]
	1904566122864 -> 1904570867552
	1904570867552 [label=AccumulateGrad]
	1904570867504 -> 1904570867456
	1904570867504 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570867648 -> 1904570867504
	1904570867648 -> 1904566116864 [dir=none]
	1904566116864 [label="bias
 (768)" fillcolor=orange]
	1904570867648 -> 1904566214768 [dir=none]
	1904566214768 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570867648 -> 1904570572032 [dir=none]
	1904570572032 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570867648 -> 1904570572592 [dir=none]
	1904570572592 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570867648 -> 1904566112624 [dir=none]
	1904566112624 [label="weight
 (768)" fillcolor=orange]
	1904570867648 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570968448 -> 1904570867648
	1904570866832 -> 1904570867648
	1904566112624 [label="blocks.11.norm1.weight
 (768)" fillcolor=lightblue]
	1904566112624 -> 1904570866832
	1904570866832 [label=AccumulateGrad]
	1904570867264 -> 1904570867648
	1904566116864 [label="blocks.11.norm1.bias
 (768)" fillcolor=lightblue]
	1904566116864 -> 1904570867264
	1904570867264 [label=AccumulateGrad]
	1904570868800 -> 1904570867456
	1904570868800 [label=TBackward0]
	1904570866880 -> 1904570868800
	1904566123184 [label="blocks.11.attn.qkv.weight
 (2304, 768)" fillcolor=lightblue]
	1904566123184 -> 1904570866880
	1904570866880 [label=AccumulateGrad]
	1904570868080 -> 1904570868464
	1904570868080 -> 1904570868464
	1904570870960 -> 1904570967824
	1904570870960 [label=TBackward0]
	1904570868944 -> 1904570870960
	1904566123824 [label="blocks.11.attn.proj.weight
 (768, 768)" fillcolor=lightblue]
	1904566123824 -> 1904570868944
	1904570868944 [label=AccumulateGrad]
	1904570969072 -> 1904570969744
	1904570969072 [label="ViewBackward0
--------------------------
self_sym_sizes: (577, 768)"]
	1904570968496 -> 1904570969072
	1904570968496 -> 1904570572272 [dir=none]
	1904570572272 [label="mat1
 (577, 3072)" fillcolor=orange]
	1904570968496 -> 1904570572192 [dir=none]
	1904570572192 [label="mat2
 (3072, 768)" fillcolor=orange]
	1904570968496 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :    (577, 3072)
mat1_sym_strides:      (3072, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (3072, 768)
mat2_sym_strides:      (1, 3072)"]
	1904570868128 -> 1904570968496
	1904566124304 [label="blocks.11.mlp.fc2.bias
 (768)" fillcolor=lightblue]
	1904566124304 -> 1904570868128
	1904570868128 [label=AccumulateGrad]
	1904570869568 -> 1904570968496
	1904570869568 [label="ViewBackward0
------------------------------
self_sym_sizes: (1, 577, 3072)"]
	1904570868848 -> 1904570869568
	1904570868848 -> 1904566217568 [dir=none]
	1904566217568 [label="self
 (1, 577, 3072)" fillcolor=orange]
	1904570868848 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	1904570867600 -> 1904570868848
	1904570867600 [label="ViewBackward0
---------------------------
self_sym_sizes: (577, 3072)"]
	1904570866976 -> 1904570867600
	1904570866976 -> 1904570572432 [dir=none]
	1904570572432 [label="mat1
 (577, 768)" fillcolor=orange]
	1904570866976 -> 1904570571792 [dir=none]
	1904570571792 [label="mat2
 (768, 3072)" fillcolor=orange]
	1904570866976 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (577, 768)
mat1_sym_strides:       (768, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (768, 3072)
mat2_sym_strides:       (1, 768)"]
	1904570867696 -> 1904570866976
	1904566124384 [label="blocks.11.mlp.fc1.bias
 (3072)" fillcolor=lightblue]
	1904566124384 -> 1904570867696
	1904570867696 [label=AccumulateGrad]
	1904570866928 -> 1904570866976
	1904570866928 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 577, 768)"]
	1904570867072 -> 1904570866928
	1904570867072 -> 1904566123664 [dir=none]
	1904566123664 [label="bias
 (768)" fillcolor=orange]
	1904570867072 -> 1904566214128 [dir=none]
	1904566214128 [label="input
 (1, 577, 768)" fillcolor=orange]
	1904570867072 -> 1904570571712 [dir=none]
	1904570571712 [label="result1
 (1, 577, 1)" fillcolor=orange]
	1904570867072 -> 1904570572112 [dir=none]
	1904570572112 [label="result2
 (1, 577, 1)" fillcolor=orange]
	1904570867072 -> 1904566122944 [dir=none]
	1904566122944 [label="weight
 (768)" fillcolor=orange]
	1904570867072 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (768,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	1904570969120 -> 1904570867072
	1904570866256 -> 1904570867072
	1904566122944 [label="blocks.11.norm2.weight
 (768)" fillcolor=lightblue]
	1904566122944 -> 1904570866256
	1904570866256 [label=AccumulateGrad]
	1904570866208 -> 1904570867072
	1904566123664 [label="blocks.11.norm2.bias
 (768)" fillcolor=lightblue]
	1904566123664 -> 1904570866208
	1904570866208 [label=AccumulateGrad]
	1904570868320 -> 1904570866976
	1904570868320 [label=TBackward0]
	1904570866304 -> 1904570868320
	1904566123504 [label="blocks.11.mlp.fc1.weight
 (3072, 768)" fillcolor=lightblue]
	1904566123504 -> 1904570866304
	1904570866304 [label=AccumulateGrad]
	1904570869472 -> 1904570968496
	1904570869472 [label=TBackward0]
	1904570867216 -> 1904570869472
	1904566123984 [label="blocks.11.mlp.fc2.weight
 (768, 3072)" fillcolor=lightblue]
	1904566123984 -> 1904570867216
	1904570867216 [label=AccumulateGrad]
	1904570969696 -> 1904570970560
	1904566124144 [label="norm.weight
 (768)" fillcolor=lightblue]
	1904566124144 -> 1904570969696
	1904570969696 [label=AccumulateGrad]
	1904570970944 -> 1904570970560
	1904566117664 [label="norm.bias
 (768)" fillcolor=lightblue]
	1904566117664 -> 1904570970944
	1904570970944 [label=AccumulateGrad]
	1904570971184 -> 1904570971760
	1904570971184 [label=TBackward0]
	1904570969888 -> 1904570971184
	1904566108224 [label="head.weight
 (4, 768)" fillcolor=lightblue]
	1904566108224 -> 1904570969888
	1904570969888 [label=AccumulateGrad]
	1904570971760 -> 1904566218848
}
